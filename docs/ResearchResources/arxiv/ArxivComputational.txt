If there are any errors
please Abort, and run `arxiv_required` for required package installation, and start again
Please wait while we phrase the requested information from global arxiv[arxiv.org] servers 
------------>
---------------------------->
------------------------------------------------------>
 
Path matrix and path energy of graphs (Aleksandar Ilic - 11 October, 2018)
{\bf 79} (2018), 387--398.] on the path energy of graphs and finally present efficient $O(|E| |V|^3)$ algorithm for computing the path matrix used for verifying computational results.
Link: https://arxiv.org/abs/1810.04870
====================================================
NSGA-NET: A Multi-Objective Genetic Algorithm for Neural Architecture Search (Zhichao Lu - 8 October, 2018)
Experimental results suggest that combining the objectives of minimizing both an error metric and computational complexity, as measured by FLOPS, allows NSGA-Net to find competitive neural architectures near the Pareto front of both objectives on two different tasks, object classification and object alignment. NSGA-Net obtains networks that achieve 3.72% (at 4.5 million FLOP) error on CIFAR-10 classification and 8.64% (at 26.6 million FLOP) error on the CMU-Car alignment task
Link: https://arxiv.org/abs/1810.03522
====================================================
A Vertical PRF Architecture for Microblog Search (FlÃ¡vio Martins - 8 October, 2018)
Experiments on the TREC Microblog datasets show that the proposed approach can match or outperform standard PRF in MAP and NDCG@30, with a computational cost that is three orders of magnitude lower.
Link: https://arxiv.org/abs/1810.03519
====================================================
A scalable parallel finite element framework for growing geometries. Application to metal additive manufacturing (Eric Neiva - 8 October, 2018)
Computational experiments consider the part-scale thermal analysis of the printing process by powder-bed technologies. After verification against a 3D benchmark, a strong scaling analysis is carried out for a simulation of 48 layers printed in a cuboid. The cuboid is adaptively meshed to model a layer-by-layer metal deposition process and the average global problem size amounts to 10.3 million unknowns. An unprecedented scalability for problems with growing domains is achieved, with the capability of simulating the printing and recoat of a single layer in 8 seconds average on 3,072 processors
Link: https://arxiv.org/abs/1810.03506
====================================================
Understanding Recurrent Neural Architectures by Analyzing and Synthesizing Long Distance Dependencies in Benchmark Sequential Datasets (Abhijit Mahalunkar - 6 October, 2018)
At present, the state-of-the-art computational models across a range of sequential data processing tasks, including language modeling, are based on recurrent neural network architectures
Link: https://arxiv.org/abs/1810.02966
====================================================
Tuning for Tissue Image Segmentation Workflows for Accuracy and Performance (Luis F. R. Taveira - 5 October, 2018)
This is a time-consuming and computationally expensive process; automating this step facilitates more robust image segmentation workflows and enables more efficient application of image analysis in large image datasets. Our results using three real-world image segmentation workflows demonstrate that the proposed solution is able to (1) search a small fraction (about 100 points) of the parameter space, which contains billions to trillions of points, and improve the quality of segmentation output by 1.20x, 1.29x, and 1.29x, on average; (2) decrease the execution time of a segmentation workflow by up to 11.79x while improving output quality; and (3) effectively use parallel systems to accelerate parameter tuning and segmentation phases.
Link: https://arxiv.org/abs/1810.02911
====================================================
A Comparison between Background Modelling Methods for Vehicle Segmentation in Highway Traffic Videos (L. A. Marcomini - 5 October, 2018)
By using accuracy and precision, we aim to identify how well the algorithms perform in detection and segmentation, while using the processing time to evaluate the impact on the computational system. Results indicate that all three algorithms had more than 90% of precision rate, while obtaining an average of 80% on accuracy. The algorithm with the lowest impact on processing time allowed the computation of 60 frames per second.
Link: https://arxiv.org/abs/1810.02835
====================================================
GraphBolt: Streaming Graph Approximations on Big Data (Miguel E. Coimbra - 5 October, 2018)
Our experiments show that GraphBolt can reduce computational time by over 50% while achieving result quality above 95% when compared to results of the traditional version of PageRank without any summarization or approximation techniques.
Link: https://arxiv.org/abs/1810.02781
====================================================
Memetic Viability Evolution for Constrained Optimization (A. Maesani - 5 October, 2018)
The proposed algorithm can outperform several state-of-the-art methods on a diverse set of benchmark and engineering problems, both for quality of solutions and computational resources needed.
Link: https://arxiv.org/abs/1810.02702
====================================================
Transfer Incremental Learning using Data Augmentation (Ghouthi Boukli Hacene - 3 October, 2018)
Deep learning-based methods have reached state of the art performances, relying on large quantity of available data and computational power
Link: https://arxiv.org/abs/1810.02020
====================================================
Sparse Winograd Convolutional neural networks on small-scale systolic arrays (Feng Shi - 3 October, 2018)
Experimental results on VGG16 show that it achieves very high computational resource utilization, 20x ~ 30x energy efficiency, and more than 5x speedup compared with the dense implementation.
Link: https://arxiv.org/abs/1810.01973
====================================================
LIT: Block-wise Intermediate Representation Training for Model Compression (Animesh Koratana - 1 October, 2018)
Knowledge distillation (KD) is a popular method for reducing the computational overhead of deep network inference, in which the output of a teacher model is used to train a smaller, faster student model. LIT has two key ideas: 1) LIT trains a student of the same width (but shallower depth) as the teacher by directly comparing the intermediate representations, and 2) LIT uses the intermediate representation from the previous block in the teacher model as an input to the current student block during training, avoiding unstable intermediate representations in the student network. We show that LIT provides substantial reductions in network depth without loss in accuracy -- for example, LIT can compress a ResNeXt-110 to a ResNeXt-20 (5.5x) on CIFAR10 and a VDCNN-29 to a VDCNN-9 (3.2x) on Amazon Reviews without loss in accuracy, outperforming KD and hint training in network size for a given accuracy
Link: https://arxiv.org/abs/1810.01937
====================================================
Optimally Segmenting Inputs for NMT Shows Preference for Character-Level Processing (Julia Kreutzer - 2 October, 2018)
Segmentation granularity importantly determines the input and output sequence lengths, hence the modeling depth, and source and target vocabularies, which in turn determine model size, computational costs of softmax normalization, and handling of out-of-vocabulary words. To overcome suboptimal segmentation choices, we present an algorithm for dynamic segmentation based on the Adaptative Computation Time algorithm (Graves 2016), that is trainable end-to-end and driven by the NMT objective
Link: https://arxiv.org/abs/1810.01480
====================================================
Energy-Based Hindsight Experience Prioritization (Rui Zhao - 8 October, 2018)
Our empirical results show that our proposed method surpasses state-of-the-art approaches in terms of both performance and sample-efficiency on all four tasks, without increasing computational time
Link: https://arxiv.org/abs/1810.01363
====================================================
Target Aware Network Adaptation for Efficient Representation Learning (Yang Zhong - 2 October, 2018)
Experimental results by the method on five datasets (Flower102, CUB200-2011, Dog120, MIT67, and Stanford40) show favorable accuracies over the related state-of-the-art techniques while enhancing the computational and storage efficiency of the transferred model.
Link: https://arxiv.org/abs/1810.01104
====================================================
Simultaneously Optimizing Weight and Quantizer of Ternary Neural Network using Truncated Gaussian Approximation (Zhezhi He - 1 October, 2018)
-1, 0, +1) have been widely explored to greatly reduce the model size and computational cost, with limited accuracy degradation
Link: https://arxiv.org/abs/1810.01018
====================================================
Non-linear Attributed Graph Clustering by Symmetric NMF with PU Learning (Seiji Maekawa - 21 September, 2018)
1) it learns a non-linear projection function between the different cluster assignments of the topology and the attributes of graphs so as to capture the complicated relationship between the topology and the attributes in real-world graphs, 2) it leverages the positive unlabeled learning to take the effect of partially observed positive edges into the cluster assignment, and 3) it achieves efficient computational complexity, $O((n^2+mn)kt)$, where $n$ is the vertex size, $m$ is the attribute size, $k$ is the number of clusters, and $t$ is the number of iterations for learning the cluster assignment
Link: https://arxiv.org/abs/1810.00946
====================================================
Text Similarity in Vector Space Models: A Comparative Study (Omid Shahmirzadi - 24 September, 2018)
Contrary to expectations, the added computational cost of text embedding methods is justified only when: 1) the target text is condensed; and 2) the similarity comparison is trivial
Link: https://arxiv.org/abs/1810.00664
====================================================
Procedural Noise Adversarial Examples for Black-Box Attacks on Deep Neural Networks (Kenneth T. Co - 30 September, 2018)
We show that it is possible to construct practical black-box attacks with low computational cost against robust neural network architectures such as Inception v3 and Inception ResNet v2 on the ImageNet dataset. Perlin noise attacks achieve at least 90% top 1 error across all classifiers. More worryingly, we show that most Perlin noise perturbations are "universal" in that they generalize, as adversarial examples, across large portions of the dataset, with up to 73% of images misclassified using a single perturbation
Link: https://arxiv.org/abs/1810.00470
====================================================
Non-local NetVLAD Encoding for Video Classification (Yongyi Tang - 29 September, 2018)
Our system fuses six different sub-models into one single computational graph, which are categorized into three families. Experimental results demonstrate that our proposed system can effectively perform the video classification task, achieving 0.88763 on the public test set and 0.88704 on the private set in terms of GAP@20, respectively
Link: https://arxiv.org/abs/1810.00207
====================================================
A fast GPU Monte Carlo Radiative Heat Transfer Implementation for Coupling with Direct Numerical Simulation (Simone Silvestri - 29 September, 2018)
The bottlenecks that dominate the computational expenses are addressed and several techniques are proposed to optimize the GPU execution. By implementing the proposed algorithmic accelerations, a speed-up of up to 3 orders of magnitude can be achieved, while maintaining the same accuracy.
Link: https://arxiv.org/abs/1810.00188
====================================================
An open source massively parallel solver for Richards equation: Mechanistic modelling of water fluxes at the watershed scale (L. Orgogozo - 28 September, 2018)
This solver has been developed in the framework of the open source generalist computational fluid dynamics tool box OpenFOAM (R)  and is capable to deal with large scale problems in both space and time. The source code for RichardsFOAM may be downloaded from the CPC program library website.It exhibits good parallel performances (up to $\sim$90% parallel efficiency with 1024 processors both in strong and weak scaling), and the conditions required for obtaining such performances are analysed and discussed
Link: https://arxiv.org/abs/1809.10895
====================================================
CNN Based Posture-Free Hand Detection (Richard Adiguna - 27 September, 2018)
However the CNN approach is complex and can increase computational time, which at the end reduce its effectiveness on a system where the speed is essential.In this study we propose a shallow CNN network which is fast, and insensitive to translation and hand poses. Our evaluation shows that the proposed shallow CNN network performs at 93.9% accuracy and reaches much faster speed than its competitors.
Link: https://arxiv.org/abs/1809.10432
====================================================
Being Corrupt Requires Being Clever, But Detecting Corruption Doesn't (Yan Jin - 26 September, 2018)
Inspired by real auditing networks, we pose our problem for arbitrary graphs and consider corruption through a computational lens. On the other hand, we prove that for any constant $Î±> 1$, it is NP-hard to find a subset of nodes $S$ in $G$ such that corrupting $S$ prevents the central agency from finding one truthful node and $|S| \leq Î±m(G)$, assuming the Small Set Expansion Hypothesis (Raghavendra and Steurer, STOC '10)
Link: https://arxiv.org/abs/1809.10325
====================================================
Geometry-Aware Network for Non-Rigid Shape Prediction from a Single View (Albert Pumarola - 26 September, 2018)
We evaluate our approach on a test split of this dataset and available real benchmarks, consistently improving state-of-the-art solutions with a significantly lower computational time.
Link: https://arxiv.org/abs/1809.10305
====================================================
Deeply Informed Neural Sampling for Robot Motion Planning (Ahmed H. Qureshi - 26 September, 2018)
DeepSMP is not only consistently computationally efficient in all tested environments but has also shown remarkable generalization to completely unseen environments. The results show that on average our method is at least 7 times faster in point-mass and rigid-body case and about 28 times faster in 6-link robot case than the existing state-of-the-art.
Link: https://arxiv.org/abs/1809.10252
====================================================
Morphed Learning: Towards Privacy-Preserving for Deep Learning Based Applications (Juncheng Shen - 20 September, 2018)
Theoretical analyses on CIFAR-10 dataset and VGG-16 network show that our method is capable of providing 10^89 morphing possibilities with only 5% computational overhead and 10% transmission overhead under limited knowledge attack scenario
Link: https://arxiv.org/abs/1809.09968
====================================================
Fast and Continuous Foothold Adaptation for Dynamic Locomotion through Convolutional Neural Networks (Octavio Villarreal - 25 September, 2018)
Indeed, the computational effort demanded by visual processing limits the potential for realtime control and planning strategies. Our method results in an up to 200 times faster computation with respect to the full-blown heuristics. We assess the performance of our method on the dynamic quadruped robot HyQ, executing static and dynamic gaits (at speeds up to 0.5 m/s) in both simulated and real scenarios; the benefit of safe foothold adaptation is clearly demonstrated by the overall robot behavior.
Link: https://arxiv.org/abs/1809.09759
====================================================
Sampling-based Polytopic Trees for Approximate Optimal Control of Piecewise Affine Systems (Sadra Sadraddini - 25 September, 2018)
Existing control techniques for PWA systems have computational drawbacks, both in offline design and online implementation. The idea is conceptually similar to LQR-trees \cite{tedrake2010lqr}, which consists of 3 steps: (1) open-loop trajectory optimization, (2) feedback control for computation of "funnels" of states around trajectories, and (3) repeating (1) and (2) in a way that the funnels are grown backward from the goal in a tree fashion and fill the state-space as much as possible
Link: https://arxiv.org/abs/1809.09716
====================================================
Nested cross-validation when selecting classifiers is overzealous for most practical applications (Jacques Wainer - 25 September, 2018)
We tested both procedures using 12 different algorithms on 115 real life binary datasets and conclude that using the less computationally expensive flat cross-validation procedure will generally result in the selection of an algorithm that is, for all practical purposes, of similar quality to that selected via nested cross-validation, provided the learning algorithms have relatively few hyperparameters to be optimised.
Link: https://arxiv.org/abs/1809.09446
====================================================
Fast and Simple Mixture of Softmaxes with BPE and Hybrid-LightRNN for Language Generation (Xiang Kong - 24 September, 2018)
Despite the known advantage, MoS is practically sealed by its large consumption of memory and computational time due to the need of computing multiple Softmaxes. With MoS, we achieve an improvement of 1.5 BLEU scores on IWSLT 2014 German-to-English corpus and an improvement of 0.76 CIDEr score on image captioning. Moreover, on the larger WMT 2014 machine translation dataset, our MoS-boosted Transformer yields 29.5 BLEU score for English-to-German and 42.1 BLEU score for English-to-French, outperforming the single-Softmax Transformer by 0.8 and 0.4 BLEU scores respectively and achieving the state-of-the-art result on WMT 2014 English-to-German task.
Link: https://arxiv.org/abs/1809.09296
====================================================
Recognizing Film Entities in Podcasts (Ahmet Salih Gundogdu - 23 September, 2018)
Taking inspiration from NER systems for noisy text in social media, we implement a two-stage approach that is robust to computer transcription errors and does not require significant computational expense to accommodate new film titles/releases. Evaluating on a diverse set of podcasts, we demonstrate more than a 20% increase in F1 score across three baseline approaches when combining fuzzy-matching with a linear model aware of film-specific metadata.
Link: https://arxiv.org/abs/1809.08711
====================================================
Accelerate CU Partition in HEVC using Large-Scale Convolutional Neural Network (Chenying Wang - 23 September, 2018)
In order to alleviate computational complexity further, an auxiliary earl-termination mechanism is also proposed to filter obvious homogeneous CUs out of the subsequent CNN-based algorithm. Experimental results show that the proposed approach achieves about 37% encoding time saving on average and insignificant BD-Bitrate rise compared with the original HEVC encoder.
Link: https://arxiv.org/abs/1809.08617
====================================================
Softer-NMS: Rethinking Bounding Box Regression for Accurate Object Detection (Yihui He - 23 September, 2018)
On MS-COCO, we boost the AP of VGG-16 faster R-CNN from 23.6% to 29.1% with a single model and nearly no additional computational overhead. More importantly, our method is able to improve the AP of ResNet-50 FPN fast R-CNN from 36.8% to 37.8%, which achieves state-of-the-art bounding box refinement result.
Link: https://arxiv.org/abs/1809.08545
====================================================
SLIDER: Fast and Efficient Computation of Banded Sequence Alignment (Mohammed Alser - 18 September, 2018)
We in-troduce SLIDER, a highly parallel and accurate pre-alignment filter that remarkably reduces the need for computationally-costly dynamic programming algorithms. The addition of SLIDER as a pre-alignment step reduces the execution time of five state-of-the-art sequence align-ers by up to 18.8x
Link: https://arxiv.org/abs/1809.07858
====================================================
A Microbenchmark Characterization of the Emu Chick (Jeffrey Young - 7 September, 2018)
The current prototype hardware uses FPGAs to implement cache-less "Gossamer cores for doing computational work and a stationary core to run basic operating system functions and migrate threads between nodes. AsHES 2018) of the the memory bandwidth characteristics of the system through benchmarks like STREAM, pointer chasing, and sparse matrix-vector multiplication. Moreover, the Emu Chick provides stable, predictable performance with up to 65% of the peak bandwidth utilization on a random-access pointer chasing benchmark with weak locality.
Link: https://arxiv.org/abs/1809.07696
====================================================
The Open Vision Computer: An Integrated Sensing and Compute System for Mobile Robots (Morgan Quigley - 20 September, 2018)
In particular our aim was to develop a system that would be suitable for relatively small-scale flying platforms where size, weight, power consumption and computational performance were all important considerations. This manuscript describes the primary features of our OVC system and explains how they are used to support fully autonomous indoor and outdoor exploration and navigation operations on our Falcon 250 quadrotor platform.
Link: https://arxiv.org/abs/1809.07674
====================================================
Throughput-Improving Control of Highways Facing Stochastic Perturbations (Li Jin - 2 October, 2018)
We illustrate the performance benefits of these criteria through a computational study of a segment on Interstate 210 in California, USA.
Link: https://arxiv.org/abs/1809.07610
====================================================
Harmonious Sampling for Mobile Manipulation Planning (Mincheul Kang - 20 September, 2018)
This coupled approach addresses sub-optimality and ncompleteness of the decoupled approach, but has not been widely used due to its excessive computational overhead. Our method shows meaningful improvements experimentally in terms of time to find an initial solution (up to 5 times faster) and final solution cost (up to 30% lower) over these techniques, especially in difficult scenes with narrow passage
Link: https://arxiv.org/abs/1809.07497
====================================================
Exploiting Tournament Selection for Efficient Parallel Genetic Programming (Darren M. Chitty - 19 September, 2018)
Genetic Programming (GP) is a computationally intensive technique which is naturally parallel in nature. Indeed, a 74% improvement in the speed of GP is achieved with a peak rate of 96 billion GPop/s for classification type problems.
Link: https://arxiv.org/abs/1809.07406
====================================================
Faster Training of Mask R-CNN by Focusing on Instance Boundaries (Roland S. Zimmermann - 3 October, 2018)
While the computational costs are increased slightly, the increment is negligible considering the high computational cost of the Mask R-CNN architecture. In a default Mask R-CNN setup, we achieve a training speed up of 29% and an overall improvement of 8.1% on the MS COCO metrics compared to the baseline.
Link: https://arxiv.org/abs/1809.07069
====================================================
Divide and Conquer: Recovering Contextual Information of Behaviors in Android Apps around Limited-quantity Audit Logs (Zhaoyi Meng - 19 September, 2018)
The challenge, however, is that the limited-quantity logs may incur high computational complexity in log matching, where there are a large amount of candidates caused by the coupling relation of successive logs. In our evaluation, DroidHolmes helps existing tools to achieve 94.87% and 100% in precision and recall respectively on 132 apps from open-source test suites. Based on the result of DroidHolmes, the contextual information in the behaviors of 500 real-world apps is also recovered
Link: https://arxiv.org/abs/1809.07036
====================================================
Efficient Dense Modules of Asymmetric Convolution for Real-Time Semantic Segmentation (Shao-Yuan Lo - 17 September, 2018)
In this paper, we propose a novel convolutional network named Efficient Dense modules with Asymmetric convolution (EDANet), which employs an asymmetric convolution structure incorporating the dilated convolution and the dense connectivity to attain high efficiency at low computational cost, inference time, and model size. Compared to FCN, EDANet is 11 times faster and has 196 times fewer parameters, while it achieves a higher the mean of intersection-over-union (mIoU) score without any additional decoder structure, context module, post-processing scheme, and pretrained model. Our network can run on resolution 512x1024 inputs at the speed of 108 and 81 frames per second on a single GTX 1080Ti and Titan X, respectively.
Link: https://arxiv.org/abs/1809.06323
====================================================
Industrial Smoke Detection and Visualization (Yen-Chia Hsu - 17 September, 2018)
Providing easy-to-use computational tools to support citizen science has become an important issue. We have helped the community members build a live camera system which captures and visualizes high resolution timelapse imagery starting from November 2014
Link: https://arxiv.org/abs/1809.06263
====================================================
Highly-Economized Multi-View Binary Compression for Scalable Image Clustering (Zheng Zhang - 16 September, 2018)
Extensive experimental results on four large-scale image datasets show that HSIC consistently outperforms the state-of-the-art approaches, whilst significantly reducing computational time and memory footprint.
Link: https://arxiv.org/abs/1809.05992
====================================================
FermiNets: Learning generative machines to generate efficient neural networks via generative synthesis (Alexander Wong - 16 September, 2018)
Experimental results for image classification, semantic segmentation, and object detection tasks illustrate the efficacy of generative synthesis in producing generators that automatically generate highly efficient deep neural networks (which we nickname FermiNets) with higher model efficiency and lower computational costs (reaching >10x more efficient and fewer multiply-accumulate operations than several tested state-of-the-art networks), as well as higher energy efficiency (reaching >4x improvements in image inferences per joule consumed on a Nvidia Tegra X2 mobile processor)
Link: https://arxiv.org/abs/1809.05989
====================================================
A Generic Multi-modal Dynamic Gesture Recognition System using Machine Learning (Gautham Krishna G - 16 September, 2018)
The proposed system is able to classify gestures performed at varying speeds with minimum preprocessing, making it computationally efficient. Moreover, this system was found to run on a low-cost embedded platform - Raspberry Pi Zero (USD 5), making it economically viable.
Link: https://arxiv.org/abs/1809.05839
====================================================
Spatial Configuration of Agile Wireless Networks with Drone-BSs and User-in-the-loop (Irem Bor-Yaliniz - 14 September, 2018)
Finally, semi-joint SNC combines benefits of joint SNC, with computational efficiency. Numerical results show that semi-joint SNC is two orders of magnitude times faster than joint SNC, and more than 15 percent profit can be obtained compared to conventional systems.
Link: https://arxiv.org/abs/1809.05315
====================================================
Learning to Fingerprint the Latent Structure in Question Articulation (Kumar Mrityunjay - 14 September, 2018)
Abstract Machine understanding of questions is tightly related to recognition of articulation in the context of the computational capabilities of an underlying processing algorithm. Experimental evaluation using many clusters of questions, each related to an objective, shows 80% recognition accuracy and negligible false positive across these clusters of questions. We also demonstrate a refinement scheme called K-fingerprints, that achieves nearly 100% recognition with negligible false positive across the different clusters of questions.
Link: https://arxiv.org/abs/1809.05275
====================================================
Random Warping Series: A Random Features Method for Time-Series Embedding (Lingfei Wu - 14 September, 2018)
Our extensive experiments on 16 benchmark datasets demonstrate that RWS outperforms or matches state-of-the-art classification and clustering methods in both accuracy and computational time
Link: https://arxiv.org/abs/1809.05259
====================================================
Graph Pattern Mining and Learning through User-defined Relations (Extended Version) (Carlos H. C. Teixeira - 13 September, 2018)
We also propose and evaluate optimizations that enable improvements of our estimators accuracy, while reducing their computational costs in up to 3-orders-of-magnitude. Finally,we show that R-GPM is scalable, providing near-linear speedups on 44 cores in all of our tests.
Link: https://arxiv.org/abs/1809.05241
====================================================
A Time Series Graph Cut Image Segmentation Scheme for Liver Tumors (Laramie Paxton - 13 September, 2018)
The proposed method also has the advantage of being relatively simple to implement computationally. It was evaluated against the ground truth on a clinical CT dataset of 10 tumors and yielded segmentations with a mean Dice similarity coefficient (DSC) of .77 and mean volume overlap error (VOE) of 36.7%. The average processing time was 1.25 minutes per slice.
Link: https://arxiv.org/abs/1809.05210
====================================================
Real-Time Lightweight Chaotic Encryption for 5G IoT Enabled Lip-Reading Driven Secure Hearing-Aid (Ahsan Adeel - 13 September, 2018)
To offload the computational complexity and real-time optimization issues, the framework runs deep learning and big data optimization processes in the background on the cloud. Specifically, in this work, three key contributions are reported: (1) 5G IoT enabled secure audio-visual hearing-aid framework that aims to achieve a round-trip latency up to 5ms with 100 Mbps datarate (2) Real-time lightweight audio-visual encryption (3) Lip-reading driven deep learning approach for speech enhancement in the cloud
Link: https://arxiv.org/abs/1809.04966
====================================================
Rapid Training of Very Large Ensembles of Diverse Neural Networks (Abdul Wasay - 12 September, 2018)
However, training such ensembles requires a large amount of computational resources and time as every network in the ensemble has to be separately trained. In particular, our approach trains an ensemble of $100$ variants of deep neural networks with diverse architectures up to $6 \times$ faster as compared to existing approaches
Link: https://arxiv.org/abs/1809.04270
====================================================
Attention based visual analysis for fast grasp planning with multi-fingered robotic hand (Zhen Deng - 11 September, 2018)
Our approach uses a computational visual attention model to locate regions of interest in a scene, and uses a deep convolutional neural network to detect grasp type and point for a sub-region of the object presented in a region of interest. A new Grasp Type Dataset (GTD) that considers 6 commonly used grasp types and covers 12 household objects is also presented.
Link: https://arxiv.org/abs/1809.04226
====================================================
Searching for Efficient Multi-Scale Architectures for Dense Image Prediction (Liang-Chieh Chen - 11 September, 2018)
Additionally, the resulting architecture is more computationally efficient, requiring half the parameters and half the computational cost as previous state of the art systems.
Link: https://arxiv.org/abs/1809.04184
====================================================
The Coin Problem in Constant Depth: Sample Complexity and Parity Gates (Nutan Limaye - 11 September, 2018)
The $\textit{Î´-Coin Problem}$ is the computational problem of distinguishing between coins that are heads with probability $(1+Î´)/2$ or $(1-Î´)/2,$ where $Î´$ is a parameter tending to $0$
Link: https://arxiv.org/abs/1809.04092
====================================================
Hubless keypoint-based 3D deformable groupwise registration (RÃ©mi Agier - 11 September, 2018)
The result is a set of half transforms which link the volumes together and can be subsequently exploited for computational anatomy, landmark detection or image segmentation. We show experimental results on whole-body CT scans, with groups of up to 103 volumes
Link: https://arxiv.org/abs/1809.03951
====================================================
Annotating shadows, highlights and faces: the contribution of a 'human in the loop' for digital art history (Maarten W. A. Wijntjes - 10 September, 2018)
While automatic computational techniques appear to reveal novel insights in digital art history, a complementary approach seems to get less attention: that of human annotation. We found that Canaletto depicted human figures in rather accurate perspective, varied viewpoint elevation between approximately 3 and 9 meters and highly preferred light directions parallel to the projection plane
Link: https://arxiv.org/abs/1809.03539
====================================================
Critically fast pick-and-place with suction cups (Hung Pham - 10 September, 2018)
The main difficulties are: (i) handling the contact between the suction cup and the object, which fundamentally involves kinodynamic constraints, and (ii) doing so at a low computational cost, typically a few hundreds of milliseconds. We experimentally validate the proposed pipeline on a physical robot system: the cycle time for a typical pick-and-place task was less than 5 seconds, planning and execution times included
Link: https://arxiv.org/abs/1809.03151