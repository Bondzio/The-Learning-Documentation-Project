If there are any errors
please Abort, and run `arxiv_required` for required package installation, and start again
Please wait while we phrase the requested information from global arxiv[arxiv.org] servers 
------------>
---------------------------->
------------------------------------------------------>
 
An Initial Step Towards Organ Transplantation Based on GitHub Repository (Shangwen Wang - 10 October, 2018)
Implementing our transplantation strategy for different kinds of organs, we manually extract 30 organs in three different programming languages, namely Java, Python, and C, and make unit tests for them utilizing four testing tools (two for Java, one for Python, and one for C). All the 30 organs extracted by our strategy possess good performances in unit test with the highest passing rate reaching 97% and the lowest one still passing 80% and the three Java organs work well in the new system, providing three new functionalities for the host
Link: https://arxiv.org/abs/1810.04825
====================================================
BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding (Jacob Devlin - 10 October, 2018)
As a result, the pre-trained BERT representations can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications.
Link: https://arxiv.org/abs/1810.04805
====================================================
Multimodal Speech Emotion Recognition Using Audio and Text (Seunghyun Yoon - 10 October, 2018)
This architecture analyzes speech data from the signal level to the language level, and it thus utilizes the information within the data more comprehensively than models that focus on audio features. Our proposed model outperforms previous state-of-the-art methods in assigning data to one of four emotion categories (i.e., angry, happy, sad and neutral) when the model is applied to the IEMOCAP dataset, as reflected by accuracies ranging from 68.8% to 71.8%.
Link: https://arxiv.org/abs/1810.04635
====================================================
DeFind: A Protege Plugin for Computing Concept Definitions in EL Ontologies (Denis Ponomaryov - 10 October, 2018)
The plugin supports ontologies formulated in the Description Logic EL, which underpins the OWL 2 EL profile of the Web Ontology Language and despite its limited expressiveness captures most of the biomedical ontologies published on the Web
Link: https://arxiv.org/abs/1810.04363
====================================================
A Fast, Compact, Accurate Model for Language Identification of Codemixed Text (Yuan Zhang - 9 October, 2018)
We show that a feed-forward network with a simple globally constrained decoder can accurately and rapidly label both codemixed and monolingual text in 100 languages and 100 language pairs. This model outperforms previously published multilingual approaches in terms of both accuracy and speed, yielding an 800x speed-up and a 19.5% averaged absolute gain on three codemixed datasets
Link: https://arxiv.org/abs/1810.04142
====================================================
Multilingual sequence-to-sequence speech recognition: architecture, transfer learning, and language modeling (Jaejin Cho - 4 October, 2018)
In this work, we attempt to use data from 10 BABEL languages to build a multi-lingual seq2seq model as a prior model, and then port them towards 4 other BABEL languages using transfer learning approach. Experimental results show that the transfer learning approach from the multilingual model shows substantial gains over monolingual models across all 4 BABEL languages
Link: https://arxiv.org/abs/1810.03459
====================================================
Active Learning for New Domains in Natural Language Understanding (Stanislav Peshterliev - 3 October, 2018)
We explore active learning (AL) utterance selection for improving the accuracy of new underrepresented domains in a natural language understanding (NLU) system. Experiments with three domains show that Majority-CRF achieves 6.6%-9% relative error rate reduction compared to random sampling with the same annotation budget, and statistically significant improvements compared to other AL approaches. Additionally, case studies with human-in-the-loop AL on six new domains show 4.6%-9% improvement on an existing NLU system.
Link: https://arxiv.org/abs/1810.03450
====================================================
Building a language evolution tree based on word vector combination model (Zhu Gao - 4 October, 2018)
First, we chose the novels of eleven British writers from 1400 to 2005 and found the corresponding works; Then, we use the natural language processing tool to construct the corresponding eleven corpora, and calculate the respective word vectors of 100 high-frequency words in eleven corpora; Next, for each corpus, we concatenate the 100 word vectors from beginning to end into one; Finally, we use the similarity comparison and hierarchical clustering method to generate the relationship tree between the combined eleven word vectors. To verify the stability and versatility of this method, we add three other themes: Dickens's eight works, the 19th century poets' works, and art criticism of recent 60 years
Link: https://arxiv.org/abs/1810.03445
====================================================
Phonology-Augmented Statistical Framework for Machine Transliteration using Limited Linguistic Resources (Gia H. Ngo - 7 October, 2018)
We propose the concept of pseudo-syllables as structures representing how segments of a foreign word are organized according to the syllables of the target language's phonology. We show that the proposed framework outperforms the statistical baseline by up to 44.68% relative, when there are limited training examples (587 entries).
Link: https://arxiv.org/abs/1810.03184
====================================================
Unsupervised Neural Word Segmentation for Chinese via Segmental Language Modeling (Zhiqing Sun - 7 October, 2018)
Our approach explicitly focuses on the segmental nature of Chinese, as well as preserves several properties of language models. As far as we know, we are the first to propose a neural model for unsupervised CWS and achieve competitive performance to the state-of-the-art statistical models on four different datasets from SIGHAN 2005 bakeoff.
Link: https://arxiv.org/abs/1810.03167
====================================================
Gendered behavior as a disadvantage in open source software development (Balazs Vedres - 6 October, 2018)
Using data on entire careers of users from GitHub.com, we develop a measure to capture the gendered pattern of behavior: We use a random forest prediction of being female (as opposed to being male) by behavioral choices in the level of activity, specialization in programming languages, and choice of partners. We find that 84.5% of women's disadvantage (compared to men) in success and 34.8% of their disadvantage in survival are due to the female pattern of their behavior
Link: https://arxiv.org/abs/1810.03005
====================================================
Understanding Recurrent Neural Architectures by Analyzing and Synthesizing Long Distance Dependencies in Benchmark Sequential Datasets (Abhijit Mahalunkar - 6 October, 2018)
At present, the state-of-the-art computational models across a range of sequential data processing tasks, including language modeling, are based on recurrent neural network architectures
Link: https://arxiv.org/abs/1810.02966
====================================================
Integrating Weakly Supervised Word Sense Disambiguation into Neural Machine Translation (Xiao Pu - 5 October, 2018)
This is demonstrated by translation on five language pairs. The improvements are above one BLEU point over strong NMT baselines, +4% accuracy over all ambiguous nouns and verbs, or +20% when scored manually over several challenging words.
Link: https://arxiv.org/abs/1810.02614
====================================================
Neural-Symbolic VQA: Disentangling Reasoning from Vision and Language Understanding (Kexin Yi - 4 October, 2018)
We marry two powerful ideas: deep representation learning for visual recognition and language understanding, and symbolic program execution for reasoning. First, executing programs on a symbolic space is more robust to long program traces; our model can solve complex reasoning tasks better, achieving an accuracy of 99.8% on the CLEVR dataset
Link: https://arxiv.org/abs/1810.02338
====================================================
Zooming Network (Yukun Yan - 4 October, 2018)
Structural information is important in natural language understanding. We applied the proposed model to long text sequence labeling tasks, with performance exceeding baseline model (biLSTM-crf) by 10 F1-measure.
Link: https://arxiv.org/abs/1810.02114
====================================================
Unsupervised Machine Learning of Open Source Russian Twitter Data Reveals Global Scope and Operational Characteristics (Christopher Griffin - 2 October, 2018)
Using natural language processing, manifold learning and Fourier analysis, we identify an operation that includes not only the 2016 US election, but also the French National and both local and national German elections
Link: https://arxiv.org/abs/1810.01466
====================================================
Findings of the E2E NLG Challenge (OndÅej DuÅ¡ek - 2 October, 2018)
This paper summarises the experimental setup and results of the first shared task on end-to-end (E2E) natural language generation (NLG) in spoken dialogue systems. We compare 62 systems submitted by 17 institutions, covering a wide range of approaches, including machine learning architectures -- with the majority implementing sequence-to-sequence models (seq2seq) -- as well as systems based on grammatical rules and templates.
Link: https://arxiv.org/abs/1810.01170
====================================================
Efficient and Accurate Abnormality Mining from Radiology Reports with Customized False Positive Reduction (Nithya Attaluri - 1 October, 2018)
We propose a methodology for approximating image-level labels for radiology studies from associated reports using a general purpose language processing tool for medical concept extraction and sentiment analysis, and simple manually crafted heuristics for false positive reduction. Using this approach, we label more than 175,000 Head CT studies for the presence of 33 features indicative of 11 clinically relevant conditions. For 27 of the 30 keywords that yielded positive results (3 had no occurrences), the lower bound of the confidence intervals created to estimate the percentage of accurately labeled reports was above 85%, with the average being above 95%
Link: https://arxiv.org/abs/1810.00967
====================================================
Automatic Data Expansion for Customer-care Spoken Language Understanding (Shahab Jalalvand - 27 September, 2018)
Spoken language understanding (SLU) systems are widely used in handling of customer-care calls.A traditional SLU system consists of an acoustic model (AM) and a language model (LM) that areused to decode the utterance and a natural language understanding (NLU) model that predicts theintent. Using these n-grams, we find the samples in the out-of-domain corpus that1) contain the desired n-gram and/or 2) have similar intent label. Our results on two divergent experimental setups show that the proposed approachreduces by 30% the absolute classification error rate (CER) comparing to the preliminary modelsand it significantly outperforms the traditional data expansion algorithms such as the ones based onsemi-supervised learning, TF-IDF and embedding vectors.
Link: https://arxiv.org/abs/1810.00670
====================================================
Text Similarity in Vector Space Models: A Comparative Study (Omid Shahmirzadi - 24 September, 2018)
Automatic measurement of semantic text similarity is an important task in natural language processing. Contrary to expectations, the added computational cost of text embedding methods is justified only when: 1) the target text is condensed; and 2) the similarity comparison is trivial
Link: https://arxiv.org/abs/1810.00664
====================================================
Attention-based Encoder-Decoder Networks for Spelling and Grammatical Error Correction (Sina Ahmadi - 21 September, 2018)
In particular, we investigate sequence-to-sequence and attention-based models which have recently shown a higher performance than the state-of-the-art of many language processing problems
Link: https://arxiv.org/abs/1810.00660
====================================================
Text Morphing (Shaohan Huang - 30 September, 2018)
In this paper, we introduce a novel natural language generation task, termed as text morphing, which targets at generating the intermediate sentences that are fluency and smooth with the two input sentences. We conduct experiments with 10 million text morphing sequences which are extracted from the Yelp review dataset
Link: https://arxiv.org/abs/1810.00341
====================================================
Learning Recurrent Binary/Ternary Weights (Arash Ardakani - 28 September, 2018)
On the software side, we evaluate the performance (in terms of accuracy) of our method using long short-term memories (LSTMs) on various sequential models including sequence classification and language modeling. Ultimately, we show that LSTMs with binary/ternary weights can achieve up to 12x memory saving and 10x inference speedup compared to the full-precision implementation on an ASIC platform.
Link: https://arxiv.org/abs/1809.11086
====================================================
Adaptive Input Representations for Neural Language Modeling (Alexei Baevski - 30 September, 2018)
We introduce adaptive input representations for neural language modeling which extend the adaptive softmax of Grave et al. We achieve a new state of the art on the WikiText-103 benchmark of 20.51 perplexity, improving the next best known result by 8.7 perplexity. On the Billion word benchmark, we achieve a state of the art of 24.14 perplexity.
Link: https://arxiv.org/abs/1809.10853
====================================================
Building a Lemmatizer and a Spell-checker for Sorani Kurdish (Shahin Salavati - 27 September, 2018)
We propose a hybrid approach based on the morphological rules and a n-gram language model. The Peyv lemmatizer has shown 86.7% accuracy. As for RÃªnÃ»s, using a lexicon, we have obtained 96.4% accuracy while without a lexicon, the correction system has 87% accuracy
Link: https://arxiv.org/abs/1809.10763
====================================================
Controllable Neural Story Generation via Reinforcement Learning (Pradyumna Tambwekar - 27 September, 2018)
However, stories generated via language models tend to lack direction and coherence. We show that our technique can train a model that generates a story that reaches the goal 94% of the time and reduces model perplexity
Link: https://arxiv.org/abs/1809.10736
====================================================
Semantic Topic Analysis of Traffic Camera Images (Jeffrey Liu - 27 September, 2018)
In this paper, we present a Natural Language Processing (NLP)-inspired approach, entitled Bag-of-Label-Words (BoLW), for analyzing image data sets using exclusively textual labels. To illustrate our approach, we use freeway camera images collected from the Boston area between December 2017-January 2018
Link: https://arxiv.org/abs/1809.10707
====================================================
Adaptive Pruning of Neural Language Models for Mobile Devices (Raphael Tang - 26 September, 2018)
Neural language models (NLMs) exist in an accuracy-efficiency tradeoff space where better perplexity typically comes at the cost of greater computation complexity. At one operating point, one of the techniques is able to provide energy savings of 40% over the state of the art with only a 17% relative increase in perplexity.
Link: https://arxiv.org/abs/1809.10282
====================================================
Information-Weighted Neural Cache Language Models for ASR (Lyan Verwimp - 24 September, 2018)
Neural cache language models (LMs) extend the idea of regular cache language models by making the cache probability dependent on the similarity between the current context and the context of the words in the cache. We obtain a 29.9%/32.1% (validation/test set) relative improvement in perplexity with respect to a baseline LSTM LM on the WikiText-2 dataset, outperforming previous work on neural cache LMs
Link: https://arxiv.org/abs/1809.08826
====================================================
Neural Transductive Learning and Beyond: Morphological Generation in the Minimal-Resource Setting (Katharina Kann - 23 September, 2018)
On a 52-language benchmark dataset, we outperform the previous state of the art by up to 9.71% absolute accuracy.
Link: https://arxiv.org/abs/1809.08733
====================================================
Textually Enriched Neural Module Networks for Visual Question Answering (Khyathi Raghavi Chandu - 23 September, 2018)
Problems at the intersection of language and vision, like visual question answering, have recently been gaining a lot of attention in the field of multi-modal machine learning as computer vision research moves beyond traditional recognition tasks. We achieve 57.1% overall accuracy on the test-dev open-ended questions from the visual question answering (VQA 1.0) real image dataset.
Link: https://arxiv.org/abs/1809.08697
====================================================
Detecting Hate Speech and Offensive Language on Twitter using Machine Learning: An N-gram and TFIDF based Approach (Aditya Gaydhani - 23 September, 2018)
Differentiating hate speech and offensive language is a key challenge in automatic detection of toxic text content. After tuning the model giving the best results, we achieve 95.6% accuracy upon evaluating it on test data
Link: https://arxiv.org/abs/1809.08651
====================================================
Towards Language Agnostic Universal Representations (Armen Aghajanyan - 22 September, 2018)
In this work, we present a method to decouple the language from the problem by learning language agnostic representations and therefore allowing training a model in one language and applying to a different one in a zero shot fashion. We learn these representations by taking inspiration from linguistics and formalizing Universal Grammar as an optimization process (Chomsky, 2014; Montague, 1970)
Link: https://arxiv.org/abs/1809.08510
====================================================
Cascade Attention Network for Person Search: Both Image and Text-Image Similarity Selection (Ya Jing - 22 September, 2018)
Person search with natural language aims to retrieve the corresponding person in an image database by virtue of a describing sentence about the person, which poses great potential for many applications, e.g., video surveillance. In the CAN, a pose-guided attention is first proposed to attend to the person in the augmented input which concatenates original 3 image channels with another 14 pose confidence maps
Link: https://arxiv.org/abs/1809.08440
====================================================
The Privacy Policy Landscape After the GDPR (Thomas Linden - 22 September, 2018)
We create a diverse corpus of 3,086 English-language privacy policies for which we fetch the pre-GPDR and the post-GDPR versions. Via a user study with 530 participants on Amazon Mturk, we discover that the visual presentation of privacy policies has slightly improved in limited data-sensitive categories in addition to the top European websites. We also find that the readability of privacy policies suffers under the GDPR, due to almost a 30% more sentences and words, despite the efforts to reduce the reliance on passive sentences. We find evidence for positive changes triggered by the GDPR, with the ambiguity level, averaged over 8 metrics, improving in over 20.5% of the policies. Finally, we show that privacy policies cover more data practices, particularly around data retention, user access rights, and specific audiences, and that an average of 15.2% of the policies improved across 8 compliance metrics
Link: https://arxiv.org/abs/1809.08396
====================================================
Augmenting Input Method Language Model with user Location Type Information (Di He - 21 September, 2018)
An LSTM based prediction experiment found a 2% edge in the accuracy from language models leveraging location type information when compared to a baseline without that information.
Link: https://arxiv.org/abs/1809.08349
====================================================
Generating GraphQL-Wrappers for REST(-like) APIs (Erik Wittern - 21 September, 2018)
GraphQL is a query language and thereupon-based paradigm for implementing web Application Programming Interfaces (APIs) for client-server interactions. We evaluate OASGraph by running it, as well as an existing open source alternative, against 959 publicly available OAS. This experiment shows that OASGraph outperforms the existing alternative and is able to create a GraphQL wrapper for 89.5% of the APIs -- however, with limitations in many cases
Link: https://arxiv.org/abs/1809.08319
====================================================
Aspects on Finding the Optimal Practical Programming Exercise for MOOCs (Ralf Teusner - 21 September, 2018)
Massive Open Online Courses (MOOCs) focus on manifold subjects, ranging from social sciences over languages to technical skills, and use different means to train the respective skills. Based on over 3 million executions and scoring runs of participants' task submissions, we aim to deduct exercise difficulty, student patterns in approaching the tasks and potential flaws in task descriptions and preparatory videos
Link: https://arxiv.org/abs/1809.08056
====================================================
Predicting the Programming Language of Questions and Snippets of StackOverflow Using Natural Language Processing (Kamel Alreshedy - 21 September, 2018)
The classifier achieves an accuracy of 91.1% in predicting the 24 most popular programming languages by combining features from the title, body and the code snippets of the question. We also propose a classifier that only uses the title and body of the question and has an accuracy of 81.1%. Finally, we propose a classifier of code snippets only that achieves an accuracy of 77.7%
Link: https://arxiv.org/abs/1809.07954
====================================================
SCC: Automatic Classification of Code Snippets (Kamel Alreshedy - 21 September, 2018)
In this paper, we describe Source Code Classification (SCC), a classifier that can identify the programming language of code snippets written in 21 different programming languages. It is shown to achieve an accuracy of 75% which is higher than that with Programming Languages Identification (PLI a proprietary online classifier of snippets) whose accuracy is only 55.5%. The average score for precision, recall and the F1 score with the proposed tool are 0.76, 0.75 and 0.75, respectively. In addition, it can distinguish between code snippets from a family of programming languages such as C, C++ and C#, and can also identify the programming language version such as C# 3.0, C# 4.0 and C# 5.0.
Link: https://arxiv.org/abs/1809.07945
====================================================
LaSOT: A High-quality Benchmark for Large-scale Single Object Tracking (Heng Fan - 20 September, 2018)
Moreover, considering the close connections of visual appearance and natural language, we enrich LaSOT by providing additional language specification, aiming at encouraging the exploration of natural linguistic feature for tracking. A thorough experimental evaluation of 35 tracking algorithms on LaSOT is presented with detailed analysis, and the results demonstrate that there is still a big room to improvements
Link: https://arxiv.org/abs/1809.07845
====================================================
Fighting Redundancy and Model Decay with Embeddings (Dan Shiebler - 18 September, 2018)
Every day, hundreds of millions of new Tweets containing over 40 languages of ever-shifting vernacular flow through Twitter
Link: https://arxiv.org/abs/1809.07703
====================================================
Joint Multilingual Supervision for Cross-lingual Entity Linking (Shyam Upadhyay - 20 September, 2018)
Extensive evaluation on three benchmark datasets across 8 languages shows that our approach significantly improves over the current state-of-the-art
Link: https://arxiv.org/abs/1809.07657
====================================================
DroidBugs: An Android Benchmark for Automatic Program Repair (Larissa Azevedo - 19 September, 2018)
Many APR techniques, for different programming language and platforms, have been proposed and evaluated on several Benchmarks. Therefore, regarding the amount of Android Applications around the world, we present DroidBugs, an introductory benchmark based on the analyzes of 360 open projects for Android, each of them with more than 5,000 downloads. From five applications, DroidBugs contains 13 single-bugs classified by the type of test that exposed them
Link: https://arxiv.org/abs/1809.07353
====================================================
On the Maintenance of Classic Modula-2 Compilers (Benjamin Kowarsch - 19 September, 2018)
The classic Modula-2 language was specified in [Wir78] by N.Wirth at ETH ZÃ¼rich in 1978. The last revision [Wir88] was published in 1988
Link: https://arxiv.org/abs/1809.07080
====================================================
Generating 3D Adversarial Point Clouds (Chong Xiang - 19 September, 2018)
Recently, adversarial examples have been extensively studied for 2D image, natural language and audio datasets, while the robustness of 3D models has not yet been explored. In addition, we propose 7 perturbation measurement metrics tailored to different attacks and conduct extensive experiments to evaluate the proposed algorithms on the ModelNet40 dataset. Overall, our attack algorithms achieve about 100% attack success rate for all targeted attacks.
Link: https://arxiv.org/abs/1809.07016
====================================================
Extreme Scale De Novo Metagenome Assembly (Evangelos Georganas - 19 September, 2018)
MetaHipMer is end-to-end parallelized using the Unified Parallel C language and therefore can run seamlessly on shared and distributed-memory systems. We demonstrate the unprecedented capability of MetaHipMer by computing the first full assembly of the Twitchell Wetlands dataset, consisting of 7.5 billion reads - size 2.6 TBytes.
Link: https://arxiv.org/abs/1809.07014
====================================================
Document Informed Neural Autoregressive Topic Models with Distributional Prior (Pankaj Gupta - 15 September, 2018)
Here, we extend a neural autoregressive topic model to exploit the full context information around words in a document in a language modeling fashion. We present novel neural autoregressive topic model variants that consistently outperform state-of-the-art generative topic models in terms of generalization, interpretability (topic coherence) and applicability (retrieval and classification) over 6 long-text and 8 short-text datasets from diverse domains.
Link: https://arxiv.org/abs/1809.06709
====================================================
User Information Augmented Semantic Frame Parsing using Coarse-to-Fine Neural Networks (Yilin Shen - 18 September, 2018)
Semantic frame parsing is a crucial component in spoken language understanding (SLU) to build spoken dialog systems. The results show that our approach leverages such simple user information to outperform state-of-the-art approaches by 0.25% for intent detection and 0.31% for slot filling using standard training data. When using smaller training data, the performance improvement on intent detection and slot filling reaches up to 1.35% and 1.20% respectively. We also show that our approach can achieve similar performance as state-of-the-art approaches by using less than 80% annotated training data. Moreover, the training time to achieve the similar performance is also reduced by over 60%.
Link: https://arxiv.org/abs/1809.06559
====================================================
Dual Dense Encoding for Zero-Example Video Retrieval (Jianfeng Dong - 17 September, 2018)
In such a retrieval paradigm, an end user searches for unlabeled videos by ad-hoc queries described in natural language text with no visual example provided. As experiments on three benchmarks, i.e., MSR-VTT, TRECVID 2016 and 2017 Ad-hoc Video Search show, the proposed method establishes a new state-of-the-art for zero-example video retrieval.
Link: https://arxiv.org/abs/1809.06181
====================================================
Best-case and Worst-case Sparsifiability of Boolean CSPs (Hubie Chen - 17 September, 2018)
For NP-complete Boolean CSPs whose constraints are symmetric (the satisfaction depends only on the number of 1 values in the assignment, not on their positions), we give a complete characterization of which constraint languages allow for a linear sparsification
Link: https://arxiv.org/abs/1809.06171
====================================================
Open Subtitles Paraphrase Corpus for Six Languages (Mathias Creutz - 17 September, 2018)
For each target language, the Opusparcus data have been partitioned into three types of data sets: training, development and test sets. The development and test sets consist of sentence pairs that have been checked manually; each set contains approximately 1000 sentence pairs that have been verified to be acceptable paraphrases by two annotators.
Link: https://arxiv.org/abs/1809.06142
====================================================
AlSub: Fully Parallel Subdivision for Modeling and Rendering (Daniel Mlakar - 1 October, 2018)
Subdivision algorithms are written in the language of linear algebra with customized operators which readily demonstrate a performance edge over existing approaches. To substantiate the versatility of our approach we apply it to $\sqrt{3}$, Loop and Catmull-Clark subdivision schemes and show support for adaptive subdivision, semi-sharp creases, and a split evaluation scheme that separates topology and topological changes from positional updates
Link: https://arxiv.org/abs/1809.06047
====================================================
Comparison of Deep Learning and the Classical Machine Learning Algorithm for the Malware Detection (Mohit Sewak - 16 September, 2018)
Recently, Deep Learning has been showing promising results in various Artificial Intelligence applications like image recognition, natural language processing, language modeling, neural machine translation, etc. We studied the performance of the classical RF and DNN with 2, 4 & 7 layers architectures with the four different feature sets, and found that irrespective of the features inputs, the classical RF accuracy outperforms the DNN.
Link: https://arxiv.org/abs/1809.05889
====================================================
Development of deep learning algorithms to categorize free-text notes pertaining to diabetes: convolution neural networks achieve higher accuracy than support vector machines (Boyi Yang - 16 September, 2018)
Health professionals can use natural language processing (NLP) technologies when reviewing electronic health records (EHR). The convolutional neural network (CNN) model with a separable convolution layer accurately identified diabetes-related notes in the Brigham and Womens Hospital testing set with the highest AUC of 0.975
Link: https://arxiv.org/abs/1809.05814
====================================================
IncSQL: Training Incremental Text-to-SQL Parsers with Non-Deterministic Oracles (Tianze Shi - 1 October, 2018)
We present a sequence-to-action parsing approach for the natural language to SQL task that incrementally fills the slots of a SQL query with feasible actions from a pre-defined inventory. We evaluate our models on the WikiSQL dataset and achieve an execution accuracy of 83.7% on the test set, a 2.1% absolute improvement over the models trained with traditional static oracles assuming a single correct target SQL query. When further combined with the execution-guided decoding strategy, our model sets a new state-of-the-art performance at an execution accuracy of 87.1%.
Link: https://arxiv.org/abs/1809.05054
====================================================
XNLI: Evaluating Cross-lingual Sentence Representations (Alexis Conneau - 13 September, 2018)
In this work, we construct an evaluation set for XLU by extending the development and test sets of the Multi-Genre Natural Language Inference Corpus (MultiNLI) to 15 languages, including low-resource languages such as Swahili and Urdu
Link: https://arxiv.org/abs/1809.05053
====================================================
Learning to Summarize Radiology Findings (Yuhao Zhang - 8 October, 2018)
The Impression section of a radiology report summarizes crucial radiology findings in natural language and plays a central role in communicating these findings to physicians. In a blind experiment, a board-certified radiologist indicated that 67% of sampled system summaries are at least as good as the corresponding human-written summaries, suggesting significant clinical validity
Link: https://arxiv.org/abs/1809.04698
====================================================
Solving Sinhala Language Arithmetic Problems using Neural Networks (W. M. T Chathurika - 11 September, 2018)
A methodology is presented to solve Arithmetic problems in Sinhala Language using a Neural Network. Mahoshadha2 learns to solve arithmetic problems with the accuracy of 76%.
Link: https://arxiv.org/abs/1809.04557
====================================================
The Wisdom of MaSSeS: Majority, Subjectivity, and Semantic Similarity in the Evaluation of VQA (Shailza Jolly - 12 September, 2018)
In its standard form, the VQA task is operationalized as follows: Given an image and an open-ended question in natural language, systems are required to provide a suitable answer. Currently, model performance is evaluated by means of a somehow simplistic metric: If the predicted answer is chosen by at least 3 human annotators out of 10, then it is 100% correct
Link: https://arxiv.org/abs/1809.04344
====================================================
Generalizing Word Embeddings using Bag of Subwords (Jinman Zhao - 12 September, 2018)
Experiments show that our model achieves state-of-the-art performances in English word similarity task and in joint prediction of part-of-speech tag and morphosyntactic attributes in 23 languages, suggesting our model's ability in capturing the relationship between words' textual representations and their embeddings.
Link: https://arxiv.org/abs/1809.04259
====================================================
Multimodal neural pronunciation modeling for spoken languages with logographic origin (Minh Nguyen - 11 September, 2018)
In this work, we propose a multimodal approach to predict the pronunciation of Cantonese logographic characters, using neural networks with a geometric representation of logographs and pronunciation of cognates in historically related languages. The proposed framework improves performance by 18.1% and 25.0% respective to unimodal and multimodal baselines.
Link: https://arxiv.org/abs/1809.04203
====================================================
DNN Dataflow Choice Is Overrated (Xuan Yang - 10 September, 2018)
To fairly compare these different approaches, we modified the Halide compiler to produce hardware as well as CPU and GPU code, and show that Halide's existing scheduling language has enough power to represent all existing dense DNN accelerators. Adding an additional level in the memory hierarchy saves an additional 25%
Link: https://arxiv.org/abs/1809.04070
====================================================
AWE: Asymmetric Word Embedding for Textual Entailment (Tengfei Ma - 12 September, 2018)
Textual entailment is a fundamental task in natural language processing. It is noteworthy that the proposed AWE-DeIsTe model can get 2.1% accuracy improvement over prior state-of-the-art on SciTail.
Link: https://arxiv.org/abs/1809.04047
====================================================
Studying the History of the Arabic Language: Language Technology and a Large-Scale Historical Corpus (Yonatan Belinkov - 11 September, 2018)
In this work, we present a large-scale historical corpus of the written Arabic language, spanning 1400 years
Link: https://arxiv.org/abs/1809.03891
====================================================
How much should you ask? On the question structure in QA systems (Dominika Basaj - 11 September, 2018)
Datasets that boosted state-of-the-art solutions for Question Answering (QA) systems prove that it is possible to ask questions in natural language manner
Link: https://arxiv.org/abs/1809.03734
====================================================
Unsupervised Cross-lingual Transfer of Word Embedding Spaces (Ruochen Xu - 10 September, 2018)
Our evaluation on benchmark datasets for bilingual lexicon induction and cross-lingual word similarity prediction shows stronger or competitive performance of the proposed method compared to other state-of-the-art supervised and unsupervised baseline methods over many language pairs.
Link: https://arxiv.org/abs/1809.03633
====================================================
Multi-view Models for Political Ideology Detection of News Articles (Vivek Kulkarni - 10 September, 2018)
Our model draws on advances in representation learning in natural language processing and network science to capture cues from both textual content and the network structure of news articles. We empirically evaluate our model against a battery of baselines and show that our model outperforms state of the art by 10 percentage points F1 score.
Link: https://arxiv.org/abs/1809.03485
====================================================
Jointly Learning to See, Ask, and GuessWhat (Aashish Venkatesh - 10 September, 2018)
We are interested in understanding how the ability to ground language in vision interacts with other abilities at play in dialogue, such as asking a series of questions to obtain the necessary information to perform a certain task. We show that the introduction of our new architecture combined with these learning regimes yields an increase of 19.5% in task success accuracy with respect to a baseline model that treats submodules independently
Link: https://arxiv.org/abs/1809.03408
====================================================
Multilingual Extractive Reading Comprehension by Runtime Machine Translation (Akari Asai - 10 September, 2018)
Experimental results in two non-English languages, namely Japanese and French, show that our method significantly outperforms a back-translation baseline of a state-of-the-art product-level machine translation system
Link: https://arxiv.org/abs/1809.03275
====================================================
SHOMA at Parseme Shared Task on Automatic Identification of VMWEs: Neural Multiword Expression Tagging with High Generalisation (Shiva Taslimipoor - 9 September, 2018)
It outperformed all participating systems in both open and closed tracks with the overall macro-average MWE-based F1 score of 58.09 averaged among all languages
Link: https://arxiv.org/abs/1809.03056
====================================================
Accelerating Viterbi Algorithm using Custom Instruction Approach (Waqar Ahmad - 8 September, 2018)
In this paper, we propose to utilize the custom instruction approach to efficiently implement the widely used Viterbi decoding algorithm by adding the assembly language instructions to the ISA of DLX, PicoJava II and NIOS II processors, which represent RISC, stack and FPGA-based soft-core processor architectures, respectively. By using the custom instruction approach, the execution time of the Viterbi algorithm is significantly improved by approximately 3 times for DLX and PicoJava II, and by 2 times for NIOS II.
Link: https://arxiv.org/abs/1809.02887
====================================================
Extracting and Analyzing Semantic Relatedness between Cities Using News Articles (Yingjie Hu - 8 September, 2018)
This framework is based on a natural language processing model and employs a machine learning process to identify the main topics of news articles. We describe the overall structure of this framework and its individual modules, and then apply it to an experimental dataset with more than 500,000 news articles covering the top 100 U.S
Link: https://arxiv.org/abs/1809.02823
====================================================
Multi-label Classification of User Reactions in Online News (Zacarias Curi - 8 September, 2018)
The increase in the number of Internet users and the strong interaction brought by Web 2.0 made the Opinion Mining an important task in the area of natural language processing
Link: https://arxiv.org/abs/1809.02811
====================================================
Can a Suit of Armor Conduct Electricity? A New Dataset for Open Book Question Answering (Todor Mihaylov - 8 September, 2018)
While existing QA datasets over documents or knowledge bases, being generally self-contained, focus on linguistic understanding, OpenBookQA probes a deeper understanding of both the topic---in the context of common knowledge---and the language it is expressed in. Human performance on OpenBookQA is close to 92%, but many state-of-the-art pre-trained QA methods perform surprisingly poorly, worse than several simple neural baselines we develop
Link: https://arxiv.org/abs/1809.02789
====================================================
Meteorologists and Students: A resource for language grounding of geographical descriptors (Alejandro Ramos-Soto - 7 September, 2018)
We present a data resource which can be useful for research purposes on language grounding tasks in the context of geographical referring expression generation. The resource is composed of two data sets that encompass 25 different geographical descriptors and a set of associated graphical representations, drawn as polygons on a map by two groups of human subjects: teenage students and expert meteorologists.
Link: https://arxiv.org/abs/1809.02494
====================================================
Multitask and Multilingual Modelling for Lexical Analysis (Johannes Bjerva - 7 September, 2018)
A large selection of NLP tasks is investigated for a substantial language sample comprising 60 languages
Link: https://arxiv.org/abs/1809.02428
====================================================
Cell-aware Stacked LSTMs for Modeling Sentences (Jihun Choi - 6 September, 2018)
We dub this architecture Cell-aware Stacked LSTM (CAS-LSTM) and show from experiments that our models achieve state-of-the-art results on benchmark datasets for natural language inference, paraphrase detection, and sentiment classification.
Link: https://arxiv.org/abs/1809.02279
====================================================
82 Treebanks, 34 Models: Universal Dependency Parsing with Multi-Treebank Models (Aaron Smith - 6 September, 2018)
Instead of training a single parsing model for each treebank, we trained models with multiple treebanks for one language or closely related languages, greatly reducing the number of models. On the official test run, we ranked 7th of 27 teams for the LAS and MLAS metrics
Link: https://arxiv.org/abs/1809.02237
====================================================
Character-Aware Decoder for Neural Machine Translation (Adithya Renduchintala - 11 September, 2018)
We experiment on the TED multi-target dataset, translating English into 14 typologically diverse languages
Link: https://arxiv.org/abs/1809.02223
====================================================
Upcycle Your OCR: Reusing OCRs for Post-OCR Text Correction in Romanised Sanskrit (Amrith Krishna - 6 September, 2018)
Owing to the lack of resources our approach uses OCR models trained for other languages written in Roman. So, we bootstrap a dataset of 430 images, scanned in two different settings and their corresponding ground truth. We find that the use of copying mechanism (Gu et al., 2016) yields a percentage increase of 7.69 in Character Recognition Rate (CRR) than the current state of the art model in solving monotone sequence-to-sequence tasks (Schnober et al., 2016). We find that our system is robust in combating OCR-prone errors, as it obtains a CRR of 87.01% from an OCR output with CRR of 35.76% for one of the dataset settings
Link: https://arxiv.org/abs/1809.02147
====================================================
Evaluating Syntactic Properties of Seq2seq Output with a Broad Coverage HPSG: A Case Study on Machine Translation (Johnny Tian-Zheng Wei - 6 September, 2018)
However, the syntactic properties of the language generated from these models are not well understood. Over 93\% of the model translations are parseable, suggesting that it learns to generate conforming to a grammar
Link: https://arxiv.org/abs/1809.02035
====================================================
Code-switched Language Models Using Dual RNNs and Same-Source Pretraining (Saurabh Garg - 6 September, 2018)
We propose two techniques that significantly improve these LMs: 1) A novel recurrent neural network unit with dual components that focus on each language in the code-switched text separately 2) Pretraining the LM using synthetic text from a generative model estimated using the training data
Link: https://arxiv.org/abs/1809.01962
====================================================
Cascaded Mutual Modulation for Visual Reasoning (Yiqun Yao - 6 September, 2018)
Experiments show that CMM significantly outperforms most related models, and reach state-of-the-arts on two visual reasoning benchmarks: CLEVR and NLVR, collected from both synthetic and natural languages
Link: https://arxiv.org/abs/1809.01943
====================================================
Describing a Knowledge Base (Qingyun Wang - 30 September, 2018)
We also create a new data set which includes 106,216 pairs of structured KBs and their corresponding natural language descriptions for two distinct entity types. The reconstructed KB achieves 68.8% - 72.6% F-score.
Link: https://arxiv.org/abs/1809.01797
====================================================
Accelerated Reinforcement Learning for Sentence Generation by Vocabulary Prediction (Kazuma Hashimoto - 5 September, 2018)
A major obstacle in reinforcement learning-based sentence generation is the large action space whose size is equal to the vocabulary size of the target-side language. In our experiments on six machine translation and two image captioning datasets, our method achieves faster reinforcement learning ($\sim$2.7x faster) with much less GPU memory ($\sim$10x less) than the full-vocabulary counterpart. The reinforcement learning with our method consistently leads to significant improvement of BLEU scores, and the scores are equal to or better than those of baselines using the full vocabularies, with faster decoding time ($\sim$3x faster) on CPUs.
Link: https://arxiv.org/abs/1809.01694
====================================================
Multimodal Dialogue Management for Multiparty Interaction with Infants (Setareh Nasihati Gilani - 5 September, 2018)
The ultimate purpose of this research is to help infants learn a visual sign language by engaging them in naturalistic and socially contingent conversations during an early-life critical period for language development (ages 6 to 12 months) as initiated by an artificial agent. The present version of the system was evaluated in interaction with 8 babies
Link: https://arxiv.org/abs/1809.01581
====================================================
Utilizing Character and Word Embeddings for Text Normalization with Sequence-to-Sequence Models (Daniel Watson - 5 September, 2018)
We show that providing the model with word-level features bridges the gap for the neural network approach to achieve a state-of-the-art F1 score on a standard Arabic language correction shared task dataset.
Link: https://arxiv.org/abs/1809.01534
====================================================
A Reinforcement Learning-driven Translation Model for Search-Oriented Conversational Systems (Wafa Aissa - 29 August, 2018)
Search-oriented conversational systems rely on information needs expressed in natural language (NL). We propose a reinforcement-learning-driven translation model framework able to 1) learn the translation from NL expressions to queries in a supervised way, and, 2) to overcome the lack of large-scale dataset by framing the translation model as a word selection approach and injecting relevance feedback in the learning process
Link: https://arxiv.org/abs/1809.01495
====================================================
Free as in Free Word Order: An Energy Based Model for Word Segmentation and Morphological Tagging in Sanskrit (Amrith Krishna - 5 September, 2018)
The configurational information in sentences of a free word order language such as Sanskrit is of limited use. Our model outperforms the state of the art with an F-Score of 96.92 (percentage improvement of 7.06%) while using less than one-tenth of the task-specific training data. We find that the use of a graph based ap- proach instead of a traditional lattice-based sequential labelling approach leads to a percentage gain of 12.6% in F-Score for the segmentation task.
Link: https://arxiv.org/abs/1809.01446
====================================================
Pre-training on high-resource speech recognition improves low-resource speech-to-text translation (Sameer Bansal - 5 September, 2018)
We present a simple approach to improve direct speech-to-text translation (ST) when the source language is low-resource: we pre-train the model on a high-resource automatic speech recognition (ASR) task, and then fine-tune its parameters for ST. We demonstrate that our approach is effective by pre-training on 300 hours of English ASR data to improve Spanish-English ST from 10.8 to 20.2 BLEU when only 20 hours of Spanish-English ST training data is available. Finally, we show that the approach improves a true low-resource task: pre-training on a combination of English ASR and French ASR improves Mboshi-French ST, where only 4 hours of data are available, from 3.5 to 7.1 BLEU.
Link: https://arxiv.org/abs/1809.01431
====================================================
RNNs as psycholinguistic subjects: Syntactic state and grammatical dependency (Richard Futrell - 5 September, 2018)
Recurrent neural networks (RNNs) are the state of the art in sequence modeling for natural language
Link: https://arxiv.org/abs/1809.01329
====================================================
BPE and CharCNNs for Translation of Morphology: A Cross-Lingual Comparison and Analysis (Pamela Shapiro - 8 September, 2018)
We translate from 8 languages into English, using a multi-way parallel collection of TED transcripts
Link: https://arxiv.org/abs/1809.01301
====================================================
Unsupervised Statistical Machine Translation (Mikel Artetxe - 4 September, 2018)
Our method profits from the modular architecture of SMT: we first induce a phrase table from monolingual corpora through cross-lingual embedding mappings, combine it with an n-gram language model, and fine-tune hyperparameters through an unsupervised MERT variant. In addition, iterative backtranslation improves results further, yielding, for instance, 14.08 and 26.22 BLEU points in WMT 2014 English-German and English-French, respectively, an improvement of more than 7-10 BLEU points over previous unsupervised systems, and closing the gap with supervised SMT (Moses trained on Europarl) down to 2-5 BLEU points
Link: https://arxiv.org/abs/1809.01272
====================================================
t-Exponential Memory Networks for Question-Answering Machines (Kyriakos Tolias - 4 September, 2018)
We perform an extensive experimental evaluation of our approach, using challenging language modeling benchmarks, and illustrate its superiority over existing state-of-the-art techniques.
Link: https://arxiv.org/abs/1809.01229
====================================================
Text2Scene: Generating Abstract Scenes from Textual Descriptions (Fuwen Tan - 4 September, 2018)
These scene representations can be sampled from our model similarly as in language-generation models. Human evaluations using a visual entailment task show that pictorial representations generated with our full model can entail at least one out of three input visual descriptions 94% of the times, and at least two out of three 62% of the times for each image.
Link: https://arxiv.org/abs/1809.01110
====================================================
Texar: A Modularized, Versatile, and Extensible Toolkit for Text Generation (Zhiting Hu - 4 September, 2018)
We introduce Texar, an open-source toolkit aiming to support the broad set of text generation tasks that transforms any inputs into natural language, such as machine translation, summarization, dialog, content manipulation, and so forth. Texar is released under Apache license 2.0 at https://github.com/asyml/texar.
Link: https://arxiv.org/abs/1809.00794
====================================================
NTUA-SLP at IEST 2018: Ensemble of Neural Transfer Methods for Implicit Emotion Classification (Alexandra Chronopoulou - 3 September, 2018)
We leverage a big collection of unlabeled Twitter messages, for pretraining word2vec word embeddings and a set of diverse language models. Our team ranked 3rd out of 30 participants, achieving an F1 score of 0.703.
Link: https://arxiv.org/abs/1809.00717
====================================================
Deductive Verification of Unmodified Linux Kernel Library Functions (Denis Efremov - 3 September, 2018)
The correctness of 23 functions was completely proved using AstraVer toolset, although success for 11 functions was achieved using 2 new specification language constructs. Another 2 functions were proved after a minor modification of their source code, while the final one cannot be completely proved using the existing memory model
Link: https://arxiv.org/abs/1809.00626
====================================================
Data Augmentation for Neural Online Chat Response Selection (Wenchao Du - 2 September, 2018)
We investigate two data augmentation proxies, permutation and flipping, for neural dialog response selection task on various models over multiple datasets, including both Chinese and English languages. Empirical results show that our approach can gain 1 to 3 recall-at-1 points over baseline models in both full-scale and small-scale settings.
Link: https://arxiv.org/abs/1809.00428
====================================================
Neural Character-based Composition Models for Abuse Detection (Pushkar Mishra - 2 September, 2018)
The current state of the art approaches to abusive language detection, based on recurrent neural networks, do not explicitly address this problem and resort to a generic OOV (out of vocabulary) embedding for unseen words
Link: https://arxiv.org/abs/1809.00378
====================================================
A Multilingual Information Extraction Pipeline for Investigative Journalism (Gregor Wiedemann - 1 September, 2018)
In contrast to comparable projects, we focus on the following three major requirements particularly serving the use case of investigative journalism in cross-border collaborations: 1) composition of multiple state-of-the-art NLP tools for entity extraction, 2) support of multi-lingual document sets up to 40 languages, 3) fast and easy-to-use extraction of full-text, metadata and entities from various file formats.
Link: https://arxiv.org/abs/1809.00221
====================================================
Microsoft's Submission to the WMT2018 News Translation Task: How I Learned to Stop Worrying and Love the Data (Marcin Junczys-Dowmunt - 1 September, 2018)
We participated in one language direction -- English-German. According to automatic metrics (BLEU) we reached the highest score for this subtask with a nearly 2 BLEU point margin over the next strongest system
Link: https://arxiv.org/abs/1809.00196
====================================================
Dependency-based Hybrid Trees for Semantic Parsing (Zhanming Jie - 31 August, 2018)
Unlike previous state-of-the-art models, the semantic information is interpreted as the latent dependency between the natural language words in our joint representation. Through extensive experiments on the standard multilingual GeoQuery dataset with eight languages, we demonstrate that our proposed approach is able to achieve state-of-the-art performance across several languages
Link: https://arxiv.org/abs/1809.00107
====================================================
What do RNN Language Models Learn about Filler-Gap Dependencies? (Ethan Wilcox - 31 August, 2018)
RNN language models have achieved state-of-the-art perplexity results and have proven useful in a suite of NLP tasks, but it is as yet unclear what syntactic generalizations they learn. Here we investigate whether state-of-the-art RNN language models represent long-distance filler-gap dependencies and constraints on them
Link: https://arxiv.org/abs/1809.00042
====================================================
Wasabi: A Framework for Dynamically Analyzing WebAssembly (Daniel Lehmann - 31 August, 2018)
Unfortunately, building such tools from scratch requires knowledge of low-level details of the language, and perhaps even its runtime environment. Our evaluation on compute-intensive benchmarks and real-world applications shows that Wasabi (i) faithfully preserves the original program behavior, (ii) imposes an overhead that is reasonable for heavyweight dynamic analysis (depending on the program and the analyzed instructions, between 1.02x and 163x), and (iii) makes it straightforward to implement various dynamic analyses, including instruction counting, call graph extraction, memory access tracing, and taint analysis.
Link: https://arxiv.org/abs/1808.10652
====================================================
Comparative Studies of Detecting Abusive Language on Twitter (Younghun Lee - 30 August, 2018)
Previously studied datasets in abusive language detection have been insufficient in size to efficiently train deep learning models. Experimental results show that bidirectional GRU networks trained on word-level features, with Latent Topic Clustering modules, is the most accurate model scoring 0.805 F1.
Link: https://arxiv.org/abs/1808.10245
====================================================
Direct Output Connection for a High-Rank Language Model (Sho Takase - 30 August, 2018)
This paper proposes a state-of-the-art recurrent neural network (RNN) language model that combines probability distributions computed not only from a final RNN layer but also from middle layers. The proposed method improves the current state-of-the-art language model and achieves the best score on the Penn Treebank and WikiText-2, which are the standard benchmark datasets
Link: https://arxiv.org/abs/1808.10143
====================================================
Zero-Shot Adaptive Transfer for Conversational Language Understanding (Sungjin Lee - 29 August, 2018)
Conversational agents such as Alexa and Google Assistant constantly need to increase their language understanding capabilities by adding new domains. Extensive experimentation over a dataset of 10 domains relevant to our commercial personal digital assistant shows that our model outperforms previous state-of-the-art systems by a large margin, and achieves an even higher improvement in the low data regime.
Link: https://arxiv.org/abs/1808.10059
====================================================
Grammar Induction with Neural Language Models: An Unusual Replication (Phu Mon Htut - 29 August, 2018)
(2018) introduce such a model and report near-state-of-the-art results on the target task of language modeling, and the first strong latent tree learning result on constituency parsing
Link: https://arxiv.org/abs/1808.10000
====================================================
Neural Cross-Lingual Named Entity Recognition with Minimal Resources (Jiateng Xie - 11 September, 2018)
We demonstrate that these methods achieve state-of-the-art or competitive NER performance on commonly tested languages under a cross-lingual setting, with much lower resource requirements than past approaches
Link: https://arxiv.org/abs/1808.09861
====================================================
Searching Toward Pareto-Optimal Device-Aware Neural Architectures (An-Chieh Cheng - 29 August, 2018)
Recent breakthroughs in Neural Architectural Search (NAS) have achieved state-of-the-art performance in many tasks such as image classification and language understanding
Link: https://arxiv.org/abs/1808.09830
====================================================
Decoupling Strategy and Generation in Negotiation Dialogues (He He - 29 August, 2018)
We consider negotiation settings in which two agents use natural language to bargain on goods. Agents need to decide on both high-level strategy (e.g., proposing \$50) and the execution of that strategy (e.g., generating "The bike is brand new. Selling for just \$50.")
Link: https://arxiv.org/abs/1808.09637
====================================================
Auto-generated Spies Increase Test Maintainability (Konstantin LÃ¤ufer - 29 August, 2018)
According to our preliminary findings, using a mocking framework that supports the automatic generation of test spies, such as Mockito, can lead to a significant improvement of test code in terms of size (in some cases over 70% smaller), readability, and conveying intent by expressing expectations through a declarative domain-specific language
Link: https://arxiv.org/abs/1808.09630
====================================================
The Remarkable Benefit of User-Level Aggregation for Lexical-based Population-Level Predictions (Salvatore Giorgi - 28 August, 2018)
This paper describes a simple yet effective method for building community-level models using Twitter language aggregated by user. We make our aggregated and anonymized community-level data, derived from 37 billion tweets -- over 1 billion of which were mapped to counties, available for research.
Link: https://arxiv.org/abs/1808.09600
====================================================
Explaining Character-Aware Neural Networks for Word-Level Prediction: Do They Discover Linguistic Rules? (FrÃ©deric Godin - 28 August, 2018)
Character-level features are currently used in different neural network-based natural language processing algorithms. 2018) to convolutional neural networks which allows us to compare convolutional neural networks and bidirectional long short-term memory networks
Link: https://arxiv.org/abs/1808.09551
====================================================
Towards Semi-Supervised Learning for Deep Semantic Role Labeling (Sanket Vaibhav Mehta - 28 August, 2018)
However, the neural models require an immense amount of semantic-role corpora and are thus not well suited for low-resource languages or domains. On CoNLL-2012 English section, the proposed semi-supervised training with 1%, 10% SRL-labeled data and varying amounts of SRL-unlabeled data achieves +1.58, +0.78 F1, respectively, over the pre-trained models that were trained on SOTA architecture with ELMo on the same SRL-labeled data. Additionally, by using the syntactic-inconsistency loss on inference time, the proposed model achieves +3.67, +2.1 F1 over pre-trained model on 1%, 10% SRL-labeled data, respectively.
Link: https://arxiv.org/abs/1808.09543
====================================================
Adapting Word Embeddings to New Languages with Morphological and Phonological Subword Representations (Aditi Chaudhary - 28 August, 2018)
We demonstrate the effectiveness of our approaches on Named Entity Recognition for four languages, namely Uyghur, Turkish, Bengali and Hindi, of which Uyghur and Bengali are low resource languages, and also perform experiments on Machine Translation. We also show improvements in the monolingual setting where we achieve (avg.) +3 F1 and (avg.) +1.35 BLEU.
Link: https://arxiv.org/abs/1808.09500
====================================================
Residualized Factor Adaptation for Community Social Media Prediction Tasks (Mohammadzaman Zamani - 28 August, 2018)
age, education rates, race) of the community from which the language originates. Our evaluation shows that residualized factor adaptation significantly improves 4 out of 5 community-level outcome predictions over prior state-of-the-art for incorporating socio-demographic contexts.
Link: https://arxiv.org/abs/1808.09479
====================================================
WikiAtomicEdits: A Multilingual Corpus of Wikipedia Edits for Modeling Language and Discourse (Manaal Faruqui - 28 August, 2018)
We release a corpus of 43 million atomic edits across 8 languages
Link: https://arxiv.org/abs/1808.09422
====================================================
Identifying Well-formed Natural Language Questions (Manaal Faruqui - 28 August, 2018)
Here, we introduce a new task of identifying a well-formed natural language question. We construct and release a dataset of 25,100 publicly available questions classified into well-formed and non-wellformed categories and report an accuracy of 70.7% on the test set
Link: https://arxiv.org/abs/1808.09419
====================================================
Semantic Role Labeling for Learner Chinese: the Importance of Syntactic Parsing and L2-L1 Parallel Data (Zi Lin - 29 August, 2018)
We find two non-obvious facts: 1) the L1-sentence-trained systems performs rather badly on the L2 data; 2) the performance drop from the L1 data to the L2 data of the two parser-based systems is much smaller, indicating the importance of syntactic parsing in SRL for interlanguages. Our model achieves an F-score of 72.06, which is a 2.02 point improvement over the best baseline.
Link: https://arxiv.org/abs/1808.09409
====================================================
What Makes Reading Comprehension Questions Easier? (Saku Sugawara - 28 August, 2018)
A challenge in creating a dataset for machine reading comprehension (MRC) is to collect questions that require a sophisticated understanding of language to answer beyond using superficial cues. In this work, we investigate what makes questions easier across recent 12 MRC datasets with three question styles (answer extraction, description, and multiple choice)
Link: https://arxiv.org/abs/1808.09384
====================================================
Understanding Back-Translation at Scale (Sergey Edunov - 2 October, 2018)
An effective method to improve neural machine translation with monolingual data is to augment the parallel training corpus with back-translations of target language sentences. Finally, we scale to hundreds of millions of monolingual sentences and achieve a new state of the art of 35 BLEU on the WMT'14 English-German test set.
Link: https://arxiv.org/abs/1808.09381
====================================================
A Unified Multilingual Handwriting Recognition System using multigrams sub-lexical units (Wassim Swaileh - 28 August, 2018)
We discuss the impact of the language unification on each model and show that our system reaches state-of-the-art methods perfor- mance with a strong reduction of the complexity.
Link: https://arxiv.org/abs/1808.09183
====================================================
Proceedings of the 5th International Workshop on Software Engineering Methods in Spreadsheets (SEMS'18) (Birgit Hofer - 28 August, 2018)
Proceedings of the 5th International Workshop on Software Engineering Methods in Spreadsheets (SEMS'18), held on October 1st, 2018, in Lisbon, Portugal, and co-located with the 2018 IEEE Symposium on Visual Languages and Human-Centric Computing (VL/HCC).
Link: https://arxiv.org/abs/1808.09174
====================================================
Guided Neural Language Generation for Abstractive Summarization using Abstract Meaning Representation ( Hardy - 28 August, 2018)
In this paper, we extend previous work on abstractive summarization using Abstract Meaning Representation (AMR) with a neural language generation stage which we guide using the source document. We demonstrate that this guidance improves summarization results by 7.4 and 10.5 points in ROUGE-2 using gold standard AMR parses and parses obtained from an off-the-shelf parser respectively. We also find that the summarization performance using the latter is 2 ROUGE-2 points higher than that of a well-established neural encoder-decoder approach trained on a larger dataset
Link: https://arxiv.org/abs/1808.09160
====================================================
Disfluency Detection using Auto-Correlational Neural Networks (Paria Jamshid Lou - 27 August, 2018)
However, state-of-the-art approaches to disfluency detection in spontaneous speech transcripts currently still depend on an array of hand-crafted features, and other representations derived from the output of pre-existing systems such as language models or dependency parsers. In experiments, the ACNN model outperforms the baseline CNN on a disfluency detection task with a 5% increase in f-score, which is close to the previous best result on this task.
Link: https://arxiv.org/abs/1808.09092
====================================================
Disfluency Detection using a Noisy Channel Model and a Deep Neural Language Model (Paria Jamshid Lou - 27 August, 2018)
We show that using an LSTM language model in the reranking process of noisy channel disfluency model improves the state-of-the-art in disfluency detection.
Link: https://arxiv.org/abs/1808.09091
====================================================
Parameter sharing between dependency parsers for related languages (Miryam de Lhoneux - 4 October, 2018)
We present an evaluation of 27 different parameter sharing strategies across 10 languages, representing five pairs of related languages, each pair from a different language family
Link: https://arxiv.org/abs/1808.09055
====================================================
Pyramidal Recurrent Unit for Language Modeling (Sachin Mehta - 27 August, 2018)
In particular, PRU improves the perplexity of a recent state-of-the-art language model Merity et al. (2018) by up to 1.3 points while learning 15-20% fewer parameters
Link: https://arxiv.org/abs/1808.09029
====================================================
Back-Translation Sampling by Targeting Difficult Words in Neural Machine Translation (Marzieh Fadaee - 21 September, 2018)
Neural Machine Translation has achieved state-of-the-art performance for several language pairs using a combination of parallel and synthetic data. Experimental results for the WMT news translation task show that our method improves translation quality by up to 1.7 and 1.2 Bleu points over back-translation using random sampling for German-English and English-German, respectively.
Link: https://arxiv.org/abs/1808.09006
====================================================
Large Margin Neural Language Model (Jiaji Huang - 27 August, 2018)
Conventionally, neural language models are trained by minimizing perplexity (PPL) on grammatical sentences. Compared with minimum-PPL training, our method gains up to 1.1 WER reduction for speech recognition and 1.0 BLEU increase for machine translation.
Link: https://arxiv.org/abs/1808.08987
====================================================
Dissecting Contextual Word Embeddings: Architecture and Representation (Matthew E. Peters - 27 September, 2018)
Contextual word representations derived from pre-trained bidirectional language models (biLMs) have recently been shown to provide significant improvements to the state of the art for a wide range of NLP tasks
Link: https://arxiv.org/abs/1808.08949
====================================================
Attentive Sequence to Sequence Translation for Localizing Clips of Interest by Natural Language Descriptions (Ke Ning - 27 August, 2018)
Integration of the multiple granularities yields a robust representation for multi-level video-language abstraction. Our ASST outperforms the state-of-the-art by $4.28\%$ in Rank$@1$ on the DiDeMo dataset. On the Charades-STA dataset, we significantly improve the state-of-the-art by $13.41\%$ in Rank$@1,IoU=0.5$.
Link: https://arxiv.org/abs/1808.08803
====================================================
Amobee at IEST 2018: Transfer Learning from Language Models (Alon Rozental - 27 August, 2018)
Our approach represents a novel use of language models (specifically trained on a large Twitter dataset) to predict and classify emotions. Our system reached 1st place with a macro $\text{F}_1$ score of 0.7145.
Link: https://arxiv.org/abs/1808.08782
====================================================
Natural Language Inference with Hierarchical BiLSTM Max Pooling Architecture (Aarne Talman - 27 August, 2018)
Recurrent neural networks have proven to be very effective for natural language inference tasks. We also show that our sentence embeddings can be utilized in a wide variety of transfer learning tasks, outperforming InferSent on 7 out of 10 and SkipThought on 8 out of 9 SentEval sentence embedding evaluation tasks. Furthermore, our model beats the InferSent model in 8 out of 10 recently published SentEval probing tasks designed to evaluate sentence embeddings' ability to capture some of the important linguistic properties of sentences.
Link: https://arxiv.org/abs/1808.08762
====================================================
Generating Text through Adversarial Training using Skip-Thought Vectors (Afroz Ahamad - 27 August, 2018)
In the field of Natural Language Processing, word embeddings such as word2vec and GLoVe are state-of-the-art methods for applying neural network models on textual data
Link: https://arxiv.org/abs/1808.08703
====================================================
Adversarially Regularising Neural NLI Models to Integrate Logical Background Knowledge (Pasquale Minervini - 26 August, 2018)
We reduce the problem of identifying such adversarial examples to a combinatorial optimisation problem, by maximising a quantity measuring the degree of violation of such constraints and by using a language model for generating linguistically-plausible examples. Our results show that, while the proposed method does not always improve results on the SNLI and MultiNLI datasets, it significantly and consistently increases the predictive accuracy on adversarially-crafted datasets -- up to a 79.6% relative improvement -- while drastically reducing the number of background knowledge violations
Link: https://arxiv.org/abs/1808.08609
====================================================
Contextual Parameter Generation for Universal Neural Machine Translation (Emmanouil Antonios Platanios - 25 August, 2018)
We further show it is able to surpass state-of-the-art performance for both the IWSLT-15 and IWSLT-17 datasets and that the learned language embeddings are able to uncover interesting relationships between languages.
Link: https://arxiv.org/abs/1808.08493
====================================================
Paraphrases as Foreign Languages in Multilingual Neural Machine Translation (Zhong Zhou - 25 August, 2018)
We treat paraphrases as foreign languages, tag source sentences with paraphrase labels, and train in the style of multilingual Neural Machine Translation (NMT). We achieve a BLEU score of 57.2 for French-to-English translation, training on 24 paraphrases of the Bible, which is ~+27 above the WMT'14 baseline.
Link: https://arxiv.org/abs/1808.08438
====================================================
Meta-Learning for Low-Resource Neural Machine Translation (Jiatao Gu - 25 August, 2018)
We evaluate the proposed meta-learning strategy using eighteen European languages (Bg, Cs, Da, De, El, Es, Et, Fr, Hu, It, Lt, Nl, Pl, Pt, Sk, Sl, Sv and Ru) as source tasks and five diverse languages (Ro, Lv, Fi, Tr and Ko) as target tasks. For instance, the proposed approach can achieve as high as 22.04 BLEU on Romanian-English WMT'16 by seeing only 16,000 translated words (~600 parallel sentences).
Link: https://arxiv.org/abs/1808.08437
====================================================
Improving the results of string kernels in sentiment analysis and Arabic dialect identification by adapting them to your test set (Radu Tudor Ionescu - 31 August, 2018)
Recently, string kernels have obtained state-of-the-art results in various text classification tasks such as Arabic dialect identification or native language identification
Link: https://arxiv.org/abs/1808.08409
====================================================
Proceedings Combined 25th International Workshop on Expressiveness in Concurrency and 15th Workshop on Structural Operational Semantics (Jorge A. PÃ©rez - 24 August, 2018)
One of the specific goals of the SOS workshop series is to establish synergies between the concurrency and programming language communities working on the theory and practice of SOS. Since 2012, the EXPRESS and SOS communities have organized an annual combined EXPRESS/SOS workshop on the expressiveness of mathematical models of computation and the formal semantics of systems and programming concepts.
Link: https://arxiv.org/abs/1808.08071
====================================================
The Importance of Generation Order in Language Modeling (Nicolas Ford - 23 August, 2018)
Neural language models are a critical component of state-of-the-art systems for machine translation, summarization, audio transcription, and other tasks
Link: https://arxiv.org/abs/1808.07910
====================================================
Review-Driven Multi-Label Music Style Classification by Exploiting Style Correlations (Guangxiang Zhao - 22 August, 2018)
This paper explores a new natural language processing task, review-driven multi-label music style classification. Especially, the micro F1 is improved from 53.9 to 64.5, and the one-error is reduced from 30.5 to 22.6
Link: https://arxiv.org/abs/1808.07604
====================================================
Dynamic Self-Attention : Computing Attention over Words Dynamically for Sentence Embedding (Deunsol Yoon - 22 August, 2018)
We achieve new state-of-the-art results among sentence encoding methods in Stanford Natural Language Inference (SNLI) dataset with the least number of parameters, while showing comparative results in Stanford Sentiment Treebank (SST) dataset.
Link: https://arxiv.org/abs/1808.07383
====================================================
Neural Named Entity Recognition from Subword Units (Abdalghani Abujabal - 27 August, 2018)
Named entity recognition (NER) is a vital task in language technology. Existing neural models for NER rely mostly on dedicated word-level representations, which suffer from two main shortcomings: 1) the vocabulary size is large, yielding large memory requirements and training time, and 2) they cannot learn morphological representations. Our experiments show that 1) with increasing training data, performance of models trained solely on subword units becomes closer to that of models with dedicated word-level embeddings (91.35 vs 93.92 F1 for English), while using a much smaller vocabulary size (332 vs 74K), 2) subword units enhance models with dedicated word-level embeddings, and 3) combining different subword units improves performance.
Link: https://arxiv.org/abs/1808.07364
====================================================
k-meansNet: When k-means Meets Differentiable Programming (Xi Peng - 22 August, 2018)
In this paper, we study how to make clustering benefiting from differentiable programming whose basic idea is treating the neural network as a language instead of a machine learning method. Extensive experimental studies show that our method achieves promising performance comparing with 12 clustering methods on some challenging datasets.
Link: https://arxiv.org/abs/1808.07292
====================================================
Improving Matching Models with Contextualized Word Representations for Multi-turn Response Selection in Retrieval-based Chatbots (Chongyang Tao - 22 August, 2018)
When directly applied to the task, state-of-the-art models, such as CoVe and ELMo, do not work as well as they do on other tasks, due to the hierarchical nature, casual language, and domain-specific word use of conversations
Link: https://arxiv.org/abs/1808.07244
====================================================
Neural Architecture Optimization (Renqian Luo - 5 September, 2018)
Specifically we obtain $2.07\%$ test set error rate for CIFAR-10 image classification task and $55.9$ test set perplexity of PTB language modeling task
Link: https://arxiv.org/abs/1808.07233
====================================================
Language Identification in Code-Mixed Data using Multichannel Neural Networks and Context Capture (Soumil Mandal - 21 August, 2018)
Inspired from the recent advancements in neural network architectures for computer vision tasks, we have implemented multichannel neural networks combining CNN and LSTM for word level language identification of code-mixed data. Combining this with a Bi-LSTM-CRF context capture module, accuracies of 93.28% and 93.32% is achieved on our two testing sets.
Link: https://arxiv.org/abs/1808.07118
====================================================
Adversarial training for multi-context joint entity and relation extraction (Giannis Bekoulis - 21 August, 2018)
In particular, we demonstrate that applying AT to a general purpose baseline model for jointly extracting entities and relations, allows improving the state-of-the-art effectiveness on several datasets in different contexts (i.e., news, biomedical, and real estate data) and for different languages (English and Dutch).
Link: https://arxiv.org/abs/1808.06876
====================================================
Translational Grounding: Using Paraphrase Recognition and Generation to Demonstrate Semantic Abstraction Abilities of MultiLingual NMT (JÃ¶rg Tiedemann - 21 August, 2018)
In our setup, we add 16 different auxiliary languages to a bidirectional bilingual baseline model (English-French) and test it with in-domain and out-of-domain paraphrases in English
Link: https://arxiv.org/abs/1808.06826
====================================================
Lessons from Natural Language Inference in the Clinical Domain (Alexey Romanov - 27 August, 2018)
To address this gap, we introduce MedNLI - a dataset annotated by doctors, performing a natural language inference task (NLI), grounded in the medical history of patients. SNLI) and 2) incorporate domain knowledge from external data and lexical sources (e.g
Link: https://arxiv.org/abs/1808.06752
====================================================
Leveraging Historical Associations between Requirements and Source Code to Identify Impacted Classes (Davide Falessi - 20 August, 2018)
We consider 18 different R2RS metrics by combining six natural language processing techniques to measure the semantic similarity among texts (e.g., VSM) and three distribution scores to compute overall similarity (e.g., average among similarity scores). Our evaluation features five classifiers and 78 releases belonging to four large open-source projects, which result in over 700,000 candidate impacted classes. Experimental results show that leveraging R2RS information increases the accuracy of predicting impacted classes practically by an average of more than 60% across the various classifiers and projects.
Link: https://arxiv.org/abs/1808.06359
====================================================
Rock bottom, the world, the sky: Catrobat, an extremely large-scale and long-term visual coding project relying purely on smartphones (Kirshan Kumar Luhana - 19 August, 2018)
Initiated in 2010, with first public versions of our free apps since 2014 and 47 releases of the main coding app as of July 2018, Catrobat currently has more than 700,000 users from 180 countries, is available in 50+ languages, and has been developed so far by almost 1,000 volunteers from around the world ("the world"). Catrobat is strongly inspired by Scratch and indeed allows to import most Scratch projects, thus giving access to more than 30 million projects on our users' phones as of July 2018
Link: https://arxiv.org/abs/1808.06292
====================================================
SABRE: Protecting Bitcoin against Routing Attacks (Maria Apostolaki - 19 August, 2018)
This enables us to offload most of the relay operations to programmable network hardware (using the P4 programming language). Our results demonstrate that SABRE is effective at securing Bitcoin against routing attacks, even with deployments as small as 6 nodes.
Link: https://arxiv.org/abs/1808.06254
====================================================
SentencePiece: A simple and language independent subword tokenizer and detokenizer for Neural Text Processing (Taku Kudo - 19 August, 2018)
While existing subword segmentation tools assume that the input is pre-tokenized into word sequences, SentencePiece can train subword models directly from raw sentences, which allows us to make a purely end-to-end and language independent system. SentencePiece is available under the Apache 2 license at https://github.com/google/sentencepiece.
Link: https://arxiv.org/abs/1808.06226
====================================================
Source-Critical Reinforcement Learning for Transferring Spoken Language Understanding to a New Language (He Bai - 22 August, 2018)
We evaluate our approach on Chinese to English language transferring for SLU systems. The experimental results show that the generated English SLU corpus via adaptation and reinforcement learning gives us over 97% in the slot F1 score and over 84% accuracy in domain classification. Compared with naive translation, our proposed method improves domain classification accuracy by relatively 22%, and the slot filling F1 score by relatively more than 71%.
Link: https://arxiv.org/abs/1808.06167
====================================================
Improved Language Modeling by Decoding the Past (Siddhartha Brahma - 29 September, 2018)
With negligible overhead in the number of parameters and training time, our past decode regularization (PDR) method achieves state-of-the-art word level perplexity on the Penn Treebank (55.6) and WikiText-2 (63.5) datasets and bits-per-character on the Penn Treebank Character (1.169) dataset for character level language modeling. Using dynamic evaluation, we also achieve the first sub 50 perplexity of 49.3 on the Penn Treebank test set.
Link: https://arxiv.org/abs/1808.05908
====================================================
Augmenting Statistical Machine Translation with Subword Translation of Out-of-Vocabulary Words (Nelson F. Liu - 16 August, 2018)
Adding OOV translators to a statistical machine translation system yields consistent BLEU gains (0.5 points on average, and up to 2.0) for all fourteen languages, especially in low-resource scenarios.
Link: https://arxiv.org/abs/1808.05700
====================================================
Linguistic data mining with complex networks: a stylometric-oriented approach (Tomasz Stanisz - 16 August, 2018)
In this paper, the possibility of using network representation in order to extract information about individual language styles of literary texts is studied. It turns out that within the studied set of texts in English and Polish, the properly rescaled weighted clustering coefficients and weighted degrees of only a few nodes in the word-adjacency networks are sufficient to obtain the accuracy of authorship attribution over 90\%
Link: https://arxiv.org/abs/1808.05439
====================================================
Identifying Implementation Bugs in Machine Learning based Image Classifiers using Metamorphic Testing (Anurag Dwarakanath - 16 August, 2018)
Computer vision, speech recognition and language translation have all seen a near human level performance. Empirical validation showed that our approach was able to catch 71% of the implementation bugs in the ML applications.
Link: https://arxiv.org/abs/1808.05353
====================================================
Google Scholar, Web of Science, and Scopus: a systematic comparison of citations in 252 subject categories (Alberto MartÃ­n-MartÃ­n - 5 October, 2018)
In response, this paper investigates 2,448,055 citations to 2,299 English-language highly-cited documents from 252 GS subject categories published in 2006, comparing GS, the WoS Core Collection, and Scopus. GS consistently found the largest percentage of citations across all areas (93%-96%), far ahead of Scopus (35%-77%) and WoS (27%-73%). GS found nearly all the WoS (95%) and Scopus (92%) citations. Most citations found only by GS were from non-journal sources (48%-65%), including theses, books, conference papers, and unpublished materials. Many were non-English (19%-38%), and they tended to be much less cited than citing sources that were also in Scopus or WoS
Link: https://arxiv.org/abs/1808.05053
====================================================
Classifier Ensembles for Dialect and Language Variety Identification (Liviu P. Dinu - 14 August, 2018)
In this paper we present ensemble-based systems for dialect and language variety identification using the datasets made available by the organizers of the VarDial Evaluation Campaign 2018. Finally, we compare the performance of these two systems with the other systems submitted to the Discriminating between Dutch and Flemish in Subtitles (DFS) and the Arabic Dialect Identification (ADI) shared tasks at VarDial 2018.
Link: https://arxiv.org/abs/1808.04800
====================================================
A Survey on Methods and Theories of Quantized Neural Networks (Yunhui Guo - 13 August, 2018)
Deep neural networks are the state-of-the-art methods for many real-world tasks, such as computer vision, natural language processing and speech recognition
Link: https://arxiv.org/abs/1808.04752
====================================================
Primal Meaning Recommendation for Chinese Words and Phrases via Descriptions in On-line Encyclopedia (Zhiyuan Zhang - 14 August, 2018)
Polysemy is a very common phenomenon in modern languages. The experiment results show that our method yields very good result with a p@1 score of 80.6%, and a MAP of 89.0%, surpassing the Word-Sum baseline by a big margin (P@1 is 62.7% and MAP is 76.8%).
Link: https://arxiv.org/abs/1808.04660
====================================================
Multimodal Deep Neural Networks using Both Engineered and Learned Representations for Biodegradability Prediction (Garrett B. Goh - 13 September, 2018)
Deep learning algorithms excel at extracting patterns from raw data, and with large datasets, they have been very successful in computer vision and natural language applications. DeepBioD, a multimodal CNN-MLP network is more accurate than either standalone network designs, and achieves an error classification rate of 0.125 that is 27% lower than the current state-of-the-art
Link: https://arxiv.org/abs/1808.04456
====================================================
Character-Level Language Modeling with Deeper Self-Attention (Rami Al-Rfou - 9 August, 2018)
LSTMs and other RNN variants have shown strong performance on character-level language modeling. In this paper, we show that a deep (64-layer) transformer model with fixed context outperforms RNN variants by a large margin, achieving state of the art on two popular benchmarks- 1.13 bits per character on text8 and 1.06 on enwik8
Link: https://arxiv.org/abs/1808.04444
====================================================
Thou shalt not hate: Countering Online Hate Speech (Binny Mathew - 13 August, 2018)
This analysis results in various interesting insights such as: the counterspeech comments receive double the likes received by the non-counterspeech comments, for certain communities majority of the non-counterspeech comments tend to be hate speech, the different types of counterspeech are not all equally effective and the language choice of users posting counterspeech is largely different from those posting non-counterspeech as revealed by a detailed psycholinguistic analysis. Finally, we build a set of machine learning models that are able to automatically detect counterspeech in YouTube videos with an F1-score of 0.73.
Link: https://arxiv.org/abs/1808.04409
====================================================
Disentangled Representation Learning for Non-Parallel Text Style Transfer (Vineet John - 10 September, 2018)
We achieve substantially better results in terms of transfer accuracy, content preservation and language fluency, in comparison to previous state-of-the-art approaches.
Link: https://arxiv.org/abs/1808.04339
====================================================
Neural Semi-Markov Conditional Random Fields for Robust Character-Based Part-of-Speech Tagging (Apostolos Kemos - 13 August, 2018)
The model matches state-of-the-art baselines for various languages and significantly outperforms them on a noisy English version of a part-of-speech tagging benchmark dataset.
Link: https://arxiv.org/abs/1808.04208
====================================================
Rapid Adaptation of Neural Machine Translation to New Languages (Graham Neubig - 13 August, 2018)
Experiments demonstrate that massively multilingual models, even without any explicit adaptation, are surprisingly effective, achieving BLEU scores of up to 15.5 with no data from the LRL, and that the proposed similar-language regularization method improves over other adaptation methods by 1.7 BLEU points average over 4 LRL settings
Link: https://arxiv.org/abs/1808.04189
====================================================
Sequence Labeling: A Practical Approach (Adnan Akhundov - 12 August, 2018)
The model's performance is evaluated on eight benchmark datasets (covering three tasks: POS-tagging, NER, and Chunking, and four languages: English, German, Dutch, and Spanish). We observe state-of-the-art results on four of them: CoNLL-2012 (English NER), CoNLL-2002 (Dutch NER), GermEval 2014 (German NER), Tiger Corpus (German POS-tagging), and competitive performance on the rest.
Link: https://arxiv.org/abs/1808.03926
====================================================
Multimodal Language Analysis with Recurrent Multistage Fusion (Paul Pu Liang - 12 August, 2018)
The RMFN displays state-of-the-art performance in modeling human multimodal language across three public datasets relating to multimodal sentiment analysis, emotion recognition, and speaker traits recognition
Link: https://arxiv.org/abs/1808.03920
====================================================
Fake Sentence Detection as a Training Task for Sentence Encoding (Viresh Ranjan - 23 August, 2018)
We compare a basic BiLSTM encoder trained on this task with a strong sentence encoding models (Skipthought and FastSent) trained on a language modeling task. We find that the BiLSTM trains much faster on fake sentence detection (20 hours instead of weeks) using smaller amounts of data (1M instead of 64M sentences)
Link: https://arxiv.org/abs/1808.03840
====================================================
Document Informed Neural Autoregressive Topic Models (Pankaj Gupta - 11 August, 2018)
Here, we extend a neural autoregressive topic model to exploit the full context information around words in a document in a language modeling fashion. With the learned representations, we show on an average a gain of 9.6% (0.57 Vs 0.52) in precision at retrieval fraction 0.02 and 7.2% (0.582 Vs 0.543) in F1 for text categorization.
Link: https://arxiv.org/abs/1808.03793
====================================================
Dropout during inference as a model for neurological degeneration in an image captioning network (Bai Li - 10 August, 2018)
We evaluate the effects of dropout on language production by measuring the KL-divergence of word frequency distributions and other linguistic metrics as dropout is added. We find that the generated sentences most closely approximate the word frequency distribution of the training corpus when using a moderate dropout of 0.4 during inference.
Link: https://arxiv.org/abs/1808.03747
====================================================
Hierarchical Attention: What Really Counts in Various NLP Tasks (Zehao Dou - 10 August, 2018)
Attention mechanisms in sequence to sequence models have shown great ability and wonderful performance in various natural language processing (NLP) tasks, such as sentence embedding, text generation, machine translation, machine reading comprehension, etc. Ham achieves a state-of-the-art BLEU score of 0.26 on Chinese poem generation task and a nearly 6.5% averaged improvement compared with the existing machine reading comprehension models such as BIDAF and Match-LSTM
Link: https://arxiv.org/abs/1808.03728
====================================================
LemmaTag: Jointly Tagging and Lemmatizing for Morphologically-Rich Languages with BRNNs (Daniel Kondratyuk - 27 August, 2018)
We evaluate our model across several languages with complex morphology, which surpasses state-of-the-art accuracy in both part-of-speech tagging and lemmatization in Czech, German, and Arabic.
Link: https://arxiv.org/abs/1808.03703
====================================================
Code-Mixed Sentiment Analysis Using Machine Learning and Neural Network Approaches (Pruthwik Mishra - 9 August, 2018)
Sentiment Analysis for Indian Languages (SAIL)-Code Mixed tools contest aimed at identifying the sentence level sentiment polarity of the code-mixed dataset of Indian languages pairs (Hi-En, Ben-Hi-En). Both the models used TF-IDF feature vectors of character n-grams where n ranged from 2 to 6. We finished first in the contest for both HI-EN with an F-score of 0.569 and BN-EN with an F-score of 0.526.
Link: https://arxiv.org/abs/1808.03299
====================================================
Building a Kannada POS Tagger Using Machine Learning and Neural Network Models (Ketan Kumar Todi - 9 August, 2018)
Kannada is a relatively poor Indian language with very limited number of quality NLP tools available for use. Our Kannada POS tagger outperforms the state-of-the-art Kannada POS tagger by 6%
Link: https://arxiv.org/abs/1808.03175
====================================================
End-to-end Speech Recognition with Word-based RNN Language Models (Takaaki Hori - 7 August, 2018)
This paper investigates the impact of word-based RNN language models (RNN-LMs) on the performance of end-to-end automatic speech recognition (ASR). Furthermore, we show that the proposed model achieves 5.1 %WER for WSJ Eval'92 test set when the vocabulary size is increased, which is the best WER reported for end-to-end ASR systems on this benchmark.
Link: https://arxiv.org/abs/1808.02608
====================================================
LISA: Explaining Recurrent Neural Network Judgments via Layer-wIse Semantic Accumulation and Example to Pattern Transformation (Pankaj Gupta - 5 August, 2018)
Recurrent neural networks (RNNs) are temporal networks and cumulative in nature that have shown promising results in various natural language processing tasks. We employ two relation classification datasets: SemEval 10 Task 8 and TAC KBP Slot Filling to explain RNN predictions via the LISA and example2pattern.
Link: https://arxiv.org/abs/1808.01591
====================================================
Improving Deep Visual Representation for Person Re-identification by Global and Local Image-language Association (Dapeng Chen - 5 August, 2018)
Our method achieves state-of-the-art performance without utilizing any auxiliary information during testing and shows better performance than other joint embedding methods for the image-language association.
Link: https://arxiv.org/abs/1808.01571
====================================================
Statistics on Open Access Books Available through the Directory of Open Access Books (Keita Tsuji - 4 August, 2018)
Open Access (OA) books available through the Directory of Open Access Books (DOAB) are investigated and the number of titles, the distribution of subjects, languages, publishers, publication years, licensing patterns, etc., are clarified. The sample comprised 10,866 OA books, which were available through the DOAB as of February 24, 2018. Many books are newly published ones, but older books, published in or before 1999, also began to be available recently
Link: https://arxiv.org/abs/1808.01541
====================================================
Language Model Supervision for Handwriting Recognition Model Adaptation (Chris Tensmeyer - 4 August, 2018)
Training state-of-the-art offline handwriting recognition (HWR) models requires large labeled datasets, but unfortunately such datasets are not available in all languages and domains due to the high cost of manual labeling.We address this problem by showing how high resource languages can be leveraged to help train models for low resource languages.We propose a transfer learning methodology where we adapt HWR models trained on a source language to a target language that uses the same writing script.This methodology only requires labeled data in the source language, unlabeled data in the target language, and a language model of the target language
Link: https://arxiv.org/abs/1808.01423
====================================================
code2seq: Generating Sequences from Structured Representations of Code (Uri Alon - 10 October, 2018)
We demonstrate the effectiveness of our approach for two tasks, two programming languages, and four datasets of up to $16$M examples. Our model significantly outperforms previous models that were specifically designed for programming languages, as well as state-of-the-art NMT models.
Link: https://arxiv.org/abs/1808.01400
====================================================
Large Scale Language Modeling: Converging on 40GB of Text in Four Hours (Raul Puri - 10 August, 2018)
Following [Radford 2017], in this work, we demonstrate similar scalability and transfer for Recurrent Neural Networks (RNNs) for Natural Language tasks. By utilizing mixed precision arithmetic and a 32k batch size distributed across 128 NVIDIA Tesla V100 GPUs, we are able to train a character-level 4096-dimension multiplicative LSTM (mLSTM) for unsupervised text reconstruction over 3 epochs of the 40 GB Amazon Reviews dataset in four hours. Since our model converges over the Amazon Reviews dataset in hours, and our compute requirement of 128 Tesla V100 GPUs, while substantial, is commercially available, this work opens up large scale unsupervised NLP training to most commercial applications and deep learning researchers
Link: https://arxiv.org/abs/1808.01371
====================================================
The Text-Based Adventure AI Competition (Timothy Atkinson - 3 August, 2018)
By providing a platform for evaluating agents in text-based adventures, the competition provides a novel benchmark for game AI with unique challenges for natural language understanding and generation. This paper summarises the two competitions ran in 2016 and 2017 (including details of open source implementations of both the competition framework and our competitors) and presents the results of an improved evaluation of these competitors across 20 games.
Link: https://arxiv.org/abs/1808.01262
====================================================
Linguistic Search Optimization for Deep Learning Based LVCSR (Zhehuai Chen - 2 August, 2018)
The inference process of a speech recognizer is to find a sequence of labels whose corresponding acoustic and language models best match the input feature [1]
Link: https://arxiv.org/abs/1808.00687
====================================================
sCompile: Critical Path Identification and Analysis for Smart Contracts (Jialiang Chang - 1 August, 2018)
The most popular programming language for creating smart contracts is called Solidity, which is supported by Ethereum. The experiment results show that sCompile is efficient, i.e., 5 seconds on average for one smart contract. Furthermore, we show that many known vulnerability can be captured if the user inspects as few as 10 program paths generated by sCompile. Lastly, sCompile discovered 224 unknown vulnerabilities with a false positive rate of 15.4% before user inspection.
Link: https://arxiv.org/abs/1808.00624
====================================================
Monolingual and Cross-lingual Zero-shot Style Transfer (Elizaveta Korotkova - 1 August, 2018)
We introduce the task of zero-shot style transfer between different languages. Our model allows to increase the presence of dissimilar styles in corpus by up to 3 times, easily learns to operate with various contractions, and provides reasonable lexicon swaps as we see from manual evaluation.
Link: https://arxiv.org/abs/1808.00179
====================================================
Universal Approximation with Quadratic Deep Networks (Fenglei Fan - 9 October, 2018)
Since AlexNet, increasingly more advanced networks have achieved state-of-the-art performance in computer vision, speech recognition, language processing, game playing, medical imaging, and so on
Link: https://arxiv.org/abs/1808.00098
====================================================
Modeling Task Effects in Human Reading with Neural Attention (Michael Hahn - 31 July, 2018)
We offer a novel explanation for skipping: readers optimize a tradeoff between performing a language-related task and fixating as few words as possible. We show that our model predicts human skipping behavior, while also modeling reading times well, even though it skips 40% of the input
Link: https://arxiv.org/abs/1808.00054
====================================================
An Empirical Study on Quality of Android Applications written in Kotlin language (Bruno Gois Mateus - 31 July, 2018)
For instance, since 2017 Android developers have the official support to write their Android applications using Kotlin language. Kotlin is programming language 100% interoperable with Java that combines Object-oriented and functional features.
Link: https://arxiv.org/abs/1808.00025
====================================================
Gender Bias in Neural Natural Language Processing (Kaiji Lu - 31 July, 2018)
Our empirical evaluation with state-of-the-art neural coreference resolution and textbook RNN-based language models trained on benchmark datasets finds significant gender bias in how models view occupations
Link: https://arxiv.org/abs/1807.11714
====================================================
UH-PRHLT at SemEval-2016 Task 3: Combining Lexical and Semantic-based Features for Community Question Answering (Marc Franco-Salvador - 30 July, 2018)
In this work we describe the system built for the three English subtasks of the SemEval 2016 Task 3 by the Department of Computer Science of the University of Houston (UH) and the Pattern Recognition and Human Language Technology (PRHLT) research center - Universitat Polit`ecnica de Val`encia: UH-PRHLT
Link: https://arxiv.org/abs/1807.11584
====================================================
A Hierarchical Approach to Neural Context-Aware Modeling (Patrick Huber - 6 August, 2018)
To show the potential of the newly introduced topology, we compare the approach against a context-agnostic set-up including a standard neural language model and a supervised binary classification network. The performance measures on the error detection task show the advantage of the hierarchical context-aware topologies, improving the baseline by 12.75% relative for unsupervised models and 20.37% relative for supervised models.
Link: https://arxiv.org/abs/1807.11582
====================================================
Domain Robust Feature Extraction for Rapid Low Resource ASR Development (Siddharth Dalmia - 30 September, 2018)
This enables rapid development of speech recognizers for new languages which can easily adapt to any domain. Testing in various cross-domain scenarios, we achieve relative improvements of around 25% in phoneme error rate, with improvements being around 50% for some domains.
Link: https://arxiv.org/abs/1807.10984
====================================================
Building a Unified Code-Switching ASR System for South African Languages (Emre YÄ±lmaz - 28 July, 2018)
Recently, we have compiled a small five-language corpus of South African soap opera speech which contains examples of CS between 5 languages occurring in various contexts such as using English as the matrix language and switching to other indigenous languages. The ASR system presented in this work is trained on 4 corpora containing English-isiZulu, English-isiXhosa, English-Setswana and English-Sesotho CS speech. The interpolation of multiple language models trained on these language pairs enables the ASR system to hypothesize mixed word sequences from these 5 languages. We evaluate various state-of-the-art acoustic models trained on this 5-lingual training data and report ASR accuracy and language recognition performance on the development and test sets of the South African multilingual soap opera corpus.
Link: https://arxiv.org/abs/1807.10949
====================================================
A small Griko-Italian speech translation corpus (Marcely Zanon Boito - 27 July, 2018)
This paper presents an extension to a very low-resource parallel corpus collected in an endangered language, Griko, making it useful for computational research. The corpus consists of 330 utterances (about 20 minutes of speech) which have been transcribed and translated in Italian, with annotations for word-level speech-to-transcription and speech-to-translation alignments
Link: https://arxiv.org/abs/1807.10740
====================================================
FPGA-Based CNN Inference Accelerator Synthesized from Multi-Threaded C Software (Jin Hee Kim - 27 July, 2018)
A deep-learning inference accelerator is synthesized from a C-language software program parallelized with Pthreads. On a mid-sized Intel Arria 10 SoC FPGA, peak performance on VGG-16 is 138 effective GOPS.
Link: https://arxiv.org/abs/1807.10695
====================================================
Resource-Size matters: Improving Neural Named Entity Recognition with Optimized Large Corpora (Sajawel Ahmed - 26 July, 2018)
This study improves the performance of neural named entity recognition by a margin of up to 11% in F-score on the example of a low-resource language like German, thereby outperforming existing baselines and establishing a new state-of-the-art on each single open-source dataset
Link: https://arxiv.org/abs/1807.10675
====================================================
Open Source Automatic Speech Recognition for German (Benjamin Milde - 26 July, 2018)
While state-of-the-art ASR software is freely available, the language dependent acoustic models are lacking for languages other than English, due to the limited amount of freely available training data. The models are trained on a total of 412 hours of German read speech data and we achieve a relative word error reduction of 26% by adding data from the Spoken Wikipedia Corpus to the previously best freely available German acoustic model recipe and dataset. Our best model achieves a word error rate of 14.38 on the Tuda-De test set
Link: https://arxiv.org/abs/1807.10311
====================================================
DeepSPINE: Automated Lumbar Vertebral Segmentation, Disc-level Designation, and Spinal Stenosis Grading Using Deep Learning (Jen-Tang Lu - 26 July, 2018)
Specifically, we introduce three major contributions: (1) a natural-language-processing scheme to extract level-by-level ground-truth labels from free-text radiology reports for the various types and grades of spinal stenosis (2) accurate vertebral segmentation and disc-level localization using a U-Net architecture combined with a spine-curve fitting method, and (3) a multi-input, multi-task, and multi-class convolutional neural network to perform central canal and foraminal stenosis grading on both axial and sagittal imaging series inputs with the extracted report-derived labels applied to corresponding imaging level segments. This study uses a large dataset of 22796 disc-levels extracted from 4075 patients
Link: https://arxiv.org/abs/1807.10215
====================================================
Missing author address information in Web of Science-An explorative study (Weishu Liu - 25 July, 2018)
The magnitude of the problem varies greatly among time periods, citation databases, document types, and publishing languages. Full-text scanning of a random sample reveals that about 40% of the articles have some address information that is not indexed in WoS. research has diminished dramatically since 1998
Link: https://arxiv.org/abs/1807.09944
====================================================
Iterative evaluation of LSTM cells (Leandro Palma - 11 July, 2018)
We provide theoretical and empirical evidence to support the augmented capabilities of the iterative scheme and show examples related to language modeling. The modification yields an enhancement in the model performance comparable with the original model augmented more than 3 times in terms of the total amount of parameters.
Link: https://arxiv.org/abs/1807.09830
====================================================
Speakers account for asymmetries in visual perspective so listeners don't have to (Robert X. D. Hawkins - 24 July, 2018)
Motivated by recent computational models of context-sensitive language use, we reconsider the evidence in light of the nuanced pragmatics of these tasks: the differential informativity expected of a speaker depending on the context. 1, we explicitly manipulated the presence or absence of occlusions and found that speakers systematically produced longer, more specific referring expressions than required given their own view when they have uncertainty about what their partner is seeing. 2, we compare the utterances used by confederates in prior work with those produced by unscripted speakers in the same task
Link: https://arxiv.org/abs/1807.09000
====================================================
Effective Reformulation of Query for Code Search using Crowdsourced Knowledge and Extra-Large Data Analytics (Mohammad Masudur Rahman - 23 July, 2018)
In this paper, we propose a novel technique that automatically identifies relevant and specific API classes from Stack Overflow Q & A site for a programming task written as a natural language query, and then reformulates the query for improved code search. The semantic proximity has been determined by an analysis of 1.3 million questions and answers of Stack Overflow. Experiments using 310 code search queries report that our technique suggests relevant API classes with 48% precision and 58% recall which are 32% and 48% higher respectively than those of the state-of-the-art
Link: https://arxiv.org/abs/1807.08798
====================================================
PCNNA: A Photonic Convolutional Neural Network Accelerator (Armin Mehrabian - 23 July, 2018)
Convolutional Neural Networks (CNN) have been the centerpiece of many applications including but not limited to computer vision, speech processing, and Natural Language Processing (NLP). While our full system design offers up to more than 3 orders of magnitude speedup in execution time, its optical core potentially offers more than 5 order of magnitude speedup compared to state-of-the-art electronic counterparts.
Link: https://arxiv.org/abs/1807.08792
====================================================
Automatic Speech Recognition for Humanitarian Applications in Somali (Raghav Menon - 23 July, 2018)
We present our first efforts in building an automatic speech recognition system for Somali, an under-resourced language, using 1.57 hrs of annotated speech for acoustic model training. We find that both types of data augmentation are beneficial to performance, with our best system using a combination of convolutional neural networks (CNNs), time-delay neural networks (TDNNs) and bi-directional long short term memory (BLSTMs) to achieve a word error rate of 53.75%.
Link: https://arxiv.org/abs/1807.08669
====================================================
ASR-free CNN-DTW keyword spotting using multilingual bottleneck features for almost zero-resource languages (Raghav Menon - 23 July, 2018)
This forms part of a United Nations effort using keyword spotting to support humanitarian relief programmes in parts of Africa where languages are severely under-resourced. We use 1920 isolated keywords (40 types, 34 minutes) as exemplars for dynamic time warping (DTW) template matching, which is performed on a much larger body of untranscribed speech. We show that multilingual BNFs trained on ten languages improve the area under the ROC curve of a CNN-DTW system by 10.9% absolute relative to the MFCC baseline
Link: https://arxiv.org/abs/1807.08666
====================================================
Clinical Text Classification with Rule-based Features and Knowledge-guided Convolutional Neural Networks (Liang Yao - 20 July, 2018)
Critical Steps of our method include identifying trigger phrases, predicting classes with very few examples using trigger phrases and training a convolutional neural network with word embeddings and Unified Medical Language System (UMLS) entity embeddings. We evaluated our method on the 2008 Integrating Informatics with Biology and the Bedside (i2b2) obesity challenge
Link: https://arxiv.org/abs/1807.07425
====================================================
Hierarchical Multi Task Learning With CTC (Ramon Sanabria - 25 July, 2018)
Our model obtains 14.0% Word Error Rate on the Eval2000 Switchboard subset without any decoder or language model, outperforming the current state-of-the-art on acoustic-to-word models.
Link: https://arxiv.org/abs/1807.07104
====================================================
Merlin: A Language Server for OCaml (Experience Report) (FrÃ©dÃ©ric Bour - 2 October, 2018)
We report on the experience of developing Merlin, a language server for the OCaml programming language in development since 2013
Link: https://arxiv.org/abs/1807.06702
====================================================
Power Networks: A Novel Neural Architecture to Predict Power Relations (Michelle Lam - 17 July, 2018)
Can language analysis reveal the underlying social power relations that exist between participants of an interaction? Prior work within NLP has shown promise in this area, but the performance of automatically predicting power relations using NLP analysis of social interactions remains wanting. We obtain an accuracy of 80.4%, a 10.1% improvement over state-of-the-art methods, in this task. We further apply our model to the task of predicting power relations between individuals based on the entire set of messages exchanged between them; here also, our model significantly outperforms the70.0% accuracy using prior state-of-the-art techniques, obtaining an accuracy of 83.0%.
Link: https://arxiv.org/abs/1807.06557
====================================================
DLA: Compiler and FPGA Overlay for Neural Network Inference Acceleration (Mohamed S. Abdelfattah - 13 July, 2018)
Additionally, we implement a sophisticated domain specific graph compiler that compiles deep learning languages such as Caffe or Tensorflow to easily target our overlay. We show how our graph compiler performs architecture-driven software optimizations to significantly boost performance of both convolutional and recurrent neural networks (CNNs/RNNs) - we demonstrate a 3x improvement on ResNet-101 and a 12x improvement for long short-term memory (LSTM) cells, compared to naive implementations. Finally, we describe how we can tailor our hardware overlay, and use our graph compiler to achieve ~900 fps on GoogLeNet on an Intel Arria 10 1150 - the fastest ever reported on comparable FPGAs.
Link: https://arxiv.org/abs/1807.06434
====================================================
The altmetric performance of publications authored by Brazilian researchers: analysis of CNPq productivity scholarship holders (Ronaldo Ferreira Araujo - 17 July, 2018)
The online attention data are analysed according to their distribution by density and variation; language of the publication and field of knowledge; and by average performance of the type of source that has provided its altmetric values. The density evidences the long tail behavior of the variable, with most part of the articles with altmetrics score = 0, while few articles have a high index
Link: https://arxiv.org/abs/1807.06366
====================================================
Theme-weighted Ranking of Keywords from Text Documents using Phrase Embeddings (Debanjan Mahata - 16 July, 2018)
Keyword extraction is a fundamental task in natural language processing that facilitates mapping of documents to a concise set of representative single and multi-word phrases. The evaluations for ranked keyword extraction are performed on two benchmark datasets comprising of short abstracts (Inspec), and long scientific papers (SemEval 2010), and is shown to produce results better than the state-of-the-art systems.
Link: https://arxiv.org/abs/1807.05962
====================================================
LATE Ain'T Earley: A Faster Parallel Earley Parser (Peter Ahrens - 15 July, 2018)
We show that the LATE algorithm can achieve a 120x speedup over the Earley algorithm on a natural language task.
Link: https://arxiv.org/abs/1807.05642
====================================================
Deriving AOC C-Models from D&V Languages for Single- or Multi-Threaded Execution Using C or C++ (Tobias Strauch - 14 July, 2018)
The C language is getting more and more popular as a design and verification language (DVL). SystemC, ParC [1] and Cx [2] are based on C. Chisel [3]) or classical DVLs such as VHDL or Verilog
Link: https://arxiv.org/abs/1807.05442
====================================================
Image Classification for Arabic: Assessing the Accuracy of Direct English to Arabic Translations (Abdulkareem Alsudais - 13 July, 2018)
Most of the available research focuses on image classification for the English language, however there is very little research on image classification for the Arabic language. Results indicated that that 65.6% of the Arabic labels were accurate
Link: https://arxiv.org/abs/1807.05206
====================================================
Low-Resource Text Classification using Domain-Adversarial Learning (Daniel GrieÃhaber - 13 July, 2018)
Deep learning techniques have recently shown to be successful in many natural language processing tasks forming state-of-the-art systems
Link: https://arxiv.org/abs/1807.05195
====================================================
New/s/leak 2.0 - Multilingual Information Extraction and Visualization for Investigative Journalism (Gregor Wiedemann - 13 July, 2018)
It includes three novel main features: 1) automatic language detection and language-dependent information extraction for 40 languages, 2) entity and keyword visualization for efficient exploration, and 3) decentral deployment for analysis of confidential data from various formats
Link: https://arxiv.org/abs/1807.05151
====================================================
Metric Semantics for Probabilistic Relational Reasoning (Arthur Azevedo de Amorim - 13 July, 2018)
The Fuzz programming language [Reed and Pierce, 2010] uses an elegant linear type system to express and reason about function sensitivity properties, most notably Îµ-differential privacy
Link: https://arxiv.org/abs/1807.05091
====================================================
Facilitating information system development with Panoramic view on data (Dejan LavbiÄ - 13 July, 2018)
Panorama therefore facilitates traversing through data by following associations where user does not need to be familiar with the query language, the data structure and does not need to know the problem domain fully. In such cases the development of selected problem domains is shortened up to 25%, where emphasis is mainly on analysis, logical design and testing, while omitting physical design and programming, which is performed automatically by Panorama tool.
Link: https://arxiv.org/abs/1807.04998
====================================================
A Survey Investigating Usage of Virtual Personal Assistants (Mateusz Dubiel - 12 July, 2018)
Despite significant improvements in automatic speech recognition and spoken language understanding - human interaction with Virtual Personal Assistants (VPAs) through speech remains irregular and sporadic. According to recent studies, currently the usage of VPAs is constrained to basic tasks such as checking facts, playing music, and obtaining weather updates.In this paper, we present results of a survey (N = 118) that analyses usage of VPAs by frequent and infrequent users
Link: https://arxiv.org/abs/1807.04606
====================================================
STRICT: Information Retrieval Based Search Term Identification for Concept Location (Mohammad Masudur Rahman - 12 July, 2018)
Such natural language texts illustrate the change requirement involving various domain related concepts. Experiments using 1,939 change requests from eight subject systems report that STRICT can identify better quality search terms than baseline terms from 52%--62% of the requests with 30%--57% Top-10 retrieval accuracy which are promising
Link: https://arxiv.org/abs/1807.04475
====================================================
Cross-lingual Word Analogies using Linear Transformations between Semantic Spaces (TomÃ¡Å¡ BrychcÃ­n - 11 July, 2018)
We experiment with six languages within different language families, including English, German, Spanish, Italian, Czech, and Croatian. We achieve average accuracy of 51.1%, 43.1%, and 38.2% for monolingual, bilingual, and multilingual semantic spaces, respectively.
Link: https://arxiv.org/abs/1807.04175
====================================================
Universal Transformers (Mostafa Dehghani - 10 July, 2018)
Our experiments show that on various algorithmic tasks and a diverse set of large-scale language understanding tasks the Universal Transformer generalizes significantly better and outperforms both a vanilla Transformer and an LSTM in machine translation, and achieves a new state of the art on the bAbI linguistic reasoning task and the challenging LAMBADA language modeling task.
Link: https://arxiv.org/abs/1807.03819
====================================================
Foreign English Accent Adjustment by Learning Phonetic Patterns (Fedor Kitashov - 9 July, 2018)
For sufficiently large datasets, neural engines tend to outshine statistical models in most natural language processing problems. We use this statistical method to generate a million phonological variations of words from the CMU Pronouncing Dictionary and train a sequence-to-sequence RNN to recognize accented words with 59% accuracy.
Link: https://arxiv.org/abs/1807.03625
====================================================
Revisiting the Hierarchical Multiscale LSTM (Ãkos KÃ¡dÃ¡r - 10 July, 2018)
Hierarchical Multiscale LSTM (Chung et al., 2016a) is a state-of-the-art language model that learns interpretable structure from character-level input
Link: https://arxiv.org/abs/1807.03595
====================================================
HDFD --- A High Deformation Facial Dynamics Benchmark for Evaluation of Non-Rigid Surface Registration and Classification (Gareth Andrews - 9 July, 2018)
In this paper, we present a novel facial dynamic dataset HDFD which addresses the gap of existing datasets, including 4D funny faces with substantial non-isometric deformation, and 4D visual-audio faces of spoken phrases in a minority language (Welsh). Both datasets are captured from 21 participants
Link: https://arxiv.org/abs/1807.03354
====================================================
Discriminating between Indo-Aryan Languages Using SVM Ensembles (Alina Maria Ciobanu - 9 July, 2018)
The system competed in the Indo-Aryan Language Identification (ILI) shared task organized within the VarDial Evaluation Campaign 2018. Our best entry in the competition, named ILIdentification, scored 88:95% F1 score and it was ranked 3rd out of 8 teams.
Link: https://arxiv.org/abs/1807.03108
====================================================
Robust Text-to-SQL Generation with Execution-Guided Decoding (Chenglong Wang - 12 September, 2018)
We consider the problem of neural semantic parsing, which translates natural language questions into executable SQL queries. As a result, we achieve new state-of-the-art execution accuracy of 83.8% on WikiSQL.
Link: https://arxiv.org/abs/1807.03100
====================================================
Universal Word Segmentation: Implementation and Interpretation (Yan Shao - 9 July, 2018)
Our model obtains state-of-the-art accuracies on all the UD languages
Link: https://arxiv.org/abs/1807.02974
====================================================
RACK: Automatic API Recommendation using Crowdsourced Knowledge (Mohammad Masudur Rahman - 9 July, 2018)
In this paper, we propose a novel API recommendation technique--RACK that recommends a list of relevant APIs for a natural language query for code search by exploiting keyword-API associations from the crowdsourced knowledge of Stack Overflow. We first motivate our technique using an exploratory study with 11 core Java packages and 344K Java posts from Stack Overflow. Experiments using 150 code search queries randomly chosen from three Java tutorial sites show that our technique recommends correct API classes within the top 10 results for about 79% of the queries which is highly promising
Link: https://arxiv.org/abs/1807.02953
====================================================
Predicting Concreteness and Imageability of Words Within and Across Languages via Word Embeddings (Nikola LjubeÅ¡iÄ - 8 July, 2018)
We show that the notions of concreteness and imageability are highly predictable both within and across languages, with a moderate loss of up to 20% in correlation when predicting across languages
Link: https://arxiv.org/abs/1807.02903
====================================================
On the Complexity and Typology of Inflectional Morphological Systems (Ryan Cotterell - 7 July, 2018)
Our measurements are taken on large morphological paradigms from 31 typologically diverse languages.
Link: https://arxiv.org/abs/1807.02747
====================================================
A Deep Generative Model of Vowel Formant Typology (Ryan Cotterell - 7 July, 2018)
We develop a novel generative probability model and report results based on a corpus of 233 languages.
Link: https://arxiv.org/abs/1807.02745
====================================================
Recommender system for learning SQL using hints (Dejan LavbiÄ - 7 July, 2018)
In this study, we present a new approach to help users conceptualize basic building blocks of the language faster and more efficiently. Furthermore, we perform an empirical evaluation with 93 participants and demonstrate that the employment of hints is successful, being especially beneficial for users with lower prior knowledge.
Link: https://arxiv.org/abs/1807.02637
====================================================
Methodic of joint using the tools of automation of lexical and parsing analysis in the process of teaching the programming theory of future informatics teachers (S. O. Semerikov - 4 July, 2018)
The main conclusions and recommendations: 1) the considered example of the expanded calculator can be refined by changing the grammar, in particular - for the introduction of conditional and cyclic constructions; 2) the proposed scheme can be used to implement the interpreter of any formal language with an arbitrary typing method - the appropriate examples of study will be subsets of procedural languages Basic and C and functional languages Scheme and SML: provided the addition of the machine code generation phase, this provides an opportunity to demonstrate the full development cycle for programming language compiler.
Link: https://arxiv.org/abs/1807.02554
====================================================
Memory Augmented Policy Optimization for Program Synthesis and Semantic Parsing (Chen Liang - 19 September, 2018)
We evaluate MAPO on weakly supervised program synthesis from natural language / semantic parsing tasks. On the WikiTableQuestions benchmark we improve the state-of-the-art by 2.5%, achieving an accuracy of 46.2%, and on the WikiSQL benchmark, MAPO achieves an accuracy of 74.9% with only weak supervision, outperforming several strong baselines with full supervision
Link: https://arxiv.org/abs/1807.02322
====================================================
TextRank Based Search Term Identification for Software Change Tasks (Mohammad Masudur Rahman - 6 July, 2018)
Each of those requests is generally written using natural language texts, and it involves one or more domain related concepts. Experiments with 349 change tasks from two subject systems and comparison with one of the latest and closely related state-of-the-art approaches show that our technique is highly promising in terms of suggestion accuracy, mean average precision and recall.
Link: https://arxiv.org/abs/1807.02263
====================================================
Addressing the Barriers to Interlingual Rule-based Machine Translation with a Concept Specification and Abstraction Semantic Representation (Patrick Connor - 13 September, 2018)
However, it lacks popularity primarily because of the extensive training and labour required to define the language rules. To address this, we present a semantic representation that 1) treats all bits of meaning as individual concepts that 2) refine or further specify one another to build a network that relates entities in space and time. Also, the representation can 3) encapsulate propositions and thereby define concepts in terms of other concepts supporting the abstraction of underlying linguistic and ontological details
Link: https://arxiv.org/abs/1807.02226
====================================================
The Data Science of Hollywood: Using Emotional Arcs of Movies to Drive Business Model Innovation in Entertainment Industries (Marco Del Vecchio - 10 July, 2018)
Much of business literature addresses the issues of consumer-centric design: how can businesses design customized services and products which accurately reflect consumer preferences? This paper uses data science natural language processing methodology to explore whether and to what extent emotions shape consumer preferences for media and entertainment content. We find that like books all movie stories are dominated by 6 basic shapes
Link: https://arxiv.org/abs/1807.02221
====================================================
V-CNN: When Convolutional Neural Network encounters Data Visualization (Mao Yang - 12 June, 2018)
Especially, the convolutional neural network (CNN), one representative model of deep learning, achieves great successes in computer vision and natural language processing. Simulation results confirm V-CNN significantly outperforms other studies and the recall rate of each invasion category is more than 99.8%.
Link: https://arxiv.org/abs/1807.02164
====================================================
A Formal Ontology-Based Classification of Lexemes and its Applications (Sreekavitha Parupalli - 4 July, 2018)
The paper describes the enrichment of OntoSenseNet - a verb-centric lexical resource for Indian Languages. The manually annotated gold standard corpus consists 8483 verbs, 253 adverbs and 1673 adjectives
Link: https://arxiv.org/abs/1807.01996
====================================================
Chinese Lexical Analysis with Deep Bi-GRU-CRF Network (Zhenyu Jiao - 5 July, 2018)
Lexical analysis is believed to be a crucial step towards natural language understanding and has been widely studied. As evaluated by linguistic experts, the model achieved a 95.5% accuracy on the test set, roughly 13% relative error reduction over our (previously) best Chinese lexical analysis tool
Link: https://arxiv.org/abs/1807.01882
====================================================
Road surface 3d reconstruction based on dense subpixel disparity map estimation (Rui Fan - 5 July, 2018)
The algorithm is implemented in C language with a near real-time performance. The experimental results illustrate that the absolute error of the reconstruction varies from 0.1 mm to 3 mm.
Link: https://arxiv.org/abs/1807.01874
====================================================
Zipf's law in 50 languages: its structural pattern, linguistic interpretation, and cognitive motivation (Shuiyuan Yu - 5 July, 2018)
The statistical results show that Zipf's laws in 50 languages all share a 3-segment structural pattern, with each segment demonstrating distinctive linguistic properties and the lower segment invariably bending downwards to deviate from theoretical expectation
Link: https://arxiv.org/abs/1807.01855
====================================================
Program Language Translation Using a Grammar-Driven Tree-to-Tree Model (Mehdi Drissi - 4 July, 2018)
We find that this grammar-based tree-to-tree model outperforms the state of the art tree-to-tree model in translating between two programming languages on a previously used synthetic task.
Link: https://arxiv.org/abs/1807.01784
====================================================
BCSAT : A Benchmark Corpus for Sentiment Analysis in Telugu Using Word-level Annotations (Sreekavitha Parupalli - 4 July, 2018)
From OntoSenseNet, we extracted 11,000 adjectives, 253 adverbs, 8483 verbs and sentiment annotation is being done by language experts
Link: https://arxiv.org/abs/1807.01679
====================================================
Sequence-to-Sequence Data Augmentation for Dialogue Language Understanding (Yutai Hou - 4 July, 2018)
A novel diversity rank is incorporated into the utterance representation to make the model produce diverse utterances and these diversely augmented utterances help to improve the language understanding module. Experimental results on the Airline Travel Information System dataset and a newly created semantic frame annotation on Stanford Multi-turn, Multidomain Dialogue Dataset show that our framework achieves significant improvements of 6.38 and 10.04 F-scores respectively when only a training set of hundreds utterances is represented
Link: https://arxiv.org/abs/1807.01554
====================================================
Automata for Infinite Argumentation Structures (Pietro Baroni - 11 October, 2018)
In particular, the possibly infinite set of arguments is specified through the language recognized by a deterministic finite automaton while a suitable formalism, called attack expression, is introduced to describe the relation of attack between arguments. The proposed approach is shown to satisfy some desirable properties which can not be achieved through other "naive" uses of formal languages
Link: https://arxiv.org/abs/1810.04892
====================================================
Sequence-to-Sequence Models for Data-to-Text Natural Language Generation: Word- vs. Character-based Processing and Output Diversity (Glorianna Jagfeld - 11 October, 2018)
We present a comparison of word-based and character-based sequence-to-sequence models for data-to-text natural language generation, which generate natural language descriptions for structured inputs
Link: https://arxiv.org/abs/1810.04864
====================================================
FEther: An Extensible Definitional Interpreter for Smart-contract Verifications in Coq (Zheng Yang - 10 October, 2018)
It supports almost all semantics of the Solidity programing language, and simultaneously executes multiple types of symbols
Link: https://arxiv.org/abs/1810.04828
====================================================
End-to-End Content and Plan Selection for Data-to-Text Generation (Sebastian Gehrmann - 10 October, 2018)
Learning to generate fluent natural language from structured data with neural networks has become an common approach for NLG
Link: https://arxiv.org/abs/1810.04700
====================================================
Structured Argument Extraction of Korean Question and Command (Won Ik Cho - 10 October, 2018)
However, due to the non-canonicality of the spoken language, it is difficult to extract the content automatically from the conversation-style utterances. This is much harder for languages like Korean and Japanese since the agglutination between morphemes make it difficult for the machines to parse the sentence and understand the intention
Link: https://arxiv.org/abs/1810.04631
====================================================
Understanding Data Science Lifecycle Provenance via Graph Segmentation and Summarization (Hui Miao - 10 October, 2018)
Increasingly modern data science platforms today have non-intrusive and extensible provenance ingestion mechanisms to collect rich provenance and context information, handle modifications to the same file using distinguishable versions, and use graph data models (e.g., property graphs) and query languages (e.g., Cypher) to represent and manipulate the stored provenance/context information
Link: https://arxiv.org/abs/1810.04599
====================================================
Inferring User Gender from User Generated Visual Content on a Deep Semantic Space (David Semedo - 10 October, 2018)
We make the assumption that user's images contain a collection of visual elements that implicitly encode discriminative patterns that allow inferring its gender, in a language independent way
Link: https://arxiv.org/abs/1810.04531
====================================================
Is there Gender bias and stereotype in Portuguese Word Embeddings? (Brenda Salenave Santana - 10 October, 2018)
The objective of this work is to study gender implications related to stereotyped professions for women and men in the context of the Portuguese language.
Link: https://arxiv.org/abs/1810.04528
====================================================
New Vistas to study Bhartrhari: Cognitive NLP (Jayashree Gajjam - 10 October, 2018)
The notions of a sentence and a word as a meaningful linguistic unit in the language have been a subject matter for the discussion in many works that followed later on
Link: https://arxiv.org/abs/1810.04440
====================================================
Persistence pays off: Paying Attention to What the LSTM Gating Mechanism Persists (Giancarlo D. Salton - 10 October, 2018)
Language Models (LMs) are important components in several Natural Language Processing systems. Recurrent Neural Network LMs composed of LSTM units, especially those augmented with an external memory, have achieved state-of-the-art results
Link: https://arxiv.org/abs/1810.04437
====================================================
Improving Neural Text Simplification Model with Simplified Corpora (Jipeng Qiang - 10 October, 2018)
Text simplification (TS) can be viewed as monolingual translation task, translating between text variations within a single language. We train encoder-decoder model using synthetic sentence pairs and original sentence pairs, which can obtain substantial improvements on the available WikiLarge data and WikiSmall data compared with the state-of-the-art methods.
Link: https://arxiv.org/abs/1810.04428
====================================================
A Simple Java Code Generator for ACL2 Based on a Deep Embedding of ACL2 in Java (Alessandro Coglio - 9 October, 2018)
AIJ (ACL2 In Java) is a deep embedding in Java of an executable, side-effect-free, non-stobj-accessing subset of the ACL2 language without guards
Link: https://arxiv.org/abs/1810.04308
====================================================
Current Trends and Future Research Directions for Interactive Music (Mauricio Toro - 4 October, 2018)
In this review, it is explained and compared different software and formalisms used in music interaction: sequencers, computer-assisted improvisation, meta- instruments, score-following, asynchronous dataflow languages, synchronous dataflow languages, process calculi, temporal constraints and interactive scores
Link: https://arxiv.org/abs/1810.04276
====================================================
Image Captioning as Neural Machine Translation Task in SOCKEYE (Loris Bazzani - 10 October, 2018)
Image captioning is an interdisciplinary research problem that stands between computer vision and natural language processing. In this paper, we explore different decoders and attentional models popular in neural machine translation, namely attentional recurrent neural networks, self-attentional transformers, and fully-convolutional networks, which represent the current state of the art of neural machine translation
Link: https://arxiv.org/abs/1810.04101
====================================================
Learning Noun Cases Using Sequential Neural Networks (Sina Ahmadi - 9 October, 2018)
Morphological declension, which aims to inflect nouns to indicate number, case and gender, is an important task in natural language processing (NLP). Given the challenge of data sparsity in processing morphologically rich languages and also, the flexibility of sentence structures in such languages, we believe that modeling morphological dependencies can improve the performance of neural network models
Link: https://arxiv.org/abs/1810.03996
====================================================
Model Cards for Model Reporting (Margaret Mitchell - 5 October, 2018)
While we focus primarily on human-centered machine learning models in the application fields of computer vision and natural language processing, this framework can be used to document any trained machine learning model
Link: https://arxiv.org/abs/1810.03993
====================================================
textTOvec: Deep Contextualized Neural Autoregressive Models of Language with Distributed Compositional Prior (Pankaj Gupta - 10 October, 2018)
The LSTM-LM learns a vector-space representation of each word by accounting for word order in local collocation patterns and models complex characteristics of language (e.g., syntax and semantics), while the TM simultaneously learns a latent representation from the entire document and discovers the underlying thematic structure. We address this challenge by incorporating external knowledge into neural autoregressive topic models via a language modelling approach: we use word embeddings as input of a LSTM-LM with the aim to improve the word-topic mapping on a smaller and/or short-text corpus
Link: https://arxiv.org/abs/1810.03947
====================================================
Answer Extraction in Question Answering using Structure Features and Dependency Principles (Lokesh Kumar Sharma - 9 October, 2018)
Question Answering (QA) research is a significant and challenging task in Natural Language Processing. The motivation behind QA research is the need of user who is using state-of-the-art search engines
Link: https://arxiv.org/abs/1810.03918
====================================================
Comparing Models of Associative Meaning: An Empirical Investigation of Reference in Simple Language Games (Judy Hanwen Shen - 8 October, 2018)
Although language provides rich, compositional truth-conditional semantics to facilitate reference, speakers and listeners may sometimes lack the overall lexical and cognitive resources to guarantee successful reference through these means alone. However, language also has rich associational structures that can serve as a further resource for achieving successful reference
Link: https://arxiv.org/abs/1810.03717
====================================================
Overcoming Language Priors in Visual Question Answering with Adversarial Regularization (Sainandan Ramakrishnan - 8 October, 2018)
We then pose training as an adversarial game between the VQA model and this question-only adversary -- discouraging the VQA model from capturing language biases in its question encoding. We show empirically that it can improve performance significantly on a bias-sensitive split of the VQA dataset for multiple base models -- achieving state-of-the-art on this task
Link: https://arxiv.org/abs/1810.03649
====================================================
End-to-End Text Classification via Image-based Embedding using Character-level Networks (Shunsuke Kitada - 10 October, 2018)
However, when a model is fed character-level features of the above languages, it often causes overfitting due to a large number of character types. Through various experiments, we found and confirmed that our CE-CLCNN captured closely embedded features for visually and semantically similar characters and achieves state-of-the-art results on several open document classification tasks
Link: https://arxiv.org/abs/1810.03595
====================================================
Zero-Resource Multilingual Model Transfer: Learning What to Share (Xilun Chen - 8 October, 2018)
Our model leverages adversarial networks to learn language-invariant features and mixture-of-experts models to dynamically exploit the relation between the target language and each individual source language. This enables our model to learn effectively what to share between various languages in the multilingual setup
Link: https://arxiv.org/abs/1810.03552
====================================================
A Query Tool for Efficiently Investigating Risky Software Behaviors (Peng Gao - 4 October, 2018)
In particular, AIQL provides: (1) domain-specific data model and storage for storing the massive system monitoring data, (2) a domain-specific query language, Attack Investigation Query Language, which integrates critical primitives for risky behavior specification, and (3) an optimized query engine based on the characteristics of the data and the query to efficiently schedule the execution
Link: https://arxiv.org/abs/1810.03464
====================================================
Cross Script Hindi English NER Corpus from Wikipedia (Mohd Zeeshan Ansari - 8 October, 2018)
Moreover, the advancements in language processing research depends upon the availability of standard corpora. Such corpora may be of mixed lingual nature in which text is written using multiple languages predominantly using a single script only
Link: https://arxiv.org/abs/1810.03430
====================================================
Query Tracking for E-commerce Conversational Search: A Machine Comprehension Perspective (Yunlun Yang - 8 October, 2018)
However, comparing with the natural language understanding in traditional task-oriented dialog which focuses on slot filling and tracking, the query understanding in E-commerce conversational search is quite different and more challenging due to more diverse user expressions and complex intentions
Link: https://arxiv.org/abs/1810.03274
====================================================
Assessing Crosslingual Discourse Relations in Machine Translation (Karin Sim Smith - 7 October, 2018)
The challenge is to detect the discourse relations in the source text and determine whether these relations are correctly transferred crosslingually to the target language -- without a reference translation
Link: https://arxiv.org/abs/1810.03148
====================================================
MeetupNet Dublin: Discovering Communities in Dublin's Meetup Network (Arjun Pakrashi - 6 October, 2018)
A meetup group typically focuses on one specific topic of interest, such as sports, music, language, or technology
Link: https://arxiv.org/abs/1810.03046
====================================================
On shuffle products, acyclic automata and piecewise-testable languages (Simon Halfon - 6 October, 2018)
We show that the shuffle $L \unicode{x29E2} F$ of a piecewise-testable language $L$ and a finite language $F$ is piecewise-testable. The proof relies on a classic but little-used automata-theoretic characterization of piecewise-testable languages
Link: https://arxiv.org/abs/1810.02953
====================================================
Scalable Micro-planned Generation of Discourse from Structured Data (Anirban Laha - 5 October, 2018)
We present a framework for generating natural language description from structured data such as tables
Link: https://arxiv.org/abs/1810.02889
====================================================
From direct tagging to Tagging with sentences compression (Peihui Chen - 5 October, 2018)
In essence, the two tagging methods (direct tagging and tagging with sentences compression) are to tag the information we need by using regular expression which basing on the inherent language patterns of the natural language
Link: https://arxiv.org/abs/1810.02741
====================================================
TRANX: A Transition-based Neural Abstract Syntax Parser for Semantic Parsing and Code Generation (Pengcheng Yin - 5 October, 2018)
We present TRANX, a transition-based neural semantic parser that maps natural language (NL) utterances into formal meaning representations (MRs). TRANX uses a transition system based on the abstract syntax description language for the target MR, which gives it two major advantages: (1) it is highly accurate, using information from the syntax of the target MR to constrain the output space and model the information flow, and (2) it is highly generalizable, and can easily be applied to new types of MR by just writing a new abstract syntax description corresponding to the allowable structures in the MR
Link: https://arxiv.org/abs/1810.02720
====================================================
Thinging Ethics for Software Engineers (Sabah Al-Fedaghi - 25 September, 2018)
Accordingly, this paper explores a thinging schematization for ethical theories that can serve a role similar to that of modeling languages (e.g., UML)
Link: https://arxiv.org/abs/1810.02685
====================================================
Unfolding of Finite Concurrent Automata (Alexandre Mansard - 4 October, 2018)
A trace language is level-regular if the set of Foata normal forms of its elements is regular
Link: https://arxiv.org/abs/1810.02471
====================================================
Prototyping Formal System Models with Active Objects (Eduard Kamburjan - 4 October, 2018)
We propose active object languages as a development tool for formal system models of distributed systems. As a modeling language we use the formal active object language ABS which comes with an extensive tool set
Link: https://arxiv.org/abs/1810.02470
====================================================
Learning Compressed Transforms with Low Displacement Rank (Anna T. Thomas - 4 October, 2018)
When replacing weight layers in fully-connected, convolutional, and recurrent neural networks for image classification and language modeling tasks, our new classes exceed the accuracy of existing compression approaches, and on some tasks even outperform general unstructured layers while using more than 20X fewer parameters.
Link: https://arxiv.org/abs/1810.02309
====================================================
MyCaffe: A Complete C# Re-Write of Caffe with Reinforcement Learning (David W. Brown - 4 October, 2018)
MyCaffe is an open source, complete C# language re-write of Berkeley's Caffe
Link: https://arxiv.org/abs/1810.02272
====================================================
Neural Networks for Cross-lingual Negation Scope Detection (Federico Fancellu - 4 October, 2018)
Unfortunately, annotations are not available in other languages. Could a model that detects negation scope be applied to a language that it hasn't been trained on? We develop neural models that learn from cross-lingual word embeddings or universal dependencies in English, and test them on Chinese, showing that they work surprisingly well
Link: https://arxiv.org/abs/1810.02156
====================================================
Semi-Supervised Methods for Out-of-Domain Dependency Parsing (Juntao Yu - 4 October, 2018)
To bridge the performance gap between in-domain and out-of-domain, this thesis investigates three semi-supervised techniques for out-of-domain dependency parsing, namely co-training, self-training and dependency language models. The comparison between those techniques shows that self-training works equally well as co-training on out-of-domain parsing, while dependency language models can improve both in- and out-of-domain accuracies.
Link: https://arxiv.org/abs/1810.02100
====================================================
Balancing Efficiency and Coverage in Human-Robot Dialogue Collection (Matthew Marge - 7 October, 2018)
Comparison of the data gathered in these phases show that the GUI enabled a faster pace of dialogue while still maintaining high coverage of suitable responses, enabling more efficient targeted data collection, and improvements in natural language understanding using GUI-collected data
Link: https://arxiv.org/abs/1810.02017
====================================================
Fast Approach to Build an Automatic Sentiment Annotator for Legal Domain using Transfer Learning (Viraj Gamage - 3 October, 2018)
The added complexity of the language used in law, and the inability of the existing systems to accurately predict the sentiments of words in law are the main motivations behind this study
Link: https://arxiv.org/abs/1810.01912
====================================================
A Deep Learning Architecture for De-identification of Patient Notes: Implementation and Evaluation (Kaung Khin - 2 October, 2018)
Recent advances in natural language processing (NLP) has allowed for the use of deep learning techniques for the task of de-identification. We test this architecture on two gold standard datasets and show that the architecture achieves state-of-the-art performance on both data sets while also converging faster than other systems without the use of dictionaries or other knowledge sources.
Link: https://arxiv.org/abs/1810.01570
====================================================
Predicate learning in neural systems: Discovering latent generative structures (Andrea E. Martin - 2 October, 2018)
Humans learn complex latent structures from their environments (e.g., natural language, mathematics, music, social hierarchies)
Link: https://arxiv.org/abs/1810.01127
====================================================
Challenges of Using Text Classifiers for Causal Inference (Zach Wood-Doughty - 1 October, 2018)
To facilitate causal analyses based on language data, we consider the role that text classifiers can play in causal inference through established modeling mechanisms from the causality literature on missing data and measurement error
Link: https://arxiv.org/abs/1810.00956
====================================================
Relay: A New IR for Machine Learning Frameworks (Jared Roesch - 25 September, 2018)
Relay is being designed as a purely-functional, statically-typed language with the goal of balancing efficient compilation, expressiveness, and portability
Link: https://arxiv.org/abs/1810.00952
====================================================
Joint On-line Learning of a Zero-shot Spoken Semantic Parser and a Reinforcement Learning Dialogue Manager (Matthieu Riou - 1 October, 2018)
Unlike many other language processing applications, dialogue systems require interactions with users, therefore it is complex to develop them with pre-recorded data. Considering that well-performing solutions can be used directly off the shelf for speech recognition and synthesis, the study is focused on learning the spoken language understanding and dialogue management modules only
Link: https://arxiv.org/abs/1810.00924
====================================================
Visual Curiosity: Learning to Ask Questions to Learn Visual Recognition (Jianwei Yang - 1 October, 2018)
In order to do this, the agent must (1) understand what it recognizes and what it does not, (2) formulate a valid, unambiguous and informative language query (a question) to ask the Oracle, (3) derive the parameters of visual classifiers from the Oracle response and (4) leverage the updated visual classifiers to ask more clarified questions
Link: https://arxiv.org/abs/1810.00912
====================================================
Codestitcher: Inter-Procedural Basic Block Layout Optimization (Rahman Lavaee - 1 October, 2018)
Previous techniques of code layout optimization were developed one or two decades ago and have become inadequate to cope with the scale and complexity of new types of applications such as compilers, browsers, interpreters, language VMs and shared libraries.
Link: https://arxiv.org/abs/1810.00905
====================================================
Extending Stan for Deep Probabilistic Programming (Javier Burroni - 30 September, 2018)
To ease this task, we extend Stan, a popular high-level probabilistic programming language, to use deep neural networks written in PyTorch. Our translation clarifies the relationship between different families of probabilistic programming languages
Link: https://arxiv.org/abs/1810.00873
====================================================
Multimodal Interactive Learning of Primitive Actions (Tuan Do - 1 October, 2018)
We propose a framework that uses multimodal human-computer interaction to teach action concepts to machines, making use of both live demonstration and communication through natural language, as two distinct teaching modalities, while requiring few training samples.
Link: https://arxiv.org/abs/1810.00838
====================================================
Direct optimization of F-measure for retrieval-based personal question answering (Rasool Fakoor - 27 September, 2018)
Recent advances in spoken language technologies and the introduction of many customer facing products, have given rise to a wide customer reliance on smart personal assistants for many of their daily tasks
Link: https://arxiv.org/abs/1810.00679
====================================================
NEXUS Network: Connecting the Preceding and the Following in Dialogue Generation (Hui Su - 7 October, 2018)
To sidestep the non-differentiability of discrete natural language tokens, we introduce an auxiliary continuous code space and map such code space to a learnable prior distribution for generation purpose
Link: https://arxiv.org/abs/1810.00671
====================================================
Translating Navigation Instructions in Natural Language to a High-Level Plan for Behavioral Robot Navigation (Xiaoxue Zang - 24 September, 2018)
We propose an end-to-end deep learning model for translating free-form natural language instructions to a high-level plan for behavioral robot navigation
Link: https://arxiv.org/abs/1810.00663
====================================================
Hindi-English Code-Switching Speech Corpus (Ganji Sreeram - 23 September, 2018)
Code-switching refers to the usage of two languages within a sentence or discourse. This database can be applied in several speech signal processing applications, such as code-switching ASR, language identification, language modeling, speech synthesis etc
Link: https://arxiv.org/abs/1810.00662
====================================================
Predicted Variables in Programming (Victor Carbune - 1 October, 2018)
We present Predicted Variables (PVars), an approach to making machine learning (ML) a first class citizen in programming languages
Link: https://arxiv.org/abs/1810.00619
====================================================
Decentralized collaborative transport of fabrics using micro-UAVs (Ryan Cotsakis - 30 September, 2018)
For maximum flexibility to dynamic and unstructured environments and task demands, we propose a fully decentralized control infrastructure based on a swarm-specific scripting language, Buzz
Link: https://arxiv.org/abs/1810.00522
====================================================
A Simple Machine Learning Method for Commonsense Reasoning? A Short Commentary on Trinh & Le (2018) (Walid S. Saba - 30 September, 2018)
This is a short Commentary on Trinh & Le (2018) ("A Simple Method for Commonsense Reasoning") that outlines three serious flaws in the cited paper and discusses why data-driven approaches cannot be considered as serious models for the commonsense reasoning needed in natural language understanding in general, and in reference resolution, in particular.
Link: https://arxiv.org/abs/1810.00521
====================================================
A Human-Computer Interface Design for Quantitative Measure of Regret Theory (Longsheng Jiang - 30 September, 2018)
To make the questions natural and familiar to the subjects, we follow the insight that humans generate, quantify and communicate preference in natural language
Link: https://arxiv.org/abs/1810.00462
====================================================
anthem: Transforming gringo Programs into First-Order Theories (Preliminary Report) (Vladimir Lifschitz - 30 September, 2018)
In a recent paper by Harrison et al., the concept of program completion is extended to a large class of programs in the input language of the ASP grounder gringo. We would like to automate the process of generating and simplifying completion formulas for programs in that language, because examining the output produced by this kind of software may help programmers to see more clearly what their program does and to what degree its set of stable models conforms with their intentions
Link: https://arxiv.org/abs/1810.00453
====================================================
An Incremental Iterated Response Model of Pragmatics (Reuben Cohn-Gordon - 30 September, 2018)
Recent Iterated Response (IR) models of pragmatics conceptualize language use as a recursive process in which agents reason about each other to increase communicative efficiency
Link: https://arxiv.org/abs/1810.00367
====================================================
On the Winograd Schema Challenge: Levels of Language Understanding and the Phenomenon of the Missing Text (Walid S. Saba - 30 September, 2018)
Furthermore, we suggest that the WS is a special case of a more general phenomenon in language understanding, namely the phenomenon of the "missing text". In particular, we will argue that what we usually call thinking in the process of language understanding almost always involves discovering the missing text - text is rarely explicitly stated but is implicitly assumed as shared background knowledge
Link: https://arxiv.org/abs/1810.00324
====================================================
Tree2Tree Neural Translation Model for Learning Source Code Changes (Saikat Chakraborty - 30 September, 2018)
For instance, compared to natural language source code vocabulary can be virtually infinite. Thus, deploying state-of-the-art NMT models without domain adaptation may poorly serve the purpose
Link: https://arxiv.org/abs/1810.00314
====================================================
Older Adults and Crowdsourcing: Android TV App for Evaluating TEDx Subtitle Quality (Kinga Skorupska - 29 September, 2018)
It relies on the older adults' innate skills as long-time native language users and the motivating factors of this socially and personally beneficial task
Link: https://arxiv.org/abs/1810.00267
====================================================
NICE: Noise Injection and Clamping Estimation for Neural Network Quantization (Chaim Baskin - 2 October, 2018)
Convolutional Neural Networks (CNN) are very popular in many fields including computer vision, speech recognition, natural language processing, to name a few. This leads to state-of-the-art results on various regression and classification tasks, e.g., ImageNet classification with architectures such as ResNet-18/34/50 with low as 3-bit weights and activations
Link: https://arxiv.org/abs/1810.00162
====================================================
Memory and Resource Leak Defects and their Repairs in Java Projects (Mohammadreza Ghanavati - 28 September, 2018)
Despite huge software engineering efforts and programming language support, resource and memory leaks are still a troublesome issue, even in memory-managed languages such as Java
Link: https://arxiv.org/abs/1810.00101
====================================================
Functional Maps Representation on Product Manifolds (Emanuele RodolÃ  - 28 September, 2018)
We model maps as densities over the product manifold of the input shapes; these densities can be treated as scalar functions and therefore are manipulable using the language of signal processing on manifolds
Link: https://arxiv.org/abs/1809.10940
====================================================
Enabling FAIR Research in Earth Science through Research Objects (Andres Garcia-Silva - 27 September, 2018)
During this journey, our work has been comprehensive, with outcomes including: an extended research object model adapted to the needs of earth scientists; the provisioning of digital object identifiers (DOI) to enable persistent identification and to give due credit to authors; the generation of content-based, semantically rich, research object metadata through natural language processing, enhancing visibility and reuse through recommendation systems and third-party search engines; and various types of checklists that provide a compact representation of research object quality as a key enabler of scientific reuse
Link: https://arxiv.org/abs/1809.10617
====================================================
Generating Ontologies from Templates: A Rule-Based Approach for Capturing Regularity (Henrik Forssell - 27 September, 2018)
The language and our results are independent of any specific DL. We define the language and its semantics, including the case of negation-as-failure, investigate reasoning over ontologies specified using our language, and show results about the decidability of useful reasoning tasks about the language itself
Link: https://arxiv.org/abs/1809.10436
====================================================
Making View Update Strategies Programmable - Toward Controlling and Sharing Distributed Data - (Yasuhito Asano - 27 September, 2018)
Despite long and intensive research on views in both the database community and the programming language community, we are facing difficulties to use views in practice. This paper aims to provide a new language-based approach to controlling and sharing distributed data based on views, and establish a software foundation for systematic construction of such data management systems
Link: https://arxiv.org/abs/1809.10357
====================================================
Vector Learning for Cross Domain Representations (Shagan Sah - 26 September, 2018)
Our model conditions image generation on a natural language caption
Link: https://arxiv.org/abs/1809.10312
====================================================
Semantic Sentence Embeddings for Paraphrasing and Text Summarization (Chi Zhang - 26 September, 2018)
This paper introduces a sentence to vector encoding framework suitable for advanced natural language processing. Experimental results help gain insight how vector representations are suitable for advanced language embedding.
Link: https://arxiv.org/abs/1809.10267
====================================================
'Senator, We Sell Ads': Analysis of the 2016 Russian Facebook Ads Campaign (Ritam Dutt - 26 September, 2018)
We analyzed the ads using natural language processing techniques to determine textual and semantic features associated with the most effective ones
Link: https://arxiv.org/abs/1809.10158
====================================================
Pay attention! - Robustifying a Deep Visuomotor Policy through Task-Focused Attention (Pooya Abolghasemi - 26 September, 2018)
The manipulation task is specified with a natural language text such as "move the red bowl to the left"
Link: https://arxiv.org/abs/1809.10093
====================================================
General-purpose Declarative Inductive Programming with Domain-Specific Background Knowledge for Data Wrangling Automation (Lidia Contreras-Ochando - 26 September, 2018)
Here we show that with the use of general-purpose declarative (programming) languages jointly with generic IP systems and the definition of domain-specific knowledge, many specific data wrangling problems from different application domains can be automatically solved from very few examples
Link: https://arxiv.org/abs/1809.10054
====================================================
Language Modeling Teaches You More Syntax than Translation Does: Lessons Learned Through Auxiliary Task Analysis (Kelly W. Zhang - 26 September, 2018)
We find that representations from language models consistently perform best on our syntactic auxiliary prediction tasks, even when trained on relatively small amounts of data. These results suggest that language modeling may be the best data-rich pretraining task for transfer learning applications requiring syntactic information
Link: https://arxiv.org/abs/1809.10040
====================================================
Personalized Education at Scale (Sam Saarinen - 24 September, 2018)
We propose that emerging technologies in reinforcement learning (RL), as well as semi-supervised learning, natural language processing, and computer vision are critical to leveraging this data to provide personalized education at scale.
Link: https://arxiv.org/abs/1809.10025
====================================================
Computational and informatics advances for reproducible data analysis in neuroimaging (Russell A. Poldrack - 24 September, 2018)
We outline how the open-source Python language has provided the basis for a data science platform that enables reproducible data analysis and visualization
Link: https://arxiv.org/abs/1809.10024
====================================================
Towards Safer Smart Contracts: A Survey of Languages and Verification Methods (Dominik Harz - 26 September, 2018)
First, we introduce several smart contract languages focussing on security features. Accordingly, we introduce their verification approach, level of automation, coverage, and supported languages
Link: https://arxiv.org/abs/1809.09805
====================================================
Skeletal Semantics and their Interpretations (Martin Bodin - 25 September, 2018)
We develop a meta-language for a skeletal semantics of a language, where each skeleton describes the complete semantic behaviour of a language construct. We define a general notion of interpretation, which provides a systematic and language-independent way of deriving semantic judgements from the skeletal semantics
Link: https://arxiv.org/abs/1809.09749
====================================================
Non-native children speech recognition through transfer learning (Marco Matassoni - 25 September, 2018)
A multi-lingual model is adopted as baseline, where a common phonetic lexicon, defined in terms of the units of the International Phonetic Alphabet (IPA), is shared across the three languages at hand (Italian, German and English); DNN adaptation methods based on transfer learning are evaluated on significant non-native evaluation sets. Results show that the resulting non-native models allow a significant improvement with respect to a mono-lingual system adapted to speakers of the target language.
Link: https://arxiv.org/abs/1809.09658
====================================================
A Re-ranker Scheme for Integrating Large Scale NLU models (Chengwei Su - 25 September, 2018)
Large scale Natural Language Understanding (NLU) systems are typically trained on large quantities of data, requiring a fast and scalable training strategy
Link: https://arxiv.org/abs/1809.09605
====================================================
Tangent: Automatic differentiation using source-code transformation for dynamically typed array programming (Bart van MerriÃ«nboer - 26 September, 2018)
We implement and demonstrate these ideas in the Tangent software library for Python, the first AD framework for a dynamic language that uses SCT.
Link: https://arxiv.org/abs/1809.09569
====================================================
On finitely ambiguous BÃ¼chi automata (Christof LÃ¶ding - 25 September, 2018)
We adapt existing notions and results concerning finite and bounded ambiguity of finite automata to the setting of $Ï$-languages and present a translation from arbitrary nondeterministic BÃ¼chi automata with $n$ states to finitely ambiguous automata with at most $3^n$ states and at most $n$ accepting runs per word.
Link: https://arxiv.org/abs/1809.09415
====================================================
HSTREAM: A directive-based language extension for heterogeneous stream computing (Suejb Memeti - 25 September, 2018)
In this paper, we present HSTREAM, a compiler directive-based language extension to support programming stream computing applications for heterogeneous parallel computing systems. We demonstrate the usefulness of HSTREAM language extension with various applications from the STREAM benchmark
Link: https://arxiv.org/abs/1809.09387
====================================================
Scenic: Language-Based Scene Generation (Daniel J. Fremont - 24 September, 2018)
We design a domain-specific language, Scenic, for describing "scenarios" that are distributions over scenes. As a probabilistic programming language, Scenic allows assigning distributions to features of the scene, as well as declaratively imposing hard and soft constraints over the scene
Link: https://arxiv.org/abs/1809.09310
====================================================
Resilient Computing with Reinforcement Learning on a Dynamical System: Case Study in Sorting (Aleksandra Faust - 24 September, 2018)
Taking advantage of this body of work, this paper formulates general computation as a feedback-control problem, which allows the agent to autonomously overcome some limitations of standard procedural language programming: resilience to errors and early program termination
Link: https://arxiv.org/abs/1809.09261
====================================================
Text Summarization as Tree Transduction by Top-Down TreeLSTM (Davide Bacciu - 24 September, 2018)
Extractive compression is a challenging natural language processing problem. The proposed model can achieve state of the art performance on sentence compression benchmarks, both in terms of accuracy and compression rate.
Link: https://arxiv.org/abs/1809.09096
====================================================
Jointly Multiple Events Extraction via Attention-based Graph Information Aggregation (Xiao Liu - 24 September, 2018)
Event extraction is of practical utility in natural language processing. The experiment results demonstrate that our proposed framework achieves competitive results compared with state-of-the-art methods.
Link: https://arxiv.org/abs/1809.09078
====================================================
A Fairness-aware Hybrid Recommender System (Golnoosh Farnadi - 12 September, 2018)
We implement our model using a powerful and expressive probabilistic programming language called probabilistic soft logic
Link: https://arxiv.org/abs/1809.09030
====================================================
Language Identification with Deep Bottleneck Features (Zhanyu Ma - 18 September, 2018)
In this paper we proposed an end-to-end short utterances speech language identification(SLD) approach based on a Long Short Term Memory (LSTM) neural network which is special suitable for SLD application in intelligent vehicles
Link: https://arxiv.org/abs/1809.08909
====================================================
ROI constrained Auctions (Benamin Heymann - 24 September, 2018)
A standard result from auction theory is that bidding truthfully in a second price auction is a weakly dominant strategy, or, in the language of digital advertising, 'the cost per mille (eCPM) is equal to the click through rate (CTR) times the cost per clicks (CPC)'
Link: https://arxiv.org/abs/1809.08837
====================================================
Sentence-Level Fluency Evaluation: References Help, But Can Be Spared! (Katharina Kann - 23 September, 2018)
Motivated by recent findings on the probabilistic modeling of acceptability judgments, we propose syntactic log-odds ratio (SLOR), a normalized language model score, as a metric for referenceless fluency evaluation of natural language generation output at the sentence level. We further introduce WPSLOR, a novel WordPiece-based version, which harnesses a more compact language model
Link: https://arxiv.org/abs/1809.08731
====================================================
Deformable Stacked Structure for Named Entity Recognition (Shuyang Cao - 28 September, 2018)
Neural architecture for named entity recognition has achieved great success in the field of natural language processing. Our model achieves the state-of-the-art performances on the OntoNotes dataset.
Link: https://arxiv.org/abs/1809.08730
====================================================
Context-Aware Attention for Understanding Twitter Abuse (Tuhin Chakrabarty - 23 September, 2018)
The complexity of the natural language constructs makes this task challenging
Link: https://arxiv.org/abs/1809.08726
====================================================
Computing with P Systems (Apostolos Syropoulos - 23 September, 2018)
The consequence of this and other such efforts is that they provide a solid ground for the implementation of real programming languages in existing hardware.
Link: https://arxiv.org/abs/1809.08664
====================================================
Gamifying the Escape from the Engineering Method Prison - An Innovative Board Game to Teach the Essence Theory to Future Project Managers and Software Engineers (Kai-Kristian Kemell - 23 September, 2018)
Essence consists of a language for modeling Software Engineering (SE) practices and methods and a kernel containing what its authors describe as being elements that are present in every software development project. Using the language of the specification, Essence can be used to model any software development method or practice
Link: https://arxiv.org/abs/1809.08656
====================================================
Mind Your Language: Abuse and Offense Detection for Code-Switched Languages (Raghav Kapoor - 23 September, 2018)
The task is made difficult due to non-fixed grammar, vocabulary, semantics and spellings of Hinglish language. This model surpasses the performance shown by the current best models to establish itself as the state-of-the-art in the unexplored domain of Hinglish offensive text classification.We also release our model and the embeddings trained for research purposes
Link: https://arxiv.org/abs/1809.08652
====================================================
Medical Knowledge Embedding Based on Recursive Neural Network for Multi-Disease Diagnosis (Jingchi Jiang - 22 September, 2018)
The representation of knowledge based on first-order logic captures the richness of natural language and supports multiple probabilistic inference models
Link: https://arxiv.org/abs/1809.08422
====================================================
Learning to Localize and Align Fine-Grained Actions to Sparse Instructions (Meera Hahn - 22 September, 2018)
The task is challenging due to the difficulty of bridging the semantic gap between the visual and natural language domains
Link: https://arxiv.org/abs/1809.08381
====================================================
Accelerating Test Automation through a Domain Specific Language (Anurag Dwarakanath - 21 September, 2018)
ATAP allows the creation of an automation test script through a domain specific language based on English
Link: https://arxiv.org/abs/1809.08100
====================================================
Towards Better Understanding Researcher Strategies in Cross-Lingual Event Analytics (Simon Gottschalk - 21 September, 2018)
Such analytics is particularly challenging due to the large amount of content, the event dynamics and the language barrier. Although memory institutions increasingly collect event-centric Web content in different languages, very little is known about the strategies of researchers who conduct analytics of such content
Link: https://arxiv.org/abs/1809.08084
====================================================
Multimodal Dual Attention Memory for Video Story Question Answering (Kyung-Min Kim - 21 September, 2018)
Using this processing pipeline, MDAM learns to infer a high-level vision-language joint representation from an abstraction of the full video content. For both datasets, MDAM achieves new state-of-the-art results with significant margins compared to the runner-up models
Link: https://arxiv.org/abs/1809.07999
====================================================
Paraphrase Detection on Noisy Subtitles in Six Languages (Eetu SjÃ¶blom - 21 September, 2018)
We perform automatic paraphrase detection on subtitle data from the Opusparcus corpus comprising six European languages: German, English, Finnish, French, Russian, and Swedish
Link: https://arxiv.org/abs/1809.07978
====================================================
Robot Communication Via Motion: Closing the Underwater Human-Robot Interaction Loop (Michael Fulton - 21 September, 2018)
To evaluate this system, we develop simulated examples of the system's body language gestures, called kinemes, and compare them to a baseline system using flashing colored lights through a user study. We thus contribute to "closing the loop" for human-robot interaction underwater by proposing and testing this system, suggesting a library of possible body language gestures for underwater robots, and offering insight on the design of nonverbal robot-to-human communication methods.
Link: https://arxiv.org/abs/1809.07948
====================================================
Modalities, Cohesion, and Information Flow (G. A. Kavvos - 20 September, 2018)
This leads to the conclusion that cohesion is a particularly useful setting for the study of both information flow, but also modalities in type theory and programming languages at large.
Link: https://arxiv.org/abs/1809.07897
====================================================
Predicting Argumenthood of English Preposition Phrases (Najoung Kim - 24 September, 2018)
In natural language processing, argumenthood information is important in tasks such as semantic role labeling (SRL) and preposition phrase (PP) attachment disambiguation
Link: https://arxiv.org/abs/1809.07889
====================================================
Metric Learning for Phoneme Perception (Yair Lakretz - 20 September, 2018)
Metric functions for phoneme perception capture the similarity structure among phonemes in a given language and therefore play a central role in phonology and psycho-linguistics. Finally, we explore how the metric function and perceptual saliencies of phonological features may vary across languages
Link: https://arxiv.org/abs/1809.07824
====================================================
Bootstrapping Transliteration with Constrained Discovery for Low-Resource Languages (Shyam Upadhyay - 20 September, 2018)
This opens the task to languages for which large number of training examples are unavailable. We present a comprehensive evaluation of our approach on nine languages, each written in a unique script.
Link: https://arxiv.org/abs/1809.07807
====================================================
Symbolic Priors for RNN-based Semantic Parsing (Chunyang Xiao - 20 September, 2018)
While in principle they can be trained directly on pairs (natural language utterances, logical forms), their performance is limited by the amount of available data
Link: https://arxiv.org/abs/1809.07721
====================================================
A Serverless Tool for Platform Agnostic Computational Experiment Management (Gregory Kiar - 2 September, 2018)
While web-portals make resources widely accessible, data organizations such as the Brain Imaging Data Structure and tool description languages such as Boutiques provide researchers with a foothold to tackle these problems using their own datasets, pipelines, and environments
Link: https://arxiv.org/abs/1809.07693
====================================================
Investigating Linguistic Pattern Ordering in Hierarchical Natural Language Generation (Shang-Yu Su - 19 September, 2018)
Natural language generation (NLG) is a critical component in spoken dialogue system, which can be divided into two phases: (1) sentence planning: deciding the overall sentence structure, (2) surface realization: determining specific word forms and flattening the sentence structure into a string
Link: https://arxiv.org/abs/1809.07629
====================================================
Lessons learned in multilingual grounded language learning (Ãkos KÃ¡dÃ¡r - 20 September, 2018)
We show that multilingual training improves over bilingual training, and that low-resource languages benefit from training with higher-resource languages. We demonstrate that a multilingual model can be trained equally well on either translations or comparable sentence pairs, and that annotating the same set of images in multiple language enables further improvements via an additional caption-caption ranking objective.
Link: https://arxiv.org/abs/1809.07615
====================================================
Syntactico-Semantic Reasoning using PCFG, MEBN, and PR-OWL (Shrinivasan R Patnaik Patnaikuni - 20 September, 2018)
Further upper ontology like Probabilistic Ontology Web Language (PR-OWL) built using MEBN takes care of probabilistic ontologies which model and capture the uncertainties inherent in the domain's semantic information
Link: https://arxiv.org/abs/1809.07607
====================================================
A Quantitative Evaluation of Natural Language Question Interpretation for Question Answering Systems (Takuto Asakura - 20 September, 2018)
While currently there are a number of existing evaluation methods for natural language (NL) QA systems, most of them consider only the final answers, limiting their utility within a black box style evaluation
Link: https://arxiv.org/abs/1809.07485
====================================================
CRN++: Molecular Programming Language (Marko Vasic - 19 September, 2018)
This paper introduces CRN++, a new language for programming deterministic (mass-action) chemical kinetics to perform computation. Our language addresses the key challenge of embedding familiar imperative constructs into a set of chemical reactions happening simultaneously and manipulating real-valued concentrations
Link: https://arxiv.org/abs/1809.07430
====================================================
Interpretable Textual Neuron Representations for NLP (Nina Poerner - 19 September, 2018)
The representations highlight differences in syntax awareness between the language and visual models of the Imaginet architecture.
Link: https://arxiv.org/abs/1809.07291
====================================================
Unsupervised cross-lingual matching of product classifications (Denis Gordeev - 19 September, 2018)
Unsupervised cross-lingual embeddings mapping has provided a unique tool for completely unsupervised translation even for languages with different scripts
Link: https://arxiv.org/abs/1809.07234
====================================================
String Transduction with Target Language Models and Insertion Handling (Garrett Nicolai - 19 September, 2018)
Many character-level tasks can be framed as sequence-to-sequence transduction, where the target is a word from a natural language. We show that leveraging target language models derived from unannotated target corpora, combined with a precise alignment of the training data, yields state-of-the art results on cognate projection, inflection generation, and phoneme-to-grapheme conversion.
Link: https://arxiv.org/abs/1809.07182
====================================================
A survey of advances in epistemic logic program solvers (Anthony P. Leclerc - 19 September, 2018)
Recent research in extensions of Answer Set Programming has included a renewed interest in the language of Epistemic Specifications, which adds modal operators K ("known") and M ("may be true") to provide for more powerful introspective reasoning and enhanced capability, particularly when reasoning with incomplete information. An epistemic logic program is a set of rules in this language
Link: https://arxiv.org/abs/1809.07141
====================================================
Latent Topic Conversational Models (Tsung-Hsien Wen - 19 September, 2018)
Our extensive experiments contribute to better understanding and training of conditional latent models for languages
Link: https://arxiv.org/abs/1809.07070
====================================================
NICT's Neural and Statistical Machine Translation Systems for the WMT18 News Translation Task (Benjamin Marie - 19 September, 2018)
For each translation direction, we prepared state-of-the-art statistical (SMT) and neural (NMT) machine translation systems. Our systems are ranked first for the Estonian-English and Finnish-English language pairs (constraint) according to BLEU-cased.
Link: https://arxiv.org/abs/1809.07037
====================================================
Multi-Task Learning for Machine Reading Comprehension (Yichong Xu - 18 September, 2018)
Empirical study shows that the proposed approach is orthogonal to the existing pre-trained representation models, such as word embedding and language models. Experiments on the Stanford Question Answering Dataset (SQuAD), the Microsoft MAchine Reading COmprehension Dataset (MS MARCO), NewsQA and other datasets show that our multi-task learning approach achieves significant improvement over state-of-the-art models in most MRC tasks.
Link: https://arxiv.org/abs/1809.06963
====================================================
Mind Your POV: Convergence of Articles and Editors Towards Wikipedia's Neutrality Norm (Umashanthi Pavalanathan - 18 September, 2018)
Does NPOV tagging help articles to converge to the desired style? Do NPOV corrections encourage editors to adopt this style? We study these questions using a corpus of NPOV-tagged articles and a set of lexicons associated with biased language. An interrupted time series analysis shows that after an article is tagged for NPOV, there is a significant decrease in biased language in the article, as measured by several lexicons
Link: https://arxiv.org/abs/1809.06951
====================================================
Argumentation Mining: Exploiting Multiple Sources and Background Knowledge (Anastasios Lytos - 18 September, 2018)
The recent progress in the wider field of Artificial Intelligence in combination with the available data through Social Web has create great potential for every sub-field of Natural Language Process including Argumentation Mining.
Link: https://arxiv.org/abs/1809.06943
====================================================
FRAGE: Frequency-Agnostic Word Representation (Chengyue Gong - 18 September, 2018)
Continuous word representation (aka word embedding) is a basic building block in many neural network-based models used in natural language processing tasks. We conducted comprehensive studies on ten datasets across four natural language processing tasks, including word similarity, language modeling, machine translation and text classification
Link: https://arxiv.org/abs/1809.06858
====================================================
Labyrinth: Compiling Imperative Control Flow to Parallel Dataflows (GÃ¡bor E. GÃ©vay - 20 September, 2018)
A natural approach is to provide imperative control flow constructs similar to those of mainstream programming languages: while-loops, if-statements, and mutable variables, whose values can change between iteration steps.
Link: https://arxiv.org/abs/1809.06845
====================================================
RumourEval 2019: Determining Rumour Veracity and Support for Rumours (Genevieve Gorrell - 18 September, 2018)
Scope is extended compared with the first RumourEval, in that the dataset is substantially expanded to include Reddit as well as Twitter data, and additional languages are also included.
Link: https://arxiv.org/abs/1809.06683
====================================================
Lung Cancer Concept Annotation from Spanish Clinical Narratives (Marjan Najafabadipour - 18 September, 2018)
The Information Extraction (IE) process requires Natural Language Processing (NLP) techniques to assign semantics to these patterns
Link: https://arxiv.org/abs/1809.06639
====================================================
Robust Spoken Language Understanding via Paraphrasing (Avik Ray - 17 September, 2018)
Learning intents and slot labels from user utterances is a fundamental step in all spoken language understanding (SLU) and dialog systems
Link: https://arxiv.org/abs/1809.06444
====================================================
DeClarE: Debunking Fake News and False Claims using Evidence-Aware Deep Learning (Kashyap Popat - 17 September, 2018)
It presents a neural network model that judiciously aggregates signals from external evidence articles, the language of these articles and the trustworthiness of their sources
Link: https://arxiv.org/abs/1809.06416
====================================================
Verification of High-Level Transformations with Inductive Refinement Types (Ahmad Salim Al-Sibahi - 17 September, 2018)
High-level transformation languages like Rascal include expressive features for manipulating large abstract syntax trees: first-class traversals, expressive pattern matching, backtracking and generalized iterators. We present the design and implementation of an abstract interpretation tool, Rabit, for verifying inductive type and shape properties for transformations written in such languages
Link: https://arxiv.org/abs/1809.06336
====================================================
FormuLog: Datalog for static analysis involving logical formulae (Aaron Bembenek - 17 September, 2018)
We have used FormuLog to implement declarative versions of symbolic execution and abstract model checking, analyses previously out of the scope of Datalog-based languages. While this paper focuses on the design of FormuLog and one of the analyses we have implemented in it, it also touches on a prototype implementation of the language and identifies performance optimizations that we believe will be necessary to scale FormuLog to real-world static analysis problems.
Link: https://arxiv.org/abs/1809.06274
====================================================
Improving Reinforcement Learning Based Image Captioning with Natural Language Prior (Tszhang Guo - 13 September, 2018)
To alleviate these issues, we propose a simple coherent solution that constrains the action space using an n-gram language prior
Link: https://arxiv.org/abs/1809.06227
====================================================
Unsupervised Sense-Aware Hypernymy Extraction (Dmitry Ustalov - 17 September, 2018)
Evaluation on two gold standard datasets for English and Russian shows that the method successfully recognizes hypernymy relationships that cannot be found with standard Hearst patterns and Wiktionary datasets for the respective languages.
Link: https://arxiv.org/abs/1809.06223
====================================================
Context-Dependent Diffusion Network for Visual Relationship Detection (Zhen Cui - 10 September, 2018)
The semantic graph is built through language priors to model semantic correlations across objects, whilst the visual scene graph defines the connections of scene objects so as to utilize the surrounding scene information. Experiments on two widely-used datasets demonstrate that our proposed method is more effective and achieves the state-of-the-art performance.
Link: https://arxiv.org/abs/1809.06213
====================================================
The Fast and the Flexible: training neural networks to learn to follow instructions from small data (Rezka Leonandya - 17 September, 2018)
In contrast, here we seek to establish whether this knowledge can be acquired automatically by a neural network system through a two phase training procedure: A (slow) offline learning stage where the network learns about the general structure of the task and a (fast) online adaptation phase where the network learns the language of a new given speaker. Moreover, even for human speakers whose language usage can depart significantly from our artificial training language, our network can still make use of its automatically acquired inductive bias to learn to follow instructions more effectively.
Link: https://arxiv.org/abs/1809.06194
====================================================
Study and Observation of the Variations of Accuracies for Handwritten Digits Recognition with Various Hidden Layers and Epochs using Convolutional Neural Network (Rezoana Bente Arif - 22 September, 2018)
In deep learning, Convolutional Neural Network (CNN) is extensively used in the pattern and sequence recognition, video analysis, natural language processing, spam detection, topic categorization, regression analysis, speech recognition, image classification, object detection, segmentation, face recognition, robotics, and control
Link: https://arxiv.org/abs/1809.06187
====================================================
The Space-Efficient Core of Vadalog (Gerald Berger - 16 September, 2018)
The logical core of the underlying Vadalog language is the warded fragment of tuple-generating dependencies (TGDs). We finally study the relative expressiveness of the query languages based on (piece-wise linear) warded sets of TGDs.
Link: https://arxiv.org/abs/1809.05951
====================================================
Curriculum-Based Neighborhood Sampling For Sequence Prediction (James O&#39; Neill - 16 September, 2018)
The task of multi-step ahead prediction in language models is challenging considering the discrepancy between training and testing. At test time, a language model is required to make predictions given past predictions as input, instead of the past targets that are provided during training
Link: https://arxiv.org/abs/1809.05916
====================================================
Classifying Process Instances Using Recurrent Neural Networks (Markku Hinkka - 16 September, 2018)
Additional contributions of our paper are improving the classification model training time by filtering infrequent activities, which is a technique commonly used, e.g., in Natural Language Processing (NLP).
Link: https://arxiv.org/abs/1809.05896
====================================================
Exploiting Errors for Efficiency: A Survey from Circuits to Algorithms (Phillip Stanley-Marbell - 16 September, 2018)
When a computational task tolerates a relaxation of its specification or when an algorithm tolerates the effects of noise in its execution, hardware, programming languages, and system software can trade deviations from correct behavior for lower resource usage. We present, for the first time, a synthesis of research results on computing systems that only make as many errors as their users can tolerate, from across the disciplines of computer aided design of circuits, digital system design, computer architecture, programming languages, operating systems, and information theory.
Link: https://arxiv.org/abs/1809.05859
====================================================
Towards Good Practices for Multi-modal Fusion in Large-scale Video Classification (Jinlai Liu - 27 September, 2018)
Inspired by the success of bilinear pooling in the visual and language fusion, we introduce multi-modal factorized bilinear pooling (MFB) to fuse visual and audio representations
Link: https://arxiv.org/abs/1809.05848
====================================================
Finding the way from Ã¤ to a: Sub-character morphological inflection for the SIGMORPHON 2018 Shared Task (Fynn SchrÃ¶der - 15 September, 2018)
The resulting system is a language-agnostic network model that aims to reduce the number of learned edit operations by introducing equivalence classes over graphical features of individual characters. We try to pinpoint advantages and drawbacks of this approach by comparing different network configurations and evaluating our results over a wide range of languages.
Link: https://arxiv.org/abs/1809.05742
====================================================
Neural Networks and Quantifier Conservativity: Does Data Distribution Affect Learnability? (Vishwali Mhasawade - 15 September, 2018)
We demonstrate that the aquisitional issues with non-conservative quantifiers can not be explained by the distribution of natural language data, which favors conservative quantifiers. This finding indicates that the bias in language acquisition data might be innate or representational.
Link: https://arxiv.org/abs/1809.05733
====================================================
XML Navigation and Transformation by Tree-Walking Automata and Transducers with Visible and Invisible Pebbles (Joost Engelfriet - 15 September, 2018)
The resulting pebble tree automata recognize the regular tree languages (i.e., can validate all generalized DTD's) and hence can find all matches of MSO definable patterns
Link: https://arxiv.org/abs/1809.05730
====================================================
Improving Natural Language Inference Using External Knowledge in the Science Questions Domain (Xiaoyan Wang - 15 September, 2018)
Natural Language Inference (NLI) is fundamental to many Natural Language Processing (NLP) applications including semantic search and question answering. Our model achieves the new state-of-the-art performance on the NLI problem over the SciTail science questions dataset.
Link: https://arxiv.org/abs/1809.05724
====================================================
QPCF: higher order languages and quantum circuits (Luca Paolini - 15 September, 2018)
qPCF is a paradigmatic quantum programming language that ex- tends PCF with quantum circuits and a quantum co-processor
Link: https://arxiv.org/abs/1809.05723
====================================================
Inferring Political Alignments of Twitter Users: A case study on 2017 Turkish constitutional referendum (Kutlu Emre Yilmaz - 15 September, 2018)
Relatively high accuracy scores obtained by full-text features may point to differences in language use, which deserves further research.
Link: https://arxiv.org/abs/1809.05699
====================================================
CLUSE: Cross-Lingual Unsupervised Sense Embeddings (Ta-Chung Chi - 15 September, 2018)
This paper proposes a modularized sense induction and representation learning model that jointly learns bilingual sense embeddings that align well in the vector space, where the cross-lingual signal in the English-Chinese parallel corpus is exploited to capture the collocation and distributed characteristics in the language pair
Link: https://arxiv.org/abs/1809.05694
====================================================
What's in a Downgrade? A Taxonomy of Downgrade Attacks in the TLS Protocol and Application Protocols Using TLS (Eman Salem Alashwali - 15 September, 2018)
Our taxonomy highlights clear and concrete aspects that many downgrade attacks have in common, and allows for a common language, classification, and comparison of downgrade attacks
Link: https://arxiv.org/abs/1809.05681
====================================================
Graph Convolutional Networks for Text Classification (Liang Yao - 15 September, 2018)
Our experimental results on multiple benchmark datasets demonstrate that a vanilla Text GCN without any external word embeddings or knowledge outperforms state-of-the-art methods for text classification. In addition, experimental results show that the improvement of Text GCN over state-of-the-art comparison methods become more prominent as we lower the percentage of training data, suggesting the robustness of Text GCN to less training data in text classification.
Link: https://arxiv.org/abs/1809.05679
====================================================
Gradual Session Types (Atsushi Igarashi - 15 September, 2018)
However, web-based applications and microservices are often written in a mix of languages, with type disciplines in a spectrum between static and dynamic typing
Link: https://arxiv.org/abs/1809.05649
====================================================
Geo-Text Data and Data-Driven Geospatial Semantics (Yingjie Hu - 14 September, 2018)
Many datasets nowadays contain links between geographic locations and natural language texts
Link: https://arxiv.org/abs/1809.05636
====================================================
Characterizing Variation in Crowd-Sourced Data for Training Neural Language Generators to Produce Stylistically Varied Outputs (Juraj Juraska - 14 September, 2018)
One of the biggest challenges of end-to-end language generation from meaning representations in dialogue systems is making the outputs more natural and varied
Link: https://arxiv.org/abs/1809.05288
====================================================
Deep CNN Frame Interpolation with Lessons Learned from Natural Language Processing (Kian Ghodoussi - 16 September, 2018)
However, recent developments in fields such as Natural Language Processing are demonstrating that this paradigm may be incorrect. From there, we demonstrate the effectiveness of our approach by presenting novel deep CNN frame interpolation architecture that is comparable to the state of the art interpolation models with a fraction of the complexity.
Link: https://arxiv.org/abs/1809.05286
====================================================
On the Strength of Character Language Models for Multilingual Named Entity Recognition (Xiaodong Yu - 20 September, 2018)
We demonstrate that CLMs provide a simple and powerful model for capturing these differences, identifying named entity tokens in a diverse set of languages at close to the performance of full NER systems. Moreover, by adding very simple CLM-based features we can significantly improve the performance of an off-the-shelf NER system for multiple languages.
Link: https://arxiv.org/abs/1809.05157
====================================================
IL-Net: Using Expert Knowledge to Guide the Design of Furcated Neural Networks (Khushmeen Sakloth - 13 September, 2018)
Through representation learning and automated feature engineering on large datasets, such models have been highly successful in computer vision and natural language applications. Compared to existing state-of-the-art approaches, we show that furcated networks can improve model accuracy by approximately 20-35%, without using additional labeled data
Link: https://arxiv.org/abs/1809.05127
====================================================
LiveBot: Generating Live Video Comments Based on Visual and Textual Contexts (Shuming Ma - 13 September, 2018)
Automatic live commenting requires AI agents to comprehend the videos and interact with human viewers who also make the comments, so it is a good testbed of an AI agent's ability of dealing with both dynamic vision and language
Link: https://arxiv.org/abs/1809.04938
====================================================
Multimodal Local-Global Ranking Fusion for Emotion Recognition (Paul Pu Liang - 12 August, 2018)
It is a significant technical challenge since humans display their emotions through complex idiosyncratic combinations of the language, visual and acoustic modalities
Link: https://arxiv.org/abs/1809.04931
====================================================
Image Captioning based on Deep Reinforcement Learning (Haichao Shi - 13 September, 2018)
What's more, with the complexity of understanding image content and diverse ways of describing image content in natural language, image captioning has been a challenging problem to deal with. To the best of our knowledge, most state-of-the-art methods follow a pattern of sequential model, such as recurrent neural networks (RNN)
Link: https://arxiv.org/abs/1809.04835
====================================================
Bounded Symbolic Execution for Runtime Error Detection of Erlang Programs (Emanuele De Angelis - 13 September, 2018)
Dynamically typed languages, like Erlang, allow developers to quickly write programs without explicitly providing any type information on expressions or function definitions. However, this feature makes those languages less reliable than statically typed languages, where many runtime errors can be detected at compile time
Link: https://arxiv.org/abs/1809.04770
====================================================
Zero-Shot Cross-lingual Classification Using Multilingual Neural Machine Translation (Akiko Eriguchi - 12 September, 2018)
Further, our system can perform classification in a new language for which no classification data was seen during training, showing that zero-shot classification is possible and remarkably competitive. Our results provide strong evidence that the representations learned from multilingual NMT systems are widely applicable across languages and tasks.
Link: https://arxiv.org/abs/1809.04686
====================================================
Game-Based Video-Context Dialogue (Ramakanth Pasunuru - 12 September, 2018)
This challenging testbed allows us to develop visually-grounded dialogue models that should generate relevant temporal and spatial event language from the live video, while also being relevant to the chat history
Link: https://arxiv.org/abs/1809.04560
====================================================
Unsupervised Controllable Text Formalization (Parag Jain - 10 September, 2018)
We propose a novel framework for controllable natural language transformation. The scorers, based on off-the-shelf language processing tools, decide the learning scheme of the encoder-decoder based on its actions
Link: https://arxiv.org/abs/1809.04556
====================================================
Using the Tsetlin Machine to Learn Human-Interpretable Rules for High-Accuracy Text Categorization with Medical Applications (Geir Thore Berge - 16 September, 2018)
We thus believe that our novel approach can have a significant impact on a wide range of text analysis applications, forming a promising starting point for deeper natural language understanding with the Tsetlin Machine.
Link: https://arxiv.org/abs/1809.04547
====================================================
Emo2Vec: Learning Generalized Emotion Representation by Multi-task Training (Peng Xu - 12 September, 2018)
We train Emo2Vec by multi-task learning six different emotion-related tasks, including emotion/sentiment analysis, sarcasm classification, stress detection, abusive language classification, insult detection, and personality recognition. When concatenated with GloVe, Emo2Vec achieves competitive performances to state-of-the-art results on several tasks using a simple logistic regression classifier.
Link: https://arxiv.org/abs/1809.04505
====================================================
The Visual QA Devil in the Details: The Impact of Early Fusion and Batch Norm on CLEVR (Mateusz Malinowski - 11 September, 2018)
Visual QA is a pivotal challenge for higher-level reasoning, requiring understanding language, vision, and relationships between many objects in a scene. In particular, we find that \textit{early fusion} of language and vision provides large performance improvements
Link: https://arxiv.org/abs/1809.04482
====================================================
An Integrated First-Order Theory of Points and Intervals over Linear Orders (Part II) (Willem Conradie - 15 September, 2018)
We consider here two-sorted first-order languages based on the same principle, and therefore including relations, as first studied by Reich, among others, between points, between intervals, and inter-sort. We give complete classifications of its sub-languages in terms of relative expressive power, thus determining how many, and which, are the intrinsically different extensions of two-sorted first-order logic with one or more such relations
Link: https://arxiv.org/abs/1809.04468
====================================================
Tuning the Performance of a Computational Persistent Homology Package (Alan Hylton - 8 September, 2018)
Eirene is a 5000-line open-source software library implemented in the dynamic programming language Julia
Link: https://arxiv.org/abs/1809.04424
====================================================
Neural Melody Composition from Lyrics (Hangbo Bao - 12 September, 2018)
In this paper, we study a novel task that learns to compose music from natural language
Link: https://arxiv.org/abs/1809.04318
====================================================
Safe Navigation with Human Instructions in Complex Scenes (Zhe Hu - 12 September, 2018)
In this paper, we present a robotic navigation algorithm with natural language interfaces, which enables a robot to safely walk through a changing environment with moving persons by following human instructions such as "go to the restaurant and keep away from people". By combining natural language processing, motion planning, and computer vision, our developed system is demonstrated to be able to successfully follow natural language navigation instructions to achieve navigation tasks in both simulated and real-world scenarios
Link: https://arxiv.org/abs/1809.04280
====================================================
Knowledge-Aware Conversational Semantic Parsing Over Web Tables (Yibo Sun - 12 September, 2018)
Third, external resource knowledge, i.e., provided by a pre-trained language model or an entity typing model, is used to improve the representation of question and table for a better semantic understanding. Results show that our knowledge-aware model outperforms the state-of-the-art approaches
Link: https://arxiv.org/abs/1809.04271
====================================================
Automatic, Personalized, and Flexible Playlist Generation using Reinforcement Learning (Shun-Yao Shih - 11 September, 2018)
By exploiting the techniques of deep learning and reinforcement learning, in this paper, we consider music playlist generation as a language modeling problem and solve it by the proposed attention language model with policy gradient. Considering a playlist as a sequence of words, we first train our attention RNN language model on baseline recommended playlists
Link: https://arxiv.org/abs/1809.04214
====================================================
Bidirectional Evaluation with Direct Manipulation (MikaÃ«l Mayer - 11 September, 2018)
We present an evaluation update (or simply, update) algorithm for a full-featured functional programming language, which synthesizes program changes based on output changes
Link: https://arxiv.org/abs/1809.04209
====================================================
What can linguistics and deep learning contribute to each other? (Tal Linzen - 14 September, 2018)
Linguists can contribute to research on neural networks for language technologies by clearly delineating the linguistic capabilities that can be expected of such systems, and by constructing controlled experimental paradigms that can determine whether those desiderata have been met. In the other direction, neural networks can benefit the scientific study of language by providing infrastructure for modeling human sentence processing and for evaluating the necessity of particular innate constraints on language acquisition.
Link: https://arxiv.org/abs/1809.04179
====================================================
Adversarial Propagation and Zero-Shot Cross-Lingual Transfer of Word Vector Specialization (Edoardo Maria Ponti - 11 September, 2018)
We report consistent improvements over distributional word vectors and vectors specialized by other state-of-the-art specialization frameworks. Finally, we also propose a cross-lingual transfer method for zero-shot specialization which successfully specializes a full target distributional space without any lexical knowledge in the target language and without any bilingual data.
Link: https://arxiv.org/abs/1809.04163
====================================================
Feature-Specific Profiling (Leif Andersen - 11 September, 2018)
Feature-specific profilers help programmers find expensive uses of specific features of their language. We describe the architecture of a profiler that implements our approach, explain prototypes of the profiler for two languages with different characteristics and implementation strategies, and provide empirical evidence for the approach's general usefulness as a performance debugging tool.
Link: https://arxiv.org/abs/1809.04151
====================================================
Limitations in learning an interpreted language with recurrent models (Denis Paperno - 11 September, 2018)
In this submission I report work in progress on learning simplified interpreted languages by means of recurrent models. The data is constructed to reflect core properties of natural language as modeled in formal syntax and semantics: recursive syntactic structure and compositionality
Link: https://arxiv.org/abs/1809.04128
====================================================
Can LSTM Learn to Capture Agreement? The Case of Basque (Shauli Ravfogel - 21 September, 2018)
Sequential neural networks models are powerful tools in a variety of Natural Language Processing (NLP) tasks. The sequential nature of these models raises the questions: to what extent can these models implicitly learn hierarchical structures typical to human language, and what kind of grammatical phenomena can they acquire?
Link: https://arxiv.org/abs/1809.04022
====================================================
Evaluating Semantic Rationality of a Sentence: A Sememe-Word-Matching Neural Network based on HowNet (Shu Liu - 11 September, 2018)
The methods based on the language model do not measure the sentence by rationality but by commonness
Link: https://arxiv.org/abs/1809.03999
====================================================
Assessing Composition in Sentence Vector Representations (Allyson Ettinger - 11 September, 2018)
An important component of achieving language understanding is mastering the composition of sentence meaning, but an immediate challenge to solving this problem is the opacity of sentence vector representations produced by current neural sentence composition models
Link: https://arxiv.org/abs/1809.03992
====================================================
Integration of Relational and Graph Databases Functionally (Jaroslav Pokorny - 11 September, 2018)
Then, a typed Î»-calculus, i.e., the language of lambda terms, will be used as a data manipulation lan-guage. Some integration options at the query language level are discussed.
Link: https://arxiv.org/abs/1809.03822
====================================================
Improving Adversarial Discriminative Domain Adaptation (Aaron Chadha - 10 September, 2018)
Beyond validating our framework on standard datasets like MNIST, MNIST-M, USPS and SVHN, we introduce and evaluate on a neuromorphic vision sensing (NVS) sign language recognition dataset, where the source domain constitutes emulated neuromorphic spike events converted from APS video and the target domain is experimental spike events from an NVS camera. Our results on all datasets show that our proposal is both simple and efficient, as it competes or outperforms the state-of-the-art in unsupervised domain adaptation.
Link: https://arxiv.org/abs/1809.03625
====================================================
Filling Missing Paths: Modeling Co-occurrences of Word Pairs and Dependency Paths for Recognizing Lexical Semantic Relations (Koki Washio - 10 September, 2018)
Recognizing lexical semantic relations between word pairs is an important task for many applications of natural language processing
Link: https://arxiv.org/abs/1809.03411
====================================================
Neural Latent Relational Analysis to Capture Lexical Semantic Relations in a Vector Space (Koki Washio - 10 September, 2018)
Capturing the semantic relations of words in a vector space contributes to many natural language processing tasks. In addition, when combined with a vector offset model, NLRA achieves a performance comparable to that of the state-of-the-art model that exploits additional semantic relational data.
Link: https://arxiv.org/abs/1809.03401
====================================================
SPASS: Scientific Prominence Active Search System with Deep Image Captioning Network (Dicong Qiu - 10 September, 2018)
Scientists can prespecify such search tasks in natural language and upload them to a rover, on which the deployed system constantly captions captured images with a deep image captioning network and compare the auto-generated captions to the prespecified search tasks by certain metrics so as to prioritize those images for transmission
Link: https://arxiv.org/abs/1809.03385
====================================================
xSense: Learning Sense-Separated Sparse Representations and Textual Definitions for Explainable Word Sense Networks (Ting-Yun Chang - 10 September, 2018)
Despite the success achieved on various natural language processing tasks, word embeddings are difficult to interpret due to the dense vector representations
Link: https://arxiv.org/abs/1809.03348
====================================================
Loop Patterns: Extension of Kleene Star Operator for More Expressive Pattern Matching against Arbitrary Data Structures (Satoshi Egi - 10 September, 2018)
The examples in this paper are coded in the Egison programming language, which features the customizable non-linear pattern-matching facility for non-free data types.
Link: https://arxiv.org/abs/1809.03252
====================================================
Learning to Generate Structured Queries from Natural Language with Indirect Supervision (Ziwei Bai - 10 September, 2018)
Generating structured query language (SQL) from natural language is an emerging research topic. This paper presents a new learning paradigm from indirect supervision of the answers to natural language questions, instead of SQL queries
Link: https://arxiv.org/abs/1809.03195
====================================================
Regular omega-Languages with an Informative Right Congruence (Dana Angluin - 9 September, 2018)
The same does not hold for regular omega-languages. The right congruence of a regular  omega-language is not informative enough; many regular omega-languages have a trivial right congruence, and in general it is not always possible to define an omega-automaton recognizing a given language that is isomorphic to the rightcon automaton.
Link: https://arxiv.org/abs/1809.03108
====================================================
On Computing the Measures of First-Order Definable Sets of Trees (Marcin PrzybyÅko - 9 September, 2018)
While the general case remains unsolved, we show that the measure of a language defined by a first-order formula with no descendant  relation or by a Boolean combination of conjunctive queries (with descendant relation) is rational and computable. Additionally, we provide an example of a first-order formula that uses descendant relation and defines a language of infinite trees having an irrational measure.
Link: https://arxiv.org/abs/1809.03104
====================================================
Temporal Logic and Model Checking for Operator Precedence Languages (Michele Chiari - 9 September, 2018)
building the "hidden syntax tree" of language sentences). We prove that our logic is at least as expressive as analogous logics defined for visible pushdown languages yet covering a much more powerful family; we design a procedure that, given a formula in our logic builds an automaton recognizing the sentences satisfying the formula, whose size is at most exponential in the length of the formula.
Link: https://arxiv.org/abs/1809.03100
====================================================
Classical Proofs as Parallel Programs (Federico Aschieri - 9 September, 2018)
The resulting functional language features a natural higher-order communication mechanism between processes, which also supports broadcasting
Link: https://arxiv.org/abs/1809.03094
====================================================
Evidence-based lean logic profiles for conceptual data modelling languages (Pablo RubÃ©n Fillottrani - 9 September, 2018)
Second, availing of this extended process, of evidence gathered of language feature usage, and of computational complexity insights from Description Logics (DL), we specify logic profiles taking into account the ontological commitments embedded in the languages. There is no known DL language that matches exactly the features of those profiles and the common core is small (in the tractable $\mathcal{ALNI}$)
Link: https://arxiv.org/abs/1809.03001
====================================================
Transforming Question Answering Datasets Into Natural Language Inference Datasets (Dorottya Demszky - 10 September, 2018)
Existing datasets for natural language inference (NLI) have propelled research on language understanding
Link: https://arxiv.org/abs/1809.02922
====================================================
Context-Free Transductions with Neural Stacks (Yiding Hao - 8 September, 2018)
Due to the architectural similarity between stack RNNs and pushdown transducers, we train stack RNN models on a number of tasks, including string reversal, context-free language modelling, and cumulative XOR evaluation
Link: https://arxiv.org/abs/1809.02836
====================================================
A natural language processing and geospatial clustering framework for harvesting local place names from geotagged housing advertisements (Yingjie Hu - 8 September, 2018)
The proposed framework consists of two stages: natural language processing (NLP) and geospatial clustering
Link: https://arxiv.org/abs/1809.02824
====================================================
Attentive Semantic Role Labeling with Boundary Indicator (Zhuosheng Zhang - 8 September, 2018)
The goal of semantic role labeling (SRL) is to discover the predicate-argument structure of a sentence, which plays a critical role in deep processing of natural language. Our syntax-agnostic model achieves competitive performance with state-of-the-art models on the CoNLL-2009 benchmarks both for English and Chinese.
Link: https://arxiv.org/abs/1809.02796
====================================================
I Know What You Want: Semantic Learning for Text Comprehension (Zhuosheng Zhang - 8 September, 2018)
Who did what to whom is a major focus in natural language understanding, which is right the aim of semantic role labeling (SRL). Extensive experiments on benchmark machine reading comprehension and inference datasets verify that the proposed semantic learning helps our system reach new state-of-the-art.
Link: https://arxiv.org/abs/1809.02794
====================================================
Sentiment analysis for Arabic language: A brief survey of approaches and techniques (Mo&#39;ath Alrefai - 15 September, 2018)
In the literature, there are numerous approaches proposed for automatic sentiment analysis for different language contexts. Each language has its own properties that makes the sentiment analysis more challenging
Link: https://arxiv.org/abs/1809.02782
====================================================
Affine Sessions (Dimitris Mostrous - 8 September, 2018)
Crucial to any language with session types is the notion of linearity, which is essential to ensure that channels exhibit the behaviour prescribed by their type without interference in the presence of concurrency. Moreover, our treatment does not affect the progress properties of the language: sessions never get stuck.
Link: https://arxiv.org/abs/1809.02781
====================================================
Exploiting Invertible Decoders for Unsupervised Sentence Representation Learning (Shuai Tang - 7 September, 2018)
However, parameters learnt in the decoder also contain useful information about language
Link: https://arxiv.org/abs/1809.02731
====================================================
What If We Simply Swap the Two Text Fragments? A Straightforward yet Effective Way to Test the Robustness of Methods to Confounding Signals in Nature Language Inference Tasks (Haohan Wang - 7 September, 2018)
Nature language inference (NLI) task is a predictive task of determining the inference relationship of a pair of natural language sentences. With the increasing popularity of NLI, many state-of-the-art predictive models have been proposed with impressive performances
Link: https://arxiv.org/abs/1809.02719
====================================================
On-line tracing of XACML-based policy coverage criteria (Francesca Lonetti - 7 September, 2018)
Currently, eXtensible Access Control Markup Language (XACML) has becoming the standard for implementing access control policies and consequently more attention is dedicated to testing the correctness of XACML policies
Link: https://arxiv.org/abs/1809.02712
====================================================
Empirical Vulnerability Analysis of Automated Smart Contracts Security Testing on Blockchains (Reza M. Parizi - 7 September, 2018)
However, writing trustworthy and safe smart contracts can be tremendously challenging because of the complicated semantics of underlying domain-specific languages and its testability. Accordingly, the goal of this paper is to carry out a far-reaching experimental assessment of current static smart contracts security testing tools, for the most widely used blockchain, the Ethereum and its domain-specific programming language, Solidity to provide the first...
Link: https://arxiv.org/abs/1809.02702
====================================================
Trick Me If You Can: Adversarial Writing of Trivia Challenge Questions (Eric Wallace - 7 September, 2018)
Modern natural language processing systems have been touted as approaching human performance
Link: https://arxiv.org/abs/1809.02701
====================================================
Neural Machine Translation of Logographic Languages Using Sub-character Level Information (Longtu Zhang - 7 September, 2018)
However, important differences between languages with logographic and alphabetic writing systems have long been overlooked. This study focuses on these differences and uses a simple approach to improve the performance of NMT systems utilizing decomposed sub-character level information for logographic languages
Link: https://arxiv.org/abs/1809.02694
====================================================
DreamNLP: Novel NLP System for Clinical Report Metadata Extraction using Count Sketch Data Streaming Algorithm: Preliminary Results (Sanghyun Choi - 25 August, 2018)
Extracting information from electronic health records (EHR) is a challenging task since it requires prior knowledge of the reports and some natural language processing algorithm (NLP)
Link: https://arxiv.org/abs/1809.02665
====================================================
A Transfer-Learnable Natural Language Interface for Databases (Wenlu Wang - 7 September, 2018)
Specifically, we introduce an automatic annotation mechanism that separates the schema and the data, where the schema also covers knowledge about natural language. Furthermore, we propose a customized sequence model that translates annotated natural language queries to SQL statements
Link: https://arxiv.org/abs/1809.02649
====================================================
Constrained Generation of Semantically Valid Graphs via Regularizing Variational Autoencoders (Tengfei Ma - 19 September, 2018)
Deep generative models have achieved remarkable success in various data domains, including images, time series, and natural languages
Link: https://arxiv.org/abs/1809.02630
====================================================
Logographic Subword Model for Neural Machine Translation (Yihao Fang - 7 September, 2018)
Compared to previous subword models, abstract subwords can be applied to various logographic languages. Considering most of the logographic languages are ancient and very low resource languages, these advantages are very desirable for archaeological computational linguistic applications such as a resource-limited offline hand-held Demotic-English translator.
Link: https://arxiv.org/abs/1809.02592
====================================================
Using Sparse Semantic Embeddings Learned from Multimodal Text and Image Data to Model Human Conceptual Knowledge (Steven Derby - 18 September, 2018)
Moreover, embeddings are often built from a single source of information (typically text data), even though neurocognitive research suggests that semantics is deeply linked to both language and perception. In this paper, we combine multimodal information from both text and image-based representations derived from state-of-the-art distributional models to produce sparse, interpretable vectors using Joint Non-Negative Sparse Embedding
Link: https://arxiv.org/abs/1809.02534
====================================================
Metamorphic Relation Based Adversarial Attacks on Differentiable Neural Computer (Alvin Chan - 7 September, 2018)
In this paper, we propose metamorphic relation based adversarial techniques for a range of tasks described in the natural processing language domain
Link: https://arxiv.org/abs/1809.02444
====================================================
Unsupervised Cross-lingual Word Embedding by Multilingual Neural Language Models (Takashi Wada - 7 September, 2018)
Accordingly, word embeddings of each language are mapped into a common latent space, making it possible to measure the similarity of words across multiple languages. 50k sentences) are available, or the domains of monolingual data are different across languages.
Link: https://arxiv.org/abs/1809.02306
====================================================
Data Augmentation for Spoken Language Understanding via Joint Variational Generation (Kang Min Yoo - 7 September, 2018)
Data scarcity is one of the main obstacles of domain adaptation in spoken language understanding (SLU) due to the high cost of creating manually tagged SLU datasets. Our approach not only helps alleviate the data scarcity issue in the SLU task for many datasets but also indiscriminately improves language understanding performances for various SLU models, supported by extensive experiments and rigorous statistical testing.
Link: https://arxiv.org/abs/1809.02305
====================================================
Dynamic Compositionality in Recursive Neural Networks with Structure-aware Tag Representations (Taeuk Kim - 6 September, 2018)
We show that models built upon the proposed architecture obtain superior performance on several sentence-level tasks such as sentiment analysis and natural language inference when compared against previous tree-structured models and other sophisticated neural models. In particular, our models achieve new state-of-the-art results on Stanford Sentiment Treebank, Movie Review, and Text Retrieval Conference datasets.
Link: https://arxiv.org/abs/1809.02286
====================================================
Relational Program Synthesis (Yuepeng Wang - 10 September, 2018)
We have implemented the proposed technique in a framework called Relish, which can be instantiated to different application domains by providing a suitable domain-specific language and the relevant relational specification
Link: https://arxiv.org/abs/1809.02283
====================================================
Assessing Gender Bias in Machine Translation -- A Case Study with Google Translate (Marcelo O. R. Prates - 13 September, 2018)
Although a systematic study of such biases can be difficult, we believe that automated translation tools can be exploited through gender neutral languages to yield a window into the phenomenon of gender bias in AI.
Link: https://arxiv.org/abs/1809.02208
====================================================
Future Directions for Optimizing Compilers (Nuno P. Lopes - 6 September, 2018)
As software becomes larger, programming languages become higher-level, and processors continue to fail to be clocked faster, we'll increasingly require compilers to reduce code bloat, eliminate abstraction penalties, and exploit interesting instruction sets
Link: https://arxiv.org/abs/1809.02161
====================================================
Object Hallucination in Image Captioning (Anna Rohrbach - 6 September, 2018)
We analyze how captioning model architectures and learning objectives contribute to object hallucination, explore when hallucination is likely due to image misclassification or language priors, and assess how well current sentence metrics capture object hallucination. Our analysis yields several interesting findings, including that models which score best on standard sentence metrics do not always have lower hallucination and that models which hallucinate more tend to make errors driven by language priors.
Link: https://arxiv.org/abs/1809.02156
====================================================
Deep Audio-Visual Speech Recognition (Triantafyllos Afouras - 6 September, 2018)
Unlike previous works that have focussed on recognising a limited number of words or phrases, we tackle lip reading as an open-world problem - unconstrained natural language sentences, and in the wild videos
Link: https://arxiv.org/abs/1809.02108
====================================================
Top-down Tree Structured Decoding with Syntactic Connections for Neural Machine Translation and Parsing (Jetic GÅ« - 6 September, 2018)
The addition of syntax-aware decoding in Neural Machine Translation (NMT) systems requires an effective tree-structured neural network, a syntax-aware attention model and a language generation model that is sensitive to sentence structure. We compare our NMT model with sequential and state of the art syntax-based NMT models and show that our model produces more fluent translations with better reordering
Link: https://arxiv.org/abs/1809.01854
====================================================
Noise Contrastive Estimation and Negative Sampling for Conditional Models: Consistency and Statistical Efficiency (Zhuang Ma - 6 September, 2018)
We show that the ranking-based variant of NCE gives consistent parameter estimates under weaker assumptions than the classification-based method; we analyze the statistical efficiency of the ranking-based and classification-based variants of NCE; finally we describe experiments on synthetic data and language modeling showing the effectiveness and trade-offs of both methods.
Link: https://arxiv.org/abs/1809.01812
====================================================
Interpretable Visual Question Answering by Reasoning on Dependency Trees (Qingxing Cao - 6 September, 2018)
In this paper, to better align image and language domains in diverse and unrestricted cases, we propose a novel neural network model that performs global reasoning on a dependency tree parsed from the question, and we thus phrase our model as parse-tree-guided reasoning network (PTGRN). Experiments on relational datasets demonstrate the superiority of our PTGRN over current state-of-the-art VQA methods, and the visualization results highlight the explainable capability of our reasoning system.
Link: https://arxiv.org/abs/1809.01810
====================================================
Stance Prediction for Russian: Data and Analysis (Nikita Lozhnikov - 3 October, 2018)
It introduces a new dataset, RuStance, of Russian tweets and news comments from multiple sources, covering multiple stories, as well as text classification approaches to stance detection as benchmarks over this data in this language. As well as presenting this openly-available dataset, the first of its kind for Russian, the paper presents a baseline for stance prediction in the language.
Link: https://arxiv.org/abs/1809.01574
====================================================
Learning Context-Sensitive Time-Decay Attention for Role-Based Dialogue Modeling (Shang-Yu Su - 5 September, 2018)
Spoken language understanding (SLU) is an essential component in conversational systems. The experiments on the benchmark Dialogue State Tracking Challenge (DSTC4) dataset show that the proposed role-based context-sensitive time-decay attention mechanisms significantly improve the state-of-the-art model for contextual understanding performance.
Link: https://arxiv.org/abs/1809.01557
====================================================
Neural DrugNet (Nishant Nikhil - 31 August, 2018)
Previous works demonstrate that LSTMs have achieved remarkable performance in natural language processing tasks. The first one is a pretrained language model appended with a classifier and takes words as input, while the second one is a LSTM model with an attention unit over it which takes character tri-gram as input
Link: https://arxiv.org/abs/1809.01500
====================================================
Chinese Discourse Segmentation Using Bilingual Discourse Commonality (Jingfeng Yang - 29 August, 2018)
With this definition, we conduct Chinese discourse segmentation with the help of English labeled data.Using discourse commonality between English and Chinese, we design an adversarial neural network framework to extract common language-independent features and language-specific features which are useful for discourse segmentation, when there is no or only a small scale of Chinese labeled data available
Link: https://arxiv.org/abs/1809.01497
====================================================
Learning Gender-Neutral Word Embeddings (Jieyu Zhao - 29 August, 2018)
Word embedding models have become a fundamental component in a wide range of Natural Language Processing (NLP) applications
Link: https://arxiv.org/abs/1809.01496
====================================================
Covariance and Controvariance: a fresh look at an old issue (a primer in advanced type systems for learning functional programmers) (Giuseppe Castagna - 10 September, 2018)
Twenty years ago, in an article titled "Covariance and contravariance: conflict without a cause", I argued that covariant and contravariant specialization of method parameters in object-oriented programming had different purposes and deduced that, not only they could, but actually they should both coexist in the same language.
Link: https://arxiv.org/abs/1809.01427
====================================================
Zero Shot Learning for Code Education: Rubric Sampling with Deep Learning Inference (Mike Wu - 5 September, 2018)
Rubric sampling requires minimal teacher effort, can associate feedback with specific parts of a student's solution and can articulate a student's misconceptions in the language of the instructor
Link: https://arxiv.org/abs/1809.01357
====================================================
Localizing Moments in Video with Temporal Language (Lisa Anne Hendricks - 5 September, 2018)
To benchmark whether our model, and other recent video localization models, can effectively reason about temporal language, we collect the novel TEMPOral reasoning in video and language (TEMPO) dataset. Our dataset consists of two parts: a dataset with real videos and template sentences (TEMPO - Template Language) which allows for controlled studies on temporal language, and a human language dataset which consists of temporal sentences annotated by humans (TEMPO - Human Language).
Link: https://arxiv.org/abs/1809.01337
====================================================
Neural MultiVoice Models for Expressing Novel Personalities in Dialog (Shereen Oraby - 5 September, 2018)
Natural language generators for task-oriented dialog should be able to vary the style of the output utterance while still effectively realizing the system dialog actions and their associated semantics
Link: https://arxiv.org/abs/1809.01331
====================================================
Learning User Preferences and Understanding Calendar Contexts for Event Scheduling (Donghyeon Kim - 5 September, 2018)
Although machine learning based event scheduling models have automated scheduling processes to some extent, they often fail to understand subtle user preferences and complex calendar contexts with event titles written in natural language. NESA successfully incorporates deep neural networks such as Bidirectional Long Short-Term Memory, Convolutional Neural Network, and Highway Network for learning the preferences of each user and understanding calendar context based on natural languages
Link: https://arxiv.org/abs/1809.01316
====================================================
Learning Concept Abstractness Using Weak Supervision (Ella Rabinovich - 4 September, 2018)
The results imply the applicability of this approach to additional properties of concepts, additional languages, and resource-scarce scenarios.
Link: https://arxiv.org/abs/1809.01285
====================================================
An automatic tool for checking multi-party contracts (Adilson Luiz Bonifacio - 4 September, 2018)
The problem of checking contracts has been largely addressed in the literature, but we are not aware about any method and tool that deals with multi-party contracts and conflict detection using a contract language. This work presents an automatic checker, so-called RECALL, for finding conflicts on multi-party contracts modeled by an extension of a contract language
Link: https://arxiv.org/abs/1809.01103
====================================================
Language Interoperability in Control Network Programming (Kostadin Kratchanov - 28 August, 2018)
We consider examples where the primitives in all those four programming languages are simultaneously used (multiple-language CNP). We also discuss CNP programming without programming (language-free CNP).
Link: https://arxiv.org/abs/1809.00976
====================================================
Minimum Violation Control Synthesis on Cyber-Physical Systems under Attacks (Luyao Niu - 31 August, 2018)
Cyber-physical systems are conducting increasingly complex tasks, which are often modeled using formal languages such as temporal logic
Link: https://arxiv.org/abs/1809.00975
====================================================
Translating C programs to MSVL programs (Meng Wang - 25 August, 2018)
C language is one of the most popular languages in system programming and applications written in C have been widely used by different industries. In order to improve the safety and reliability of these applications, a runtime verification tool UMC4MSVL based on Modeling, Simulation and Verification Language (MSVL) is employed
Link: https://arxiv.org/abs/1809.00959
====================================================
Segmentation-free compositional $n$-gram embedding (Geewook Kim - 4 September, 2018)
Applying conventional word embedding models to unsegmented languages, where word boundary is not clear, requires word segmentation as preprocessing
Link: https://arxiv.org/abs/1809.00918
====================================================
Non-monotonic Reasoning in Deductive Argumentation (Anthony Hunter - 4 September, 2018)
some form of modus ponens with a rule-based language, or classical logic)
Link: https://arxiv.org/abs/1809.00858
====================================================
The MISRA C Coding Standard and its Role in the Development and Analysis of Safety- and Security-Critical Embedded Software (Roberto Bagnara - 4 September, 2018)
In this paper, we introduce MISRA C, its role in the development of critical software, especially in embedded systems, its relevance to industry safety standards, as well as the challenges of working with a general-purpose programming language standard that is written in natural language with a slow evolution over the last 40+ years. We also outline the role of static analysis in the automatic checking of compliance with respect to MISRA C, and the role of the MISRA C language subset in enabling a wider application of formal methods to industrial software written in C.
Link: https://arxiv.org/abs/1809.00821
====================================================
Mapping Instructions to Actions in 3D Environments with Visual Goal Prediction (Dipendra Misra - 3 September, 2018)
We design a model that maps raw visual observations to goals using LINGUNET, a language-conditioned image generation network, and then generates the actions required to complete them
Link: https://arxiv.org/abs/1809.00786
====================================================
Automatic Event Salience Identification (Zhengzhong Liu - 3 September, 2018)
importance) of discourse units is an important task in language understanding
Link: https://arxiv.org/abs/1809.00647
====================================================
Typed Linear Algebra for Efficient Analytical Querying (JoÃ£o M. Afonso - 3 September, 2018)
The typed approach offers strong type checking (as in modern programming languages) and a diagrammatic way of expressing queries (paths in LA diagrams)
Link: https://arxiv.org/abs/1809.00641
====================================================
