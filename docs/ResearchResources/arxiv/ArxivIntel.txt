If there are any errors
please Abort, and run `arxiv_required` for required package installation, and start again
Please wait while we phrase the requested information from global arxiv[arxiv.org] servers 
------------>
---------------------------->
------------------------------------------------------>
 
ECHO-3DHPC: Advance the performance of astrophysics simulations with code modernization (Matteo Bugli - 10 October, 2018)
With the help of the Intel Software Development Tools, like Fortran compiler and Profile-Guided Optimization (PGO), Intel MPI library, VTune Amplifier and Inspector we have investigated the performance issues and improved the application scalability and the time to solution. The node-level performance is improved by $2.3 \times$ and, thanks to the improved threading parallelisation, the hybrid MPI-OpenMP version of the code outperforms the MPI-only, thus lowering the MPI communication overhead.
Link: https://arxiv.org/abs/1810.04597
====================================================
LIRS: Enabling efficient machine learning on NVM-based storage via a lightweight implementation of random shuffling (Zhi-Lin Ke - 10 October, 2018)
With the emerging non-volatile memory-based storage device, such as Intel Optane SSD, which provides fast random accesses, we propose a lightweight implementation of random shuffling (LIRS) to randomly shuffle the indexes of the entire training dataset, and the selected training instances are directly accessed from the storage and packed into batches. Experimental results show that LIRS can reduce the total training time of SVM and DNN by 49.9% and 43.5% on average, and improve the final testing accuracy on DNN by 1.01%.
Link: https://arxiv.org/abs/1810.04509
====================================================
Studies on the energy and deep memory behaviour of a cache-oblivious, task-based hyperbolic PDE solver (Dominic E. Charrier - 9 October, 2018)
However, in cases where memory-intense and computationally expensive tasks overlap, ExaHype's cache-oblivious implementation can exploit the Intel Memory Drive Technology (IMDT) virtualizing the extra memory layer, and it suffers only from a less than 3x performance decline per degree of freedom versus pure DDR4 memory
Link: https://arxiv.org/abs/1810.03940
====================================================
A Microbenchmark Characterization of the Emu Chick (Jeffrey Young - 7 September, 2018)
We compare the Emu Chick hardware to architectural simulation and an Intel Xeon-based platform. Moreover, the Emu Chick provides stable, predictable performance with up to 65% of the peak bandwidth utilization on a random-access pointer chasing benchmark with weak locality.
Link: https://arxiv.org/abs/1809.07696
====================================================
Optimizing CNN Model Inference on CPUs (Yizhi Liu - 7 September, 2018)
Experiments show that our solution achieves up to 2.81x better latency for CNN model inference on a 18-core Intel Platinum 8000-series CPU compared to the state-of-the-art implementations using Intel MKL-DNN.
Link: https://arxiv.org/abs/1809.02697
====================================================
Fair Marketplace for Secure Outsourced Computations (Hung Dang - 29 August, 2018)
Kosto protects the confidentiality of clients' inputs as well as the integrity of the outsourced computations and their results using trusted hardware's enclave execution, in particular Intel SGX. Empirical evaluation on the prototype implementation of Kosto shows that performance overhead incurred by enclave execution is as small as 3% for computation-intensive operations, and 1.5x for IO-intensive operations.
Link: https://arxiv.org/abs/1808.09682
====================================================
Ithemal: Accurate, Portable and Fast Basic Block Throughput Estimation using Deep Neural Networks (Charith Mendis - 20 August, 2018)
In particular, our model has a worst case average error of 10.53% on actual throughput values when compared to best case average errors of 19.57% for the LLVM scheduler (llvm-mca) and 22.51% for IACA, Intel's machine code analyzer when compared on three different microarchitectures, while predicting throughput values at a faster rate than aforementioned tools
Link: https://arxiv.org/abs/1808.07412
====================================================
MicroWalk: A Framework for Finding Side Channels in Binaries (Jan Wichelmann - 16 August, 2018)
For the first time, by utilizing MicroWalk, we perform rigorous leakage analysis of two widely-used closed-source cryptographic libraries: Intel IPP and Microsoft CNG. We analyze 15 different cryptographic implementations consisting of 112 million instructions in about 105 minutes of CPU time
Link: https://arxiv.org/abs/1808.05575
====================================================
Novel Model-based Methods for Performance Optimization of Multithreaded 2D Discrete Fourier Transform on Multicore Processors (Semyon Khokhriakov - 16 August, 2018)
Based on our experiments on a modern Intel Haswell multicore server consisting of 36 physical cores, the average and maximum speedups observed for PFFT-FPM using FFTW-3.3.7 are 1.9x and 6.8x respectively and the average and maximum speedups observed using Intel MKL FFT are 1.3x and 2x respectively. The average and maximum speedups observed for PFFT-FPM-PAD using FFTW-3.3.7 are 2x and 9.4x respectively and the average and maximum speedups observed using Intel MKL FFT are 1.4x and 5.9x respectively.
Link: https://arxiv.org/abs/1808.05405
====================================================
libhclooc: Software Library Facilitating Out-of-core Implementations of Accelerator Kernels on Hybrid Computing Platforms (Daniel Hanlon - 15 August, 2018)
We show that it suffers from a maximum overhead of 10%, 4%, and 8% (due to abstraction) compared to the state-of-the-art optimised implementations for Nvidia K40c GPU, Nvidia P100 PCIe GPU, and Intel Xeon Phi 3120P respectively. We also show that using libhclooc API reduces the number of lines of code (LOC) by 75% thereby drastically improving programmer productivity.
Link: https://arxiv.org/abs/1808.05056
====================================================
CosmoFlow: Using Deep Learning to Learn the Universe at Scale (Amrita Mathuriya - 14 August, 2018)
CosmoFlow uses efficient implementations of 3D convolution and pooling primitives, together with improvements in threading for many element-wise operations, to improve training performance on Intel(C) Xeon Phi(TM) processors. We demonstrate fully synchronous data-parallel training on 8192 nodes of Cori with 77% parallel efficiency, achieving 3.5 Pflop/s sustained performance
Link: https://arxiv.org/abs/1808.04728
====================================================
Highly Scalable Deep Learning Training System with Mixed-Precision: Training ImageNet in Four Minutes (Xianyan Jia - 30 July, 2018)
On training ResNet-50 with 90 epochs, the state-of-the-art GPU-based system with 1024 Tesla P100 GPUs spent 15 minutes and achieved 74.9\% top-1 test accuracy, and another KNL-based system with 2048 Intel KNLs spent 20 minutes and achieved 75.4\% accuracy. Our training system can achieve 75.8\% top-1 test accuracy in only 6.6 minutes using 2048 Tesla P40 GPUs. When training AlexNet with 95 epochs, our system can achieve 58.7\% top-1 test accuracy within 4 minutes, which also outperforms all other existing systems.
Link: https://arxiv.org/abs/1807.11205
====================================================
FPGA-Based CNN Inference Accelerator Synthesized from Multi-Threaded C Software (Jin Hee Kim - 27 July, 2018)
On a mid-sized Intel Arria 10 SoC FPGA, peak performance on VGG-16 is 138 effective GOPS.
Link: https://arxiv.org/abs/1807.10695
====================================================
Scheduling Computation Graphs of Deep Learning Models on Manycore CPUs (Linpeng Tang - 16 July, 2018)
The training times on four different neural networks with Graphi are 2.1x to 9.5x faster than those with TensorFlow on a 68-core Intel Xeon Phi processor.
Link: https://arxiv.org/abs/1807.09667
====================================================
Using Intel Optane Devices for In-situ Data Staging in HPC Workflows (Pradeep Subedi - 11 July, 2018)
Intel recently released the Optane drive, which features 3D XPoint memory technology. We study the performance from two perspectives: 1) Benchmarking of drives using FIO workloads, and 2) Assessing the impact of using Optane over NVMe within the DataSpaces framework for in-memory data staging to support in-situ scientific workflows.
Link: https://arxiv.org/abs/1807.09651
====================================================
DLA: Compiler and FPGA Overlay for Neural Network Inference Acceleration (Mohamed S. Abdelfattah - 13 July, 2018)
Finally, we describe how we can tailor our hardware overlay, and use our graph compiler to achieve ~900 fps on GoogLeNet on an Intel Arria 10 1150 - the fastest ever reported on comparable FPGAs.
Link: https://arxiv.org/abs/1807.06434
====================================================
Private Data Objects: an Overview (Mic Bowman - 16 July, 2018)
In particular, contracts run off-ledger in secure enclaves using Intel SGX, which preserves data confidentiality, execution integrity and enforces data access policies (as opposed to raw data access). The design and the development of PDOs is an ongoing research effort, and open source code is available and hosted by Hyperledger Labs [5, 7].
Link: https://arxiv.org/abs/1807.05686
====================================================
Real-time stereo vision-based lane detection system (Rui Fan - 8 July, 2018)
The proposed system is implemented on a heterogeneous system which consists of an Intel Core i7-4720HQ CPU and a NVIDIA GTX 970M GPU. A processing speed of 143 fps has been achieved, which is over 38 times faster than our previous work. Also, in order to evaluate the detection precision, we tested 2495 frames with 5361 lanes from the KITTI database (1637 lanes more than our previous experiment). It is shown that the overall successful detection rate is improved from 98.7% to 99.5%.
Link: https://arxiv.org/abs/1807.02752
====================================================
Trading Cointegrated Assets with Price Impact (Alvaro Cartea - 3 July, 2018)
As an example, the agent liquidates a portfolio consisting of shares in Intel Corporation (INTC) and Market Vectors Semiconductor ETF (SMH). We show that including the information provided by three additional assets, FARO Technologies (FARO), NetApp (NTAP) and Oracle Corporation (ORCL), considerably improves the strategy's performance; for the portfolio we execute, it outperforms the multi-asset version of Almgren-Chriss by approximately 4 to 4.5 basis points.
Link: https://arxiv.org/abs/1807.01428
====================================================
BesFS: Mechanized Proof of an Iago-Safe Filesystem for Enclaves (Shweta Shinde - 2 July, 2018)
New trusted computing primitives such as Intel SGX have shown the feasibility of running user-level applications in enclaves on a commodity trusted processor without trusting a large OS. We prove 118 lemmas and 2 key theorems in 3676 lines of CoQ proof scripts, which directly proves safety properties of BesFS implementation. BesFS API is expressive enough to support 17 real applications we test, and this principled approach eliminates several bugs. BesFS integrates into existing SGX-enabled applications with minimal impact to TCB (less than 750 LOC), and it can serve as concrete test oracle for other hand-coded Iago-safety checks.
Link: https://arxiv.org/abs/1807.00477
====================================================
Quantum algorithm for visual tracking (Chao-Hua Yu - 2 July, 2018)
Intell., \textbf{7}, 583 (2015)]
Link: https://arxiv.org/abs/1807.00476
====================================================
LPRNet: License Plate Recognition via Deep Neural Networks (Sergey Zherzdev - 27 June, 2018)
Our approach is inspired by recent breakthroughs in Deep Neural Networks, and works in real-time with recognition accuracy up to 95% for Chinese license plates: 3 ms/plate on nVIDIA GeForce GTX 1080 and 1.3 ms/plate on Intel Core i7-6700K CPU
Link: https://arxiv.org/abs/1806.10447
====================================================
AVX-512 extension to OpenQCD 1.6 (Ed Bennett - 15 June, 2018)
We report on the implementation and performance of the AVX-512 OpenQCD extension on clusters using Intel Knights Landing and Xeon Scalable (Skylake) CPUs. In complete HMC trajectories with physically relevant parameters we observe a performance increase of 5% to 10%.
Link: https://arxiv.org/abs/1806.06043
====================================================
SIMD Vectorization for the Lennard-Jones Potential with AVX2 and AVX-512 instructions (Hiroshi Watanabe - 13 June, 2018)
We present results for benchmarks on three CPU architectures: Intel Haswell (HSW), Knights Landing (KNL), and Skylake (SKL). The performance gains by vectorization are about 42\% on HSW compared with the code optimized without vectorization. On KNL, the hand-vectorized codes exhibit 34\% better performance than the codes vectorized automatically by the Intel compiler
Link: https://arxiv.org/abs/1806.05713
====================================================
Slalom: Fast, Verifiable and Private Execution of Neural Networks in Trusted Hardware (Florian Tramer - 8 June, 2018)
We evaluate Slalom by executing DNNs in an Intel SGX enclave, which selectively outsources work to an untrusted GPU. For two canonical DNNs, VGG16 and MobileNet, we obtain 20x and 6x increases in throughput for verifiable inference, and 10x and 3.5x for verifiable and private inference.
Link: https://arxiv.org/abs/1806.03287
====================================================
A 5.5 ps Time-interval RMS Precision Time-to-Digital Convertor Implemented in Intel Arria 10 FPGA (Jie Kuang - 31 May, 2018)
In this paper, the basic tapped delay line (TDL) TDC structure is adapted in Intel Arria 10 FPGA, which is manufactured with 20 nm process technology. Using two identical TDC channels, the average RMS precision for measurements of time-intervals in the range from 0 to 50 ns reaches 5.45 ps
Link: https://arxiv.org/abs/1805.12390
====================================================
Optimizing Sparse Matrix-Vector Multiplication on Emerging Many-Core Architectures (Shizhao Chen - 29 May, 2018)
This paper provides the first comprehensive study on the impact of sparse matrix representations on two emerging many-core architectures: the Intel's Knights Landing (KNL) XeonPhi and the ARM-based FT-2000Plus (FTP). Our large-scale experiments involved over 9,500 distinct profiling runs performed on 956 sparse datasets and five mainstream SpMV representations. We show that our model delivers on average 95% and 91% of the best available performance on KNL and FTP respectively, and it achieves this with no runtime profiling overhead.
Link: https://arxiv.org/abs/1805.11938
====================================================
A Case for Variability-Aware Policies for NISQ-Era Quantum Computers (Swamit S. Tannu - 25 May, 2018)
Recently, IBM, Google, and Intel showcased quantum computers ranging from 49 to 72 qubits
Link: https://arxiv.org/abs/1805.10224
====================================================
Deploy Large-Scale Deep Neural Networks in Resource Constrained IoT Devices with Local Quantization Region (Yi Yang - 23 May, 2018)
For example, our 8-bit scheme has no drops on top-1 and top-5 accuracy with 2x speedup on Intel Edison IoT platform. For example, the drop on our task is only 0.7% when using 2-bit scheme, a scheme which could largely save transistors
Link: https://arxiv.org/abs/1805.09473
====================================================
One machine, one minute, three billion tetrahedra (CÃ©lestin Marot - 22 May, 2018)
The performances of our implementation have been measured on three different processors, Intel core-i7, Intel Xeon Phi and AMD EPYC, on which we have been able to compute 3 billion tetrahedra in 53 seconds . This corresponds to a generation rate of over 55 million tetrahedra per second which is, to our best knowledge, three times the rate reached by the current fastest implementation
Link: https://arxiv.org/abs/1805.08831
====================================================
ELT-scale Adaptive Optics real-time control with the Intel Xeon Phi Many Integrated Core Architecture (David Jenkins - 24 May, 2018)
We propose a solution to the increased computational demands of Extremely Large Telescope (ELT) scale adaptive optics (AO) real-time control with the Intel Xeon Phi Knights Landing (KNL) Many Integrated Core (MIC) Architecture. The Xeon Phi contains a large number (> 64) of low power x86 CPU cores and high bandwidth memory integrated into a single socketed server CPU package. Here, we demonstrate that the Xeon Phi KNL is capable of performing ELT scale single conjugate AO real-time control computation at over 1.0 kHz with less than 20 Î¼s RMS jitter. We have also shown that with a wavefront sensor camera attached the KNL can process the real-time control loop at up to 966 Hz, the maximum frame-rate of the camera, with jitter remaining below 20 Î¼s RMS
Link: https://arxiv.org/abs/1805.07254
====================================================
LMNet: Real-time Multiclass Object Detection on CPU using 3D LiDAR (Kazuki Minemura - 18 May, 2018)
We achieved execution times as fast as 50 FPS using desktop GPUs, and up to 10 FPS on a single Intel Core i5 CPU
Link: https://arxiv.org/abs/1805.04902
====================================================
Massively parallel quantum computer simulator, eleven years later (Hans De Raedt - 12 May, 2018)
The simulator features close-to-linear scaling behavior on the Sunway TaihuLight, on the K computer, on an IBM BlueGene/Q, and on an Intel Xeon based cluster, implying that the combination of software and hardware beats the exponential scaling with the system size. Adaptive encoding of the wave function reduces the memory requirement by a factor of eight, making it possible to simulate universal quantum computers with up to 48 qubits on the Sunway TaihuLight and on the K computer. Results of executing simple quantum circuits and Shor's factorization algorithm on quantum computers containing up to 48 qubits are presented.
Link: https://arxiv.org/abs/1805.04708
====================================================
IBBE-SGX: Cryptographic Group Access Control using Trusted Execution Environments (Stefan Contiu - 27 July, 2018)
We address IBBE's impracticality for cloud deployments by exploiting Intel Software Guard Extensions (SGX) to derive cuts in the computational complexity. Results highlight that IBBE-SGX performs membership changes 1.2 orders of magnitude faster than the traditional approach of Hybrid Encryption (HE), producing group metadata that are 6 orders of magnitude smaller than HE, while at the same time offering zero knowledge guarantees.
Link: https://arxiv.org/abs/1805.01563
====================================================
Modeling Risk and Return using Dirichlet Process Prior (Sourish Das - 1 May, 2018)
The first dataset contains the return of IBM, Intel and NASDAQ and the second dataset contains the return data of 51 stocks as part of the index "Nifty 50" for Indian equity markets.
Link: https://arxiv.org/abs/1805.00306
====================================================
High-Performance Massive Subgraph Counting using Pipelined Adaptive-Group Communication (Langshi Chen - 25 April, 2018)
Experimentation on an Intel Xeon E5 cluster shows that our implementation achieves 5x speedup of performance compared to the state-of-the-art work while reduces the peak memory utilization by a factor of 2 on large templates of 12 to 15 vertices and input graphs of 2 to 5 billions of edges.
Link: https://arxiv.org/abs/1804.09764
====================================================
Are FPGAs Suitable for Edge Computing? (Saman Biookaghazadeh - 17 April, 2018)
This goal is accomplished by conducting comparison experiments on an Intel Arria 10 GX1150 FPGA and an Nvidia Tesla K40m GPU. The experiment results imply that the key advantages of adopting FPGAs for edge computing over GPUs are three-fold: 1) FPGAs can provide a consistent throughput invariant to the size of application workload, which is critical to aggregating individual service requests from various IoT sensors; (2) FPGAs offer both spatial and temporal parallelism at a fine granularity and a massive scale, which guarantees a consistently high performance for accelerating both high-concurrency and high-dependency algorithms; and (3) FPGAs feature 3-4 times lower power consumption and up to 30.7 times better energy efficiency, offering better thermal stability and lower energy cost per functionality.
Link: https://arxiv.org/abs/1804.06404
====================================================
An Efficient I/O Architecture for RAM-based Content-Addressable Memory on FPGA (Xuan-Thuan Nguyen - 26 June, 2018)
The experimental results in an Intel Arria V 5ASTFD5 FPGA prove that at 100 MHz, the proposed designs achieve at least 9.6 times higher I/O efficiency as compared to the traditional RCAM.
Link: https://arxiv.org/abs/1804.02330
====================================================
Early Experience on Using Knights Landing Processors for Lattice Boltzmann Applications (Enrico Calore - 5 April, 2018)
The Knights Landing (KNL) is the codename for the latest generation of Intel processors based on Intel Many Integrated Core (MIC) architecture. The KNL peak performance is very high - approximately 3 Tflops in double precision and 6 Tflops in single precision - but sustained performance depends critically on how well all parallel features of the processor are exploited by real-life applications
Link: https://arxiv.org/abs/1804.01918
====================================================
Energy-efficiency evaluation of Intel KNL for HPC workloads (E. Calore - 5 April, 2018)
In this work we focus on energy performance of the Knights Landing (KNL) Xeon Phi, the latest many-core architecture processor introduced by Intel into the HPC market. We take into account the 64-core Xeon Phi 7230, and analyze its energy performance using both the on-chip MCDRAM and the regular DDR4 system memory as main storage for the application data-domain
Link: https://arxiv.org/abs/1804.01911
====================================================
An FPGA-Based Hardware Accelerator for Energy-Efficient Bitmap Index Creation (Xuan-Thuan Nguyen - 20 April, 2018)
The experimental results on an Intel Arria V 5ASTFD5 FPGA prove that at 100 MHz, BIC64K8 and BIC32K16 achieve the approximate indexing throughput of 1.43 GB/s and 1.46 GB/s, respectively. More significantly, BIC32K16 only consumes as low as 6.76% and 3.28% of energy compared to the central-processing-unit- and graphic-processing-unit-based designs, respectively.
Link: https://arxiv.org/abs/1803.11207
====================================================
Extreme Scale FMM-Accelerated Boundary Integral Equation Solver for Wave Scattering (Mustafa Abduljabbar - 27 March, 2018)
Our application code is well optimized to exploit the AVX-512 SIMD units of Intel Skylake and Knights Landing architectures. With shared memory optimizations, we achieve roughly 77% of peak single precision floating point performance of a 56-core Skylake processor, and on average 60% of peak single precision floating point performance of a 72-core KNL. These numbers represent nearly 5.4x and 10x speedup on Skylake and KNL, respectively, compared to the baseline scalar code. In addition, we exhibit up to 85% efficiency in strong scaling. We compute in excess of 2 billion DoF on the full-scale of the Cray XC40 supercomputer.
Link: https://arxiv.org/abs/1803.09948
====================================================
Gaussian and exponential lateral connectivity on distributed spiking neural network simulation (Elena Pastorelli - 23 March, 2018)
The hardware platform was a cluster of IBM NX360 M5 16-core compute nodes, each one containing two Intel Xeon Haswell 8-core E5-2630 v3 processors, with a clock of 2.40 G Hz, interconnected through an InfiniBand network, equipped with 4x QDR switches.
Link: https://arxiv.org/abs/1803.08833
====================================================
GossipGraD: Scalable Deep Learning using Gossip Communication based Asynchronous Gradient Descent (Jeff Daily - 15 March, 2018)
We implement GossipGraD for GPU and CPU clusters and use NVIDIA GPUs (Pascal P100) connected with InfiniBand, and Intel Knights Landing (KNL) connected with Aries network. Specifically, for ResNet50, GossipGraD is able to achieve ~100% compute efficiency using 128 NVIDIA Pascal P100 GPUs - while matching the top-1 classification accuracy published in literature.
Link: https://arxiv.org/abs/1803.05880
====================================================
Co-processor-based Behavior Monitoring: Application to the Detection of Attacks Against the System Management Mode (Ronny Chevalier - 7 March, 2018)
The results show that our solution detects intrusions from the state of the art, without any false positives, while remaining acceptable in terms of performance overhead in the context of the SMM (i.e., less than the 150 $Î¼$s threshold defined by Intel).
Link: https://arxiv.org/abs/1803.02700
====================================================
ISA-Based Trusted Network Functions And Server Applications In The Untrusted Cloud (Spyridon Mastorakis - 20 February, 2018)
In this paper, we identify (i) a number of NF and server application use-cases that trusted execution can be applied to, (ii) the assets and impact of compromising the private data and execution integrity of each use-case, and (iii) we leverage Intel's Software Guard Extensions (SGX) architecture to design Trusted Execution Environments (TEEs) for cloud-based NFs and server applications. We combine SGX with the Data Plane Development KIT (DPDK) to prototype and evaluate our TEEs for a number of application scenarios (Layer 2 frame and Layer 3 packet processing for plain and encrypted traffic, traffic load-balancing and back-end server processing). Our results indicate that NFs involving plain traffic can achieve almost native performance (e.g., ~22 Million Packets Per Second for Layer 3 forwarding for 64-byte frames), while NFs involving encrypted traffic and server processing can still achieve competitive performance (e.g., ~12 Million Packets Per Second for server processing for 64-byte frames).
Link: https://arxiv.org/abs/1802.06970
====================================================
New High Performance GPGPU Code Transformation Framework Applied to Large Production Weather Prediction Code (Michel MÃ¼ller - 16 February, 2018)
In a full scale production run, using an ASUCA grid with 1581 x 1301 x 58 cells and real world weather data in 2km resolution, 24 NVIDIA Tesla P100 running the Hybrid Fortran based GPU port are shown to replace more than 50 18-core Intel Xeon Broadwell E5-2695 v4 running the reference implementation - an achievement comparable to more invasive GPGPU rewrites of other weather models.
Link: https://arxiv.org/abs/1802.05839
====================================================
GPU implementation of algorithm SIMPLE-TS for calculation of unsteady, viscous, compressible and heat-conductive gas flows (Kiril S. Shterev - 12 February, 2018)
The tests show that overall speedup of AMD Radeon R9 280X is up to 102x compared to Intel Core i5-4690 core and up to 184x compared to Intel Core i7-920 core, while speedup of NVIDIA Tesla M2090 is up to 11x compared to Intel Core i5-4690 core and up to 20x compared to Intel Core i7-920 core. It requires 1[GB] global memory for 5.9 million finite volumes that are two times less compared to C++ CPU code
Link: https://arxiv.org/abs/1802.04243
====================================================
Tuning Streamed Applications on Intel Xeon Phi: A Machine Learning Based Approach (Peng Zhang - 8 February, 2018)
In this paper, we present an automatic approach to determine the hardware resource partition and the task granularity for any given application, targeting the Intel XeonPhi architecture. We apply our approach to 23 representative parallel applications and evaluate it on a CPU-XeonPhi mixed heterogenous many-core platform. Our approach achieves, on average, a 1.6x (upto 5.6x) speedup, which translates to 94.5% of the performance delivered by a theoretically perfect predictor.
Link: https://arxiv.org/abs/1802.02760
====================================================
Efficiency of high-performance discontinuous Galerkin spectral element methods for under-resolved turbulent incompressible flows (Niklas Fehn - 5 February, 2018)
We present excellent performance numbers on modern, cache-based computer architectures achieving a throughput for operator evaluation of 3e8 up to 1e9 DoFs/sec on one Intel Haswell node with 28 cores. Compared to performance results published within the last 5 years for high-order DG discretizations of the compressible Navier-Stokes equations, our approach reduces computational costs by more than one order of magnitude for the same setup.
Link: https://arxiv.org/abs/1802.01439
====================================================
Snort Intrusion Detection System with Intel Software Guard Extension (Intel SGX) (Dmitrii Kuvaiskii - 1 February, 2018)
Our IDS secured using Intel SGX, called SEC-IDS, is an unmodified Snort 3 with a DPDK network layer that achieves 10Gbps line rate. At the same time, SEC-IDS achieves near-native performance, with throughput close to 100 percent of vanilla Snort 3, by retaining network I/O outside of the enclave. Only 27 Lines of Code (LoC) were modified in Snort and 178 LoC in Graphene-SGX itself.
Link: https://arxiv.org/abs/1802.00508
====================================================
Combined Spatial and Temporal Blocking for High-Performance Stencil Computation on FPGAs Using OpenCL (Hamid Reza Zohouri - 1 February, 2018)
Accelerator parameter tuning is guided by our performance model, which we also use to project performance for the upcoming Intel Stratix 10 devices. On an Arria 10 GX 1150 device, our accelerator can reach up to 760 and 375 GFLOP/s of compute performance, for 2D and 3D stencils, respectively, which rivals the performance of a highly-optimized GPU implementation. Furthermore, we estimate that the upcoming Stratix 10 devices can achieve a performance of up to 3.5 TFLOP/s and 1.6 TFLOP/s for 2D and 3D stencil computation, respectively.
Link: https://arxiv.org/abs/1802.00438
====================================================
Cataloging the Visible Universe through Bayesian Inference at Petascale (Jeffrey Regier - 30 January, 2018)
Using over 1.3 million threads on 650,000 Intel Xeon Phi cores of the Cori Phase II supercomputer, Celeste achieves a peak rate of 1.54 DP PFLOP/s. Celeste is able to jointly optimize parameters for 188M stars and galaxies, loading and processing 178 TB across 8192 nodes in 14.6 minutes
Link: https://arxiv.org/abs/1801.10277
====================================================
BOPS, Not FLOPS! A New Metric and Roofline Performance Model For Datacenter Computing (Lei Wang - 2 May, 2018)
However, for datacenter (in short, DC) computing workloads, such as Internet services or big data analytics, previous work reports that they have extremely low floating point operation intensity, and the average FLOPS efficiency is only 0.1%, while the average IPC is 1.3 (the theoretic IPC is 4 on the Intel Xeon E5600 platform). On the basis of BOPS, we propose a new Roofline performance model for DC computing, which we call DC-Roofline model, with which we optimize DC workloads with the improvement varying from 119% to 325%.
Link: https://arxiv.org/abs/1801.09212
====================================================
HeNet: A Deep Learning Approach on Intel$^\circledR$ Processor Trace for Effective Exploit Detection (Li Chen - 8 January, 2018)
We use Intel$^\circledR$ Processor Trace enabled processor for low overhead execution tracing and design a lightweight image conversion and segmentation of the control flow trace. HeNet achieves 100\% accuracy and 0\% false positive on test set, and higher classification accuracy compared to classical machine learning algorithms.
Link: https://arxiv.org/abs/1801.02318
====================================================
Meltdown (Moritz Lipp - 3 January, 2018)
The attack works on different Intel microarchitectures since at least 2010 and potentially other processors are affected
Link: https://arxiv.org/abs/1801.01207
====================================================
On quality of implementation of Fortran 2008 complex intrinsic functions on branch cuts (Anton Shterenlikht - 29 December, 2017)
Results are reported with 8 Fortran 2008 compilers: GCC, Flang, Cray, Oracle, PGI, Intel, NAG and IBM. We conclude that the quality of implementation of these Fortran 2008 intrinsics in many compilers is not yet sufficient to remove the need for special code for branch cuts
Link: https://arxiv.org/abs/1712.10230
====================================================
Scaling GRPC Tensorflow on 512 nodes of Cori Supercomputer (Amrita Mathuriya - 26 December, 2017)
We explore scaling of the standard distributed Tensorflow with GRPC primitives on up to 512 Intel Xeon Phi (KNL) nodes of Cori supercomputer with synchronous stochastic gradient descent (SGD), and identify causes of scaling inefficiency at higher node counts. We studied scaling of two convolution neural networks - ResNet-50, a state-of-the-art deep network for classification with roughly 25.5 million parameters, and HEP-CNN, a shallow topology with less than 1 million parameters for common scientific usages. For ResNet-50, we achieve >80% scaling efficiency on up to 128 workers, using 32 parameter servers (PS tasks) with a steep decline down to 23% for 512 workers using 64 PS tasks. The HEP-CNN demands less interconnect bandwidth, and shows >80% weak scaling efficiency for up to 256 nodes with only 1 PS task
Link: https://arxiv.org/abs/1712.09388
====================================================
Accelerating the computation of FLAPW methods on heterogeneous architectures (Davor DavidoviÄ - 19 December, 2017)
Our final code attains over 70\% of the architectures' peak performance, and outperforms Nvidia's and Intel's libraries
Link: https://arxiv.org/abs/1712.07206
====================================================
Parallel Prefix Algorithms for the Registration of Arbitrarily Long Electron Micrograph Series (Marcin Copik - 7 December, 2017)
With our parallelization scheme, the time of registration of results from ten seconds of microscopy acquisition has been decreased from almost thirteen hours to less than seven minutes on 512 Intel IvyBridge cores.
Link: https://arxiv.org/abs/1712.02533
====================================================
MicroExpNet: An Extremely Small and Fast Model For Expression Recognition From Frontal Face Images (Ä°lke ÃuÄu - 13 August, 2018)
In addition, our smallest model (MicroExpNet), obtained using knowledge distillation, is less than $1$MB in size and works at 1408 frames per second on an Intel i7 CPU. MicroExpNet performs on part with our largest model on the CK+ and Oulu-CASIA datasets but with 330x fewer parameters.
Link: https://arxiv.org/abs/1711.07011
====================================================
Cyclone: High Availability for Persistent Key Value Stores (Amitabha Roy - 18 November, 2017)
It uses a small amount of non-volatile memory directly addressable by the CPU - such as in the form of NVDIMMs or Intel 3DXPoint - to remove block oriented IO devices such as SSDs from the critical path for appending to the log. Cyclone is able to replicate millions of small updates per second using only commodity 10 gigabit ethernet adapters
Link: https://arxiv.org/abs/1711.06964
====================================================
Scale out for large minibatch SGD: Residual network training on ImageNet-1K with improved accuracy and reduced time to train (Valeriu Codreanu - 15 November, 2017)
This is supported by software tools from Intel's ecosystem. Moreover, we show that with regular 90 - 120 epoch train runs we can achieve a top-1 accuracy as high as 77\% for the unmodified ResNet-50 topology
Link: https://arxiv.org/abs/1711.04291
====================================================
Fast matrix-free evaluation of discontinuous Galerkin finite element operators (Martin Kronbichler - 9 November, 2017)
In isolation our implementation then reaches up to 60\% of arithmetic peak on Intel Haswell and Broadwell processors and up to 50\% of arithmetic peak on Intel Knights Landing. Our performance analysis shows that the results are often within 10\% of the available memory bandwidth for the proposed implementation, with the exception of the Cartesian mesh case where the cost of gather operations and MPI communication are more substantial.
Link: https://arxiv.org/abs/1711.03590
====================================================
CMS Analysis and Data Reduction with Apache Spark (Oliver Gutsche - 31 October, 2017)
Studying the first thrust, CMS is working together with CERN openlab and Intel on the CMS Big Data Reduction Facility. The goal is to reduce 1 PB of official CMS data to 1 TB of ntuple output for analysis
Link: https://arxiv.org/abs/1711.00375
====================================================
Deep and Shallow convections in Atmosphere Models on Intel Xeon Phi Coprocessor Systems (Srinivasan Ramesh - 1 November, 2017)
In this work, we accelerate these calculations on Intel{\textregistered} Xeon Phi{\texttrademark} Coprocessor Systems. By employing dynamic scheduling in OpenMP, we demonstrate large reductions in load imbalance and about 10% increase in speedups. These techniques along with various vectorization strategies resulted in about 30% improvement in convection calculations.
Link: https://arxiv.org/abs/1711.00289
====================================================
Barrier Free Internet Access: Evaluating the Cyber Security Risk Posed by the Adoption of Bring Your Own Devices to e-Learning Network Infrastructure (E. T. Tchao - 22 October, 2017)
BYOD, since its emergence in 2009, courtesy of Intel, is now a common practice in many organizations
Link: https://arxiv.org/abs/1710.08795
====================================================
Communication-avoiding Cholesky-QR2 for rectangular matrices (Edward Hutter - 25 August, 2018)
We implement the new 3D CholeskyQR2 algorithm and study its performance relative to ScaLAPACK on Stampede 2, an Intel Knights Landing cluster, demonstrating improvements in parallel scalability and absolute performance.
Link: https://arxiv.org/abs/1710.08471
====================================================
The ALICE O2 common driver for the C-RORC and CRU read-out cards (Pascal Boeschoten - 16 October, 2017)
This paper discusses the driver architecture for the cards that will be used in O2 : the PCIe v2 x8, Xilinx Virtex 6 based C-RORC (Common Readout Receiver Card) and the PCIe v3 x16, Intel Arria 10 based CRU (Common Readout Unit)
Link: https://arxiv.org/abs/1710.05607
====================================================
Computation on Encrypted Data using Data Flow Authentication (Andreas Fischer - 1 October, 2017)
Trusted (hardware) modules, e.g., secure enclaves like Intel's SGX, can very efficiently run entire programs in encrypted memory. A transformed neural network that performs machine learning on sensitive medical data can be evaluated on encrypted inputs and encrypted weights in 0.86 seconds.
Link: https://arxiv.org/abs/1710.00390
====================================================
An Efficient Load Balancing Method for Tree Algorithms (Osama Talaat Ibrahim - 29 September, 2017)
To conduct an initial performance study, we implemented the method on an Intel Xeon Phi accelerator system. The results show scalable performance for up to the 60 physical processors of the accelerator, as well as an extrapolated 128 processors case.
Link: https://arxiv.org/abs/1710.00122
====================================================
Mixed Precision Solver Scalable to 16000 MPI Processes for Lattice Quantum Chromodynamics Simulations on the Oakforest-PACS System (Taisuke Boku - 29 September, 2017)
We have developed a mixed-precision quark solver for a large Intel Xeon Phi (KNL) system named "Oakforest-PACS", employing the $O(a)$-improved Wilson quarks as the discretized equation of motion. The solver achieved 2.6 PFLOPS in the single-precision part on a $400^3\times 800$ lattice using 16000 MPI processes on 8000 nodes on the system.
Link: https://arxiv.org/abs/1709.08785
====================================================
OpenMP GNU and Intel Fortran programs for solving the time-dependent Gross-Pitaevskii equation (Luis E. Young-S. - 13 September, 2017)
We present Open Multi-Processing (OpenMP) version of Fortran 90 programs for solving the Gross-Pitaevskii (GP) equation for a Bose-Einstein condensate in one, two, and three spatial dimensions, optimized for use with GNU and Intel compilers
Link: https://arxiv.org/abs/1709.04423
====================================================
RDeepSense: Reliable Deep Mobile Computing Models with Uncertainty Estimations (Shuochao Yao - 9 September, 2017)
We evaluate RDeepSense with four mobile sensing applications using Intel Edison devices. Results show that RDeepSense can reduce around 90% of the energy consumption while producing superior uncertainty estimations and preserving at least the same model accuracy compared with other state-of-the-art methods.
Link: https://arxiv.org/abs/1709.02980
====================================================
Embedded Binarized Neural Networks (Bradley McDanel - 6 September, 2017)
For example, eBNN achieves 95\% accuracy on the MNIST dataset running on an Intel Curie with only 15 KB of usable memory with an inference runtime of under 50 ms per sample
Link: https://arxiv.org/abs/1709.02260
====================================================
Beyond 16GB: Out-of-Core Stencil Computations (Istvan Z Reguly - 26 October, 2017)
Evaluating our work on Intel's Knights Landing Platform as well as NVIDIA P100 GPUs, we demonstrate that it is possible to solve 3 times larger problems than the on-chip memory size with at most 15\% loss in efficiency
Link: https://arxiv.org/abs/1709.02125
====================================================
Multi-radial LBP Features as a Tool for Rapid Glomerular Detection and Assessment in Whole Slide Histopathology Images (Olivier Simon - 20 September, 2017)
Using 5 Intel(R) Core(TM) i7-4790 CPUs with 40 GB RAM, our method typically requires ~15 sec for training and ~2 min to extract glomeruli reproducibly from a WSI. Deploying a deep convolutional neural network trained for glomerular recognition in tandem with the SVM suffices to reduce false positives to below 3%
Link: https://arxiv.org/abs/1709.01998
====================================================
Optimization of the Brillouin operator on the KNL architecture (Stephan Durr - 9 July, 2018)
Experiences with optimizing the matrix-times-vector application of the Brillouin operator on the Intel KNL processor are reported. Without adjustments to the memory layout, performance figures of 360 Gflop/s in single and 270 Gflop/s in double precision are observed
Link: https://arxiv.org/abs/1709.01828
====================================================
Galactos: Computing the Anisotropic 3-Point Correlation Function for 2 Billion Galaxies (Brian Friesen - 31 August, 2017)
Our implementation is optimized for the Intel Xeon Phi architecture, exploiting SIMD parallelism, instruction and thread concurrency, and significant L1 and L2 cache reuse, reaching 39% of peak performance on a single node. Galactos scales to the full Cori system, achieving 9.8PF (peak) and 5.06PF (sustained) across 9636 nodes, making the 3PCF easily computable for all galaxies in the observable universe.
Link: https://arxiv.org/abs/1709.00086
====================================================
LevelHeaded: Making Worst-Case Optimal Joins Work in the Common Case (Christopher R. Aberger - 25 August, 2017)
Using these optimizations, LevelHeaded outperforms other relational database engines (LogicBlox, MonetDB, and HyPer) by orders of magnitude on standard LA benchmarks, while performing on average within 31% of the best-of-breed BI (HyPer) and LA (Intel MKL) solutions on their own benchmarks
Link: https://arxiv.org/abs/1708.07859
====================================================
Performance Characterization of Multi-threaded Graph Processing Applications on Intel Many-Integrated-Core Architecture (Xu Liu - 15 August, 2017)
In this paper, we empirically evaluate various computing platforms including an Intel Xeon E5 CPU, a Nvidia Geforce GTX1070 GPU and an Xeon Phi 7210 processor codenamed Knights Landing (KNL) in the domain of parallel graph processing. We further characterize the impact of KNL architectural enhancements on the performance of a state-of-the art graph framework.We have four key observations: 1 Different graph applications require distinctive numbers of threads to reach the peak performance. 2 Only a few graph applications benefit from the high bandwidth MCDRAM, while others favor the low latency DDR4 DRAM. 3 Vector processing units executing AVX512 SIMD instructions on KNLs are underutilized when running the state-of-the-art graph framework. 4 The sub-NUMA cache clustering mode offering the lowest local memory access latency hurts the performance of graph benchmarks that are lack of NUMA awareness
Link: https://arxiv.org/abs/1708.04701
====================================================
Porting of the DBCSR library for Sparse Matrix-Matrix Multiplications to Intel Xeon Phi systems (Iain Bethune - 21 August, 2017)
We describe a performance comparison of DBCSR on systems with Intel Xeon Phi Knights Landing (KNL) processors, with respect to systems with Intel Xeon CPUs (including systems with GPUs). We find that the DBCSR on Cray XC40 KNL-based systems is 11%-14% slower than on a hybrid Cray XC50 with Nvidia P100 cards, at the same number of nodes. When compared to a Cray XC40 system equipped with dual-socket Intel Xeon CPUs, the KNL is up to 24% faster.
Link: https://arxiv.org/abs/1708.03604
====================================================
Automated Tiling of Unstructured Mesh Computations with Application to Seismological Modelling (Fabio Luporini - 10 August, 2017)
Besides automation, we advance the state-of-the-art by introducing: a revisited, more efficient sparse tiling algorithm; support for distributed-memory parallelism; a range of fine-grained optimizations for increased run-time performance; implementation in a publicly-available library, SLOPE; and an in-depth study of the performance impact in Seigen, a real-world elastic wave equation solver for seismological problems, which shows speed-ups up to 1.28x on a platform consisting of 896 Intel Broadwell cores.
Link: https://arxiv.org/abs/1708.03183
====================================================
ExaGeoStat: A High Performance Unified Software for Geostatistics on Manycore Systems (Sameh Abdulah - 22 June, 2018)
Using state-of-the-art high performance dense linear algebra libraries associated with various leading edge parallel architectures (Intel KNLs, NVIDIA GPUs, and distributed-memory systems), ExaGeoStat raises the game for statistical applications from climate and environmental science
Link: https://arxiv.org/abs/1708.02835
====================================================
Embracing a new era of highly efficient and productive quantum Monte Carlo simulations (Amrita Mathuriya - 8 August, 2017)
We demonstrate upto 4.5x speedups on recent Intel processors and IBM Blue Gene/Q for representative workloads. Memory-footprints are reduced by up-to 3.8x, opening the possibility to solve much larger problems of future.
Link: https://arxiv.org/abs/1708.02645
====================================================
Early Evaluation of Intel Optane Non-Volatile Memory with HPC I/O Workloads (Kai Wu - 12 May, 2018)
Earlier in 2017, Intel and Micron released first NVM product -- Intel Optane SSDs
Link: https://arxiv.org/abs/1708.02199
====================================================
An efficient MPI/OpenMP parallelization of the Hartree-Fock method for the second generation of Intel Xeon Phi processor (Vladimir Mironov - 14 August, 2017)
All implementations are benchmarked on a super-computer of 3,000 Intel Xeon Phi processors. With 64 cores per processor, scaling numbers are reported on up to 192,000 cores. The hybrid MPI/OpenMP implementation reduces the memory footprint by approximately 200 times compared to the legacy code
Link: https://arxiv.org/abs/1708.00033
====================================================
Methods for compressible fluid simulation on GPUs using high-order finite differences (Johannes PekkilÃ¤ - 27 July, 2017)
Our fastest implementation is bandwidth-bound and integrates $343$ million grid points per second on a Tesla K40t GPU, achieving a $3.6 \times$ speedup over a comparable hydrodynamics solver benchmarked on two Intel Xeon E5-2690v3 processors. Our alternative GPU implementation is latency-bound and achieves the rate of $168$ million updates per second.
Link: https://arxiv.org/abs/1707.08900
====================================================
Teechain: Scalable Blockchain Payments using Trusted Execution Environments (Joshua Lind - 17 July, 2017)
We evaluate an implementation of Teechain using Intel SGX as the TEE and the operational Bitcoin blockchain. Our prototype achieves orders of magnitude improvement in most metrics compared to existing implementations of payment channels: with replicated Teechain nodes in a trans-atlantic deployment, we measure a throughput of over 33,000 transactions per second with 0.1 second latency.
Link: https://arxiv.org/abs/1707.05454
====================================================
Benchmarking Data Analysis and Machine Learning Applications on the Intel KNL Many-Core Processor (Chansup Byun - 11 July, 2017)
Also a performance comparison of a machine learning application, Caffe, between the two different Intel CPUs, Xeon E5 v3 and Xeon Phi 7210, demonstrated a 2.7x improvement on a KNL node.
Link: https://arxiv.org/abs/1707.03515
====================================================
Radio-flaring Ultracool Dwarf Population Synthesis (Matthew Route - 15 August, 2017)
This simulator is powered by Intel Secure Key (ISK)- a new processor technology that uses a local entropy source to improve random number generation that has heretofore been used to improve cryptography. The results from this simulator indicate that only $\sim$5% of radio-flaring UCDs within the local interstellar neighborhood ($<$25 pc away) have been discovered
Link: https://arxiv.org/abs/1707.02212
====================================================
Climbing the Kaggle Leaderboard by Exploiting the Log-Loss Oracle (Jacob Whitehill - 6 July, 2017)
In this paper, (1) We demonstrate this attack on the first stage of a recent Kaggle competition (Intel & MobileODT Cancer Screening) and use it to achieve a log-loss of $0.00000$ (and thus attain a rank of #4 out of 848 contestants), without ever training a classifier to solve the actual task
Link: https://arxiv.org/abs/1707.01825
====================================================
Challenges to Keeping the Computer Industry Centered in the US (Thomas M. Conte - 30 June, 2017)
Much of the reason for the success of Silicon Valley had to do with Moore's Law: the observation by Intel co-founder Gordon Moore that the number of transistors on a microchip doubled at a rate of approximately every two years. According to the International Technology Roadmap for Semiconductors, Moore's Law will end in 2021. How can we rethink computing technology to restart the historic explosive performance growth? Since 2012, the IEEE Rebooting Computing Initiative (IEEE RCI) has been working with industry and the US government to find new computing approaches to answer this question
Link: https://arxiv.org/abs/1706.10267
====================================================
Tuning and optimization for a variety of many-core architectures without changing a single line of implementation code using the Alpaka library (Alexander Matthes - 30 June, 2017)
We specifically test the code for bleeding edge architectures such as Nvidia's Tesla P100, Intel's Knights Landing (KNL) and Haswell architecture as well as IBM's Power8 system. On some of these we are able to reach almost 50\% of the peak floating point operation performance using the aforementioned means. When adding compiler-specific #pragmas we are able to reach 5 TFLOPS/s on a P100 and over 1 TFLOPS/s on a KNL system.
Link: https://arxiv.org/abs/1706.10086
====================================================
GPGPU Acceleration of the KAZE Image Feature Extraction Algorithm (Ramkumar B - 21 June, 2017)
For a 1920 by 1200 sized image our Compute Unified Device Architecture (CUDA) C based GPU version took around 300 milliseconds on a NVIDIA GeForce GTX Titan X (Maxwell Architecture-GM200) card in comparison to nearly 2400 milliseconds for a multithreaded CPU version (16 threaded Intel(R) Xeon(R) CPU E5-2650 processsor). By achieving nearly 8 fold speedup without performance degradation our work expands the applicability of the KAZE algorithm
Link: https://arxiv.org/abs/1706.06750
====================================================
AMPS: An Augmented Matrix Formulation for Principal Submatrix Updates with Application to Power Grids (Yu-Hong Yeung - 9 June, 2017)
Our algorithms are capable of computing N - k contingency analysis on a 778 thousand bus grid, updating a solution with k = 20 elements in 16 milliseconds on an Intel Xeon processor.
Link: https://arxiv.org/abs/1706.03147
====================================================
Securing Application with Software Partitioning: A case study using SGX (Ahmad Atamli-Reineh - 9 June, 2017)
For this work, we focus on the upcoming Intel Software Guard Extensions (SGX) technology as the state-of-the-art in this field
Link: https://arxiv.org/abs/1706.03006
====================================================
Extended Sammon Projection and Wavelet Kernel Extreme Learning Machine for Gait-Based Legitimate User Identification on Smartphones (Muhammad Ahmad - 6 June, 2017)
All experiments were carried out using MATLAB (2014b) on Intel Core i5 CPU 3.20 GHz with 8 GB of RAM with a 64-bit operating system machine.
Link: https://arxiv.org/abs/1706.01739
====================================================
DeepIoT: Compressing Deep Neural Network Structures for Sensing Systems with a Compressor-Critic Framework (Shuochao Yao - 22 November, 2017)
We conduct experiments with five different sensing-related tasks on Intel Edison devices. It reduces the size of deep neural networks by 90% to 98.9%. It is thus able to shorten execution time by 71.4% to 94.5%, and decrease energy consumption by 72.2% to 95.7%
Link: https://arxiv.org/abs/1706.01215
====================================================
Heterogeneous computing for a hybridizable discontinuous Galerkin geometric multigrid method (M. S. Fabien - 4 June, 2017)
We use Intel's second generation Xeon Phi (Knights Landing) to enable acceleration. The GMG method achieves ideal convergence rates of $0.2$ or less, for high polynomial orders. Our algorithm is able to attain 80\% of peak bandwidth performance for higher order polynomials
Link: https://arxiv.org/abs/1705.09907
====================================================
Parallel Accelerated Custom Correlation Coefficient Calculations for Genomics Applications (Wayne Joubert - 20 September, 2018)
In this paper we describe a new approach to calculations of the Custom Correlation Coefficient (CCC) between Single Nucleotide Polymorphisms (SNPs) across a population, suitable for parallel systems equipped with graphics processing units (GPUs) or Intel Xeon Phi processors. Also it is estimated that as many as 90 quadrillion comparisons per second may be achievable on the upcoming ORNL Summit system, an additional 10X performance increase
Link: https://arxiv.org/abs/1705.08213
====================================================
Leaky Cauldron on the Dark Land: Understanding Memory Side-Channel Hazards in SGX (Wenhao Wang - 30 August, 2017)
Side-channel risks of Intel's SGX have recently attracted great attention. Our research identifies 8 potential attack vectors, ranging from TLB to DRAM modules
Link: https://arxiv.org/abs/1705.07289
====================================================
Detect Kernel-Mode Rootkits via Real Time Logging & Controlling Memory Access (Igor Korkin - 18 May, 2017)
To deal with the new malware we propose monitoring and controlling access to the memory in real time using Intel VT-x with EPT. MemoryMonRWX also has the following competitive advantages: fine-grained analysis, support of multi-core CPUs and 64-bit Windows 10
Link: https://arxiv.org/abs/1705.06784
====================================================
PerfWeb: How to Violate Web Privacy with Hardware Performance Events (Berk Gulmezoglu - 11 May, 2017)
We profile 40 different websites, 30 of the top Alexa sites and 10 whistleblowing portals, on two machines featuring an Intel and an ARM processor. By monitoring retired instructions, cache accesses, and bus cycles for at most 5 seconds, we manage to classify the selected websites with a success rate of up to 86.3%
Link: https://arxiv.org/abs/1705.04437
====================================================
Why & When Deep Learning Works: Looking Inside Deep Learnings (Ronny Ronen - 10 May, 2017)
The Intel Collaborative Research Institute for Computational Intelligence (ICRI-CI) has been heavily supporting Machine Learning and Deep Learning research from its foundation in 2012
Link: https://arxiv.org/abs/1705.03921
====================================================
A Novel Hybrid Quicksort Algorithm Vectorized using AVX-512 on Intel Skylake (Berenger Bramas - 12 March, 2018)
Our results demonstrate that our approach is faster than two libraries of reference: the GNU \emph{C++} sort algorithm by a speedup factor of 4, and the Intel IPP library by a speedup factor of 1.4.
Link: https://arxiv.org/abs/1704.08579
====================================================
Exploring the Performance Benefit of Hybrid Memory System on HPC Environments (Ivy Bo Peng - 26 April, 2017)
For example, the Intel Knights Landing (KNL) processor is equipped with 16 GB of high-bandwidth memory (HBM) that works together with conventional DRAM memory. Theoretically, HBM can provide 5x higher bandwidth than conventional DRAM. Our results show that applications with regular memory access benefit from MCDRAM, achieving up to 3x performance when compared to the performance obtained using only DRAM
Link: https://arxiv.org/abs/1704.08273
====================================================
In-Datacenter Performance Analysis of a Tensor Processing Unit (Norman P. Jouppi - 16 April, 2017)
We compare the TPU to a server-class Intel Haswell CPU and an Nvidia K80 GPU, which are contemporaries deployed in the same datacenters. Our workload, written in the high-level TensorFlow framework, uses production NN applications (MLPs, CNNs, and LSTMs) that represent 95% of our datacenters' NN inference demand
Link: https://arxiv.org/abs/1704.04760
====================================================
HPTT: A High-Performance Tensor Transposition C++ Library (Paul Springer - 10 May, 2017)
Across a wide range of different tensor transpositions and architectures (e.g., Intel Ivy Bridge, Intel Knights Landing, ARMv7, IBM Power7), HPTT attains a bandwidth comparable to that of SAXPY, and yields remarkable speedups over Eigen's tensor transposition implementation. Most importantly, the integration of HPTT into the Cyclops Tensor Framework (CTF) improves the overall performance of tensor contractions by up to 3.1x.
Link: https://arxiv.org/abs/1704.04374
====================================================
Loop Tiling in Large-Scale Stencil Codes at Run-time with OPS (Istvan Z Reguly - 26 June, 2017)
We also evaluate our algorithms on Intel's Knights Landing, demonstrating maintained throughput as the problem size grows beyond 16GB, and we do scaling studies up to 8704 cores
Link: https://arxiv.org/abs/1704.00693
====================================================
Accelerating gravitational microlensing simulations using the Xeon Phi coprocessor (Bin Chen - 28 March, 2017)
For the selected set of parameters evaluated in our experiment, we find that the speedup by Intel's Knights Corner coprocessor is comparable to that by NVIDIA's Fermi family of GPUs with compute capability 2.0, but less significant than GPUs with higher compute capabilities such as the Kepler. However, the very recently released second generation Xeon Phi, Knights Landing, is about 5.8 times faster than the Knights Corner, and about 2.9 times faster than the Kepler GPU used in our simulations
Link: https://arxiv.org/abs/1703.09707
====================================================
A Hybrid Supervised-unsupervised Method on Image Topic Visualization with Convolutional Neural Network and LDA (Kai Zhen - 9 April, 2017)
For scalability test, parallelization experiments are conducted with Harp-LDA on a Intel Knights Landing cluster: to extract 1,000 topic assignments for 241,035 COCO images, it takes 10 minutes with 60 threads.
Link: https://arxiv.org/abs/1703.05243
====================================================
A performance study of anomaly detection using entropy method (A. A. Waskita - 12 March, 2017)
The study has been conducted using real data generated from the distributed sensor networks at the Intel Berkeley Research Laboratory. The experimental results were compared with the elliptical method and has been analyzed in two dimensional data sets acquired from temperature and humidity sensors across 52 micro controllers
Link: https://arxiv.org/abs/1703.04086
====================================================
A note on quickly sampling a sparse matrix with low rank expectation (Karl Rohe - 8 March, 2017)
For example, on a graph with $n=500,000$ and $m = 5,000,000$, fastRG runs in less than one second on a 3.5 GHz Intel i5.
Link: https://arxiv.org/abs/1703.02998
====================================================
SAFETY: Secure gwAs in Federated Environment Through a hYbrid solution with Intel SGX and Homomorphic Encryption (Md Nazmus Sadat - 7 March, 2017)
To the best of our knowledge, this hybrid use of homomorphic encryption along with Intel SGX is not proposed or experimented to this date. Our proposed framework, SAFETY is up to 4.82 times faster than the best existing secure computation technique.
Link: https://arxiv.org/abs/1703.02577
====================================================
Computing in Memory with Spin-Transfer Torque Magnetic RAM (Shubham Jain - 20 November, 2017)
We evaluate STT-CiM using a device-to-architecture modeling framework, and integrate cycle-accurate models of STT-CiM with a commercial processor and on-chip bus (Nios II and Avalon from Intel). Our system-level evaluation shows that STT-CiM provides system-level performance improvements of 3.93x on average (upto 10.4x), and concurrently reduces memory system energy by 3.83x on average (upto 12.4x).
Link: https://arxiv.org/abs/1703.02118
====================================================
Landau Collision Integral Solver with Adaptive Mesh Refinement on Emerging Architectures (M. F. Adams - 28 February, 2017)
The Landau collision integral is vectorized with Intel AVX-512 intrinsics and the solver sustains as much as 22% of the theoretical peak flop rate of the Second Generation Intel Xeon Phi, Knights Landing, processor.
Link: https://arxiv.org/abs/1702.08880
====================================================
Enabling Sparse Winograd Convolution by Native Pruning (Sheng Li - 13 October, 2017)
Furthermore, we present a sparse Winograd convolution algorithm and implementation that exploits the sparsity, achieving up to 31.7 effective TFLOP/s in 32-bit precision on a latest Intel Xeon CPU, which corresponds to a 5.4x speedup over a state-of-the-art dense convolution implementation.
Link: https://arxiv.org/abs/1702.08597
====================================================
Parallelization of Path Planning Algorithms for AUVs Concepts, Opportunities, and Program-Technical Implementation (Mike Eichhorn - 26 February, 2017)
A previously published path planning algorithm was ported onto the SCC, an experimental 48 core single-chip system developed by Intel
Link: https://arxiv.org/abs/1702.08092
====================================================
CHAOS: A Parallelization Scheme for Training Convolutional Neural Networks on Intel Xeon Phi (Andre Viebke - 25 February, 2017)
Experimental results for the MNIST dataset of handwritten digits using the total number of threads on the Xeon Phi show speedups of up to 103x compared to the execution on one thread of the Xeon Phi, 14x compared to the sequential execution on Intel Xeon E5, and 58x compared to the sequential execution on Intel Core i5.
Link: https://arxiv.org/abs/1702.07908
====================================================
First Experiences Optimizing Smith-Waterman on Intel's Knights Landing Processor (Enzo Rucci - 23 February, 2017)
In this paper, we have explored SW acceleration on Intel KNL processor. Our evaluation, using the renowned Environmental NR database as benchmark, has shown that multi-threading and SIMD exploitation reports competitive performance (351 GCUPS) in comparison with other implementations.
Link: https://arxiv.org/abs/1702.07195
====================================================
Benchmarking the computing resources at the Instituto de AstrofÃ­sica de Canarias (Nicola Caon - 16 February, 2017)
In particular, we run the "Polyhedron Fortran Benchmarks" suite, using three different compilers: GNU Fortran Compiler, Intel Fortran Compiler and the PGI Fortran Compiler; execution times are then normalized to the reference values published by Polyhedron. The same tests were run multiple times on a same PCs, and on 3 to 5 PCs of the same model (whenever possible) to check for repeatability and consistency of the results. We found that in general execution times, for a given PC model, are consistent within an uncertainty of about 10%, and show a gain in CPU speed of a factor of about 3 between the oldest PCs used at the IAC (7-8 years old) and the newest ones.
Link: https://arxiv.org/abs/1702.04942
====================================================
Acceleration of the Implicit-Explicit Non-hydrostatic Unified Model of the Atmosphere (NUMA) on Manycore Processors (Daniel S. Abdi - 13 February, 2017)
We present the acceleration of an IMplicit-EXplicit (IMEX) non-hydrostatic atmospheric model on manycore processors such as GPUs and Intel's MIC architecture. Finally, we validate our results with standard benchmark problems in NWP and evaluate the performance and scalability of the IMEX method using up to 4192 GPUs and 16 Knights Landing processors.
Link: https://arxiv.org/abs/1702.04316
====================================================
LAMMPS' PPPM Long-Range Solver for the Second Generation Xeon Phi (William McDoniel - 14 February, 2017)
We extend the popular LAMMPS molecular dynamics code with an implementation of PPPM particularly suitable for the second generation Intel Xeon Phi. Our main target is the optimization of computational kernels by means of vectorization, and we observe speedups in these kernels of up to 12x
Link: https://arxiv.org/abs/1702.04250
====================================================
A Quantum von Neumann Architecture for Large-Scale Quantum Computing (Matthias F. Brandl - 11 November, 2017)
Its hardware is optimized for simplicity and uses the classical Intel 4004 CPU from 1971 as a blueprint. The Quantum 4004 has only a single processing zone and is structured in 4 qubit packages. Its quantum memory can store up to 32768 qubit ions and its computation speed is 10 $Î¼$s for single qubit operations and 20 $Î¼$s for two-qubit operations.
Link: https://arxiv.org/abs/1702.02583
====================================================
Intel MPX Explained: An Empirical Study of Intel MPX and Software-based Bounds Checking Approaches (Oleksii Oleksenko - 16 June, 2017)
Intel MPX's performance overheads are still high (roughly 50% on average), and the supporting infrastructure has bugs which may cause compilation or runtime errors
Link: https://arxiv.org/abs/1702.00719
====================================================
FPGA Architecture for Deep Learning and its application to Planetary Robotics (Pranay Gankidi - 25 January, 2017)
The results show up to a 43-fold speed up by Virtex 7 FPGAs compared to a conventional Intel i5 2.3 GHz CPU
Link: https://arxiv.org/abs/1701.07543
====================================================
ARM Wrestling with Big Data: A Study of Commodity ARM64 Server for Big Data Workloads (Jayanth Kalyanasundaram - 8 September, 2017)
Specifically, we study these for Intel's HiBench suite of web, query and machine learning benchmarks on Apache Hadoop v2.7 in a pseudo-distributed setup, for data sizes up to $20GB$ files, $5M$ web pages and $500M$ tuples. Our results show that the ARM64 server's runtime performance is comparable to the x64 server for integer-based workloads like Sort and Hive queries, and only lags behind for floating-point intensive benchmarks like PageRank, when they do not exploit data parallelism adequately. We also see that the ARM64 server takes $\frac{1}{3}^{rd}$ the energy, and has an Energy Delay Product (EDP) that is $50-71\%$ lower than the x64 server
Link: https://arxiv.org/abs/1701.05996
====================================================
BigDAWG Polystore Release and Demonstration (Kyle OBrien - 18 January, 2017)
The Intel Science and Technology Center for Big Data is developing a reference implementation of a Polystore database. We intend to release an open source BigDAWG v1.0 in the Spring of 2017
Link: https://arxiv.org/abs/1701.05799
====================================================
An OpenCL(TM) Deep Learning Accelerator on Arria 10 (Utku Aydonat - 12 January, 2017)
As a result, when running our DLA on Intel's Arria 10 device we can achieve a performance of 1020 img/s, or 23 img/s/W when running the AlexNet CNN benchmark. This comes to 1382 GFLOPs and is 10x faster with 8.4x more GFLOPS and 5.8x better efficiency than the state-of-the-art on FPGAs. Additionally, 23 img/s/W is competitive against the best publicly known implementation of AlexNet on nVidia's TitanX GPU.
Link: https://arxiv.org/abs/1701.03534
====================================================
A performance evaluation of CCS QCD Benchmark on the COMA (Intel(R) Xeon Phi$^{TM}$, KNC) system (Taisuke Boku - 20 December, 2016)
We optimized the benchmark program for a \Intel \XeonPhi (Knights Corner, KNC) system named "COMA (PACS-IX)" at CCS Tsukuba under the Intel Parallel Computing Center program. We observed a performance of $\sim 200$ GFlops sustained for the Wilson-Clover hopping matrix multiplication on the lattice sizes larger than $24^3\times 32$ on a sinlge card of the COMA system. A good weak scaling perofmace was observed on the local lattice sizes larger than $24^3\times 32$.
Link: https://arxiv.org/abs/1612.06556
====================================================
Performance Optimisation of Smoothed Particle Hydrodynamics Algorithms for Multi/Many-Core Architectures (Fabio Baruffa - 10 May, 2017)
We obtain shorter execution time and improved threading scalability both on Intel XeonR ($2.6 \times$ on Ivy Bridge) and Xeon PhiTM ($13.7 \times$ on Knights Corner) systems. First few tests of the optimised code result in $19.1 \times$ faster execution on second generation Xeon Phi (Knights Landing), thus demonstrating the portability of the devised optimisation solutions to upcoming architectures.
Link: https://arxiv.org/abs/1612.06090
====================================================
Sorting Data on Ultra-Large Scale with RADULS. New Incarnation of Radix Sort (Marek Kokot - 8 December, 2016)
For example 4G 16-byte records can be sorted with 16 threads in less than 15 seconds on Intel Xeon-based workstation
Link: https://arxiv.org/abs/1612.02557
====================================================
GPU-accelerated algorithms for many-particle continuous-time quantum walks (Enrico Piccinini - 2 December, 2016)
In turn, we have benchmarked 4 NVIDIA GPUs and 3 quad-core Intel CPUs for a 2-particle system over lattices of increasing dimension, showing that the speedup providend by GPU computing, with respect to the OPENMP parallelization, lies in the range between 8x and (more than) 20x, depending on the frequency of post-processing
Link: https://arxiv.org/abs/1612.00746
====================================================
A Real-time Single Pulse Detection Algorithm for GPUs (Karel AdÃ¡mek - 29 November, 2016)
Our GPU algorithm is approximately 17x faster than our current CPU OpenMP code (NVIDIA Titan XP vs Intel E5-2650v3). This work allows our AstroAccelerate code to perform a single pulse search on SKA-like data 4.3x faster than real-time.
Link: https://arxiv.org/abs/1611.09704
====================================================
On the Feasibility of Attribute-Based Encryption on Internet of Things Devices (Moreno Ambrosin - 24 November, 2016)
This article explores such feasibility for well-known IoT platforms, namely, Intel Galileo Gen 2, Intel Edison, Raspberry Pi 1 Model B, and Raspberry Pi Zero, and concludes that adopting ABE in the IoT is indeed feasible.
Link: https://arxiv.org/abs/1611.08098
====================================================
Inferring Fine-grained Control Flow Inside SGX Enclaves with Branch Shadowing (Sangho Lee - 1 June, 2017)
The root cause of this attack is that Intel SGX does not clear the branch history when switching from enclave mode to non-enclave mode, leaving the fine-grained traces to the outside world through a branch-prediction side channel. However, exploiting the channel is not so straightforward in practice because 1) measuring branch prediction/misprediction penalties based on timing is too inaccurate to distinguish fine-grained control-flow changes and 2) it requires sophisticated control over the enclave execution to force its execution to the interesting code blocks. To overcome these challenges, we developed two novel exploitation techniques: 1) Intel PT- and LBR-based history-inferring techniques and 2) APIC-based technique to control the execution of enclave programs in a fine-grained manner
Link: https://arxiv.org/abs/1611.06952
====================================================
Optimization and parallelization of B-spline based orbital evaluations in QMC on multi/many-core shared memory processors (Amrita Mathuriya - 8 November, 2016)
These optimizations are portable on four distinct cache-coherent architectures and result in up to 5.6x performance enhancements on Intel Xeon Phi processor 7250P (KNL), 5.7x on Intel Xeon Phi coprocessor 7120P, 10x on an Intel Xeon processor E5v4 CPU and 9.5x on BlueGene/Q processor. Our nested threading implementation shows nearly ideal parallel efficiency on KNL up to 16 threads. This work combined with our current efforts of optimizing other QMC kernels, result in greater than 4.5x speedup of miniQMC on KNL.
Link: https://arxiv.org/abs/1611.02665
====================================================
Efficient molecular dynamics simulations with many-body potentials on graphics processing units (Zheyong Fan - 25 June, 2017)
For the Tersoff many-body potential, the double precision performance of GPUMD using a Tesla K40 card is equivalent to that of the LAMMPS (Large-scale Atomic/Molecular Massively Parallel Simulator) molecular dynamics code running with about 100 CPU cores (Intel Xeon CPU X5670 @ 2.93 GHz).
Link: https://arxiv.org/abs/1610.03343
====================================================
Regular and almost universal hashing: an efficient implementation (Dmytro Ivanchykhin - 18 October, 2016)
On recent Intel processors, PM+ achieves a speed of 4.7 bytes per cycle for 32-bit outputs and 3.3 bytes per cycle for 64-bit outputs
Link: https://arxiv.org/abs/1609.09840
====================================================
Solving Batched Linear Programs on GPU and Multicore CPU (Amit Gurung - 26 September, 2016)
The thread parallel GLPK implementation runs $9.6\times$ faster in solving a batch of $1e5$ LPs of size $100$, on a $12$-core Intel Xeon processor
Link: https://arxiv.org/abs/1609.08114
====================================================
PVANET: Deep but Lightweight Neural Networks for Real-time Object Detection (Kye-Hyeon Kim - 30 September, 2016)
We obtained solid results on well-known object detection benchmarks: 83.8% mAP (mean average precision) on VOC2007 and 82.5% mAP on VOC2012 (2nd place), while taking only 750ms/image on Intel i7-6700K CPU with a single core and 46ms/image on NVIDIA Titan X GPU. Theoretically, our network requires only 12.3% of the computational cost compared to ResNet-101, the winner on VOC2012.
Link: https://arxiv.org/abs/1608.08021
====================================================
Co-design of a particle-in-cell plasma simulation code for Intel Xeon Phi: a first look at Knights Landing (Igor Surmin - 2 August, 2016)
This paper presents first performance results of the particle-in-cell plasma simulation code PICADOR on the recently introduced Knights Landing generation of Intel Xeon Phi. A straightforward rebuilding of the code yields a 2.43 x speedup compared to the previous Knights Corner generation. Further code optimization results in an additional 1.89 x speedup. The optimized version achieves 100 GFLOPS double precision performance on a Knights Landing device with the speedups of 2.35 x compared to a 14-core Haswell CPU and 3.47 x compared to a 61-core Knights Corner Xeon Phi.
Link: https://arxiv.org/abs/1608.01009
====================================================
Comment on "Spin-Orbit Logic with Magnetoelectric Nodes: A Scalable Charge Mediated Nonvolatile Spintronic Logic" (arXiv:1512.05428) (D. C. Ralph - 22 July, 2016)
Researchers from Intel Corporation recently proposed "Magneto-Electric Spin Orbit (MESO)" logic as a new strategy for beyond-CMOS electronics [1]. The Intel researchers project that this concept has the potential to reduce the switching energy per bit "to near thermodynamic limits for GHz logic (100 kT switching at 100 ps delay)", i.e., to near 0.4 aJ. [1] is incorrect, because the paper neglects a large energy cost associated with Ohmic dissipation that is unavoidable within the MESO scheme. Using optimistic parameters, the true minimum switching energy per bit within the MESO approach is at least 150 fJ, or more than 300,000 times greater than the value stated in ref. [1]
Link: https://arxiv.org/abs/1607.06690
====================================================
The Vectorization of the Tersoff Multi-Body Potential: An Exercise in Performance Portability (Markus HÃ¶hnerbach - 11 July, 2016)
On a cluster of Intel Xeon Phi's, our optimized solver is between 3 and 5 times faster than the pure MPI reference.
Link: https://arxiv.org/abs/1607.02904
====================================================
Selecting optimal parallel microchannel configurations for active hot spot mitigation of multicore microprocessors in real time (Lakshmi Sirisha Maganti - 10 July, 2016)
An Intel Core i7 4770 3.40 GHz quad core processor has been mimicked using heat load data retrieved from a real microprocessor with non-uniform core activity
Link: https://arxiv.org/abs/1607.02730
====================================================
TTC: A Tensor Transposition Compiler for Multiple Architectures (Paul Springer - 5 July, 2016)
We report speedups of TTC over a meaningful baseline implementation generated by external C++ compilers; the results suggest that a domain-specific compiler can outperform its general purpose counterpart significantly: For instance, comparing with Intel's latest C++ compiler on the Haswell and Knights Corner architecture, TTC yields speedups of up to $8\times$ and $32\times$, respectively. We also showcase TTC's support for multiple leading dimensions, making it a suitable candidate for the generation of performance-critical packing functions that are at the core of the ubiquitous BLAS 3 routines.
Link: https://arxiv.org/abs/1607.01249
====================================================
Using the pyMIC Offload Module in PyFR (Michael Klemm - 1 July, 2016)
Benchmark results show that for a standard cylinder flow problem PyFR with pyMIC is able achieve 240 GFLOP/s of sustained double precision floating point performance; for a 1.85 times improvement over PyFR with C/OpenMP on a 12 core Intel Xeon E5-2697 v2 CPU.
Link: https://arxiv.org/abs/1607.00844
====================================================
FPGA Online Tracking Algorithm for the PANDA Straw Tube Tracker (Yutie Liang - 23 June, 2016)
Comparing to the algorithm running on a CPU chip (single core Intel Xeon E5520 at 2.26 GHz), an improvement of 3 orders of magnitude in processing time is obtained. The algorithm can handle severe overlapping of events which are typical for interaction rates above 10 MHz.
Link: https://arxiv.org/abs/1606.07306
====================================================
Combinatorial Optimization of Work Distribution on Heterogeneous Systems (Suejb Memeti - 16 June, 2016)
We evaluate our approach experimentally using a heterogeneous platform that comprises two 12-core Intel Xeon E5 CPUs and an Intel Xeon Phi 7120P co-processor with 61 cores. Using our approach we are able to find a near-optimal system configuration by performing only about 5% of all possible experiments.
Link: https://arxiv.org/abs/1606.05134
====================================================
Analyzing the Gadgets Towards a Metric to Measure Gadget Quality (Andreas Follner - 26 May, 2016)
We apply these metrics to binaries produced when compiling programs for architectures implementing Intel's recent MPX CPU extensions. Our results demonstrate a 17% increase in useful gadgets in MPX binaries, and a decrease in side-effects and preconditions, making them better suited for ROP attacks.
Link: https://arxiv.org/abs/1605.08159
====================================================
DLAU: A Scalable Deep Learning Accelerator Unit on FPGA (Chao Wang - 23 May, 2016)
Experimental results on the state-of-the-art Xilinx FPGA board demonstrate that the DLAU accelerator is able to achieve up to 36.1x speedup comparing to the Intel Core2 processors, with the power consumption at 234mW.
Link: https://arxiv.org/abs/1605.06894
====================================================
The GPU-based Parallel Ant Colony System (RafaÅ Skinderowicz - 5 May, 2017)
Computational experiments conducted on several Travelling Salesman Problem (TSP) instances of sizes ranging from 198 to 2392 cities showed that the parallel ACS on Nvidia Kepler GK104 GPU (1536 CUDA cores) is able to obtain a speedup up to 24.29x vs the sequential ACS running on a single core of Intel Xeon E5-2670 CPU. The parallel ACS with the selective pheromone memory achieved speedups up to 16.85x, but in most cases the obtained solutions were of significantly better quality than for the sequential ACS.
Link: https://arxiv.org/abs/1605.02669
====================================================
Parallel Pairwise Correlation Computation On Intel Xeon Phi Clusters (Yongchao Liu - 26 September, 2016)
We have evaluated LightPCC and compared it to two CPU-based counterparts: a sequential C++ implementation in ALGLIB and an implementation based on a parallel general matrix-matrix multiplication routine in Intel Math Kernel Library (MKL) (all use double precision), using a set of gene expression datasets. Performance evaluation revealed that with one 5110P Phi and 16 Phis, LightPCC runs up to $20.6\times$ and $218.2\times$ faster than ALGLIB, and up to $6.8\times$ and $71.4\times$ faster than single-threaded MKL, respectively
Link: https://arxiv.org/abs/1605.01584
====================================================
Implementing Strassen's Algorithm with BLIS (Jianyu Huang - 3 May, 2016)
Our implementation demonstrates speedup over conventional DGEMM even on an Intel(R) Xeon Phi(TM) coprocessor utilizing 240 threads
Link: https://arxiv.org/abs/1605.01078
====================================================
Efficient Execution of Irregular Wavefront Propagation Pattern on Many Integrated Core Architecture (Jeremias Gomes - 3 May, 2016)
In this work, using the Intel (R) Xeon Phi (TM) coprocessor, we have implemented a vector version of IWPP with up to 5.63x gains on non-vectored version, a parallel version using First In, First Out (FIFO) queue that attained speedup up to 55x as compared to the single core version on the coprocessor, a version using priority queue whose performance was 1.62x better than the fastest version of GPU based implementation available in the literature, and a cooperative version between heterogeneous processors that allow to process images bigger than the Intel (R) Xeon Phi (TM) memory and also provides a way to utilize all the available devices in the computation.
Link: https://arxiv.org/abs/1605.00930
====================================================
Thermally smart characteristics of nanofluids in parallel microchannel systems to mitigate hot spots in MEMS (Lakshmi Sirisha Maganti - 1 May, 2016)
A silicon-based microchip emitting non-uniform heat flux (gathered from real-time monitoring of an Intel Core i7 4770 3.40 GHz quad core processor) under various processor load conditions has been studied and evidence of enhanced cooling of hot spots has been obtained from DPM analysis.
Link: https://arxiv.org/abs/1605.00244
====================================================
LightScan: Faster Scan Primitive on CUDA Compatible Manycore Processors (Yongchao Liu - 16 April, 2016)
Furthermore, LightScan runs up to 8.9 and 257.3 times faster than Intel TBB running on 16 CPU cores and an Intel Xeon Phi 5110P coprocessor, respectively
Link: https://arxiv.org/abs/1604.04815
====================================================
Reliable Linear, Sesquilinear and Bijective Operations On Integer Data Streams Via Numerical Entanglement (Mohammad Ashraful Anam - 16 April, 2016)
We have validated our proposal in an Intel processor (Haswell architecture with AVX2 support) via fast Fourier transforms, circular convolutions, and matrix multiplication operations. Our analysis and experiments reveal that the proposed approach incurs between $0.03\%$ to $7\%$ reduction in processing throughput for a wide variety of LSB operations. This overhead is 5 to 1000 times smaller than that of the equivalent ABFT method that uses a checksum stream
Link: https://arxiv.org/abs/1604.04740
====================================================
A Left-Looking Selected Inversion Algorithm and Task Parallelism on Shared Memory Systems (Mathias Jacquelin - 9 April, 2016)
We demonstrate that with the task scheduling features provided by OpenMP 4.0, the left-looking selected inversion algorithm can scale well both on the Intel Haswell multicore architecture and on the Intel Knights Corner (KNC) manycore architecture
Link: https://arxiv.org/abs/1604.02528
====================================================
Parallel Delta-Stepping Algorithm for Shared Memory Architectures (M. KranjÄeviÄ - 20 February, 2017)
We collect performance data on multi-core CPUs and Intel Xeon Phi. Both on the CPU and the co-processor we achieve an overall performance of at least 50% parallel efficiency.
Link: https://arxiv.org/abs/1604.02113
====================================================
Evaluating the Performance Impact of Multiple Streams on the MIC-based Heterogeneous Platform (Zhaokui Li - 28 March, 2016)
Prior work focuses a lot on GPUs but little is known about the performance impact on (Intel Xeon) Phi. At the real-world application level, we show that both overlappable and non-overlappable applications can benefit from using multiple streams (with an performance improvement of up to 24\%)
Link: https://arxiv.org/abs/1603.08619
====================================================
Classification-based Financial Markets Prediction using Deep Neural Networks (Matthew Dixon - 13 June, 2017)
All results in this paper are generated using a C++ implementation on the Intel Xeon Phi co-processor which is 11.4x faster than the serial version and a Python strategy backtesting environment both of which are available as open source code written by the authors.
Link: https://arxiv.org/abs/1603.08604
====================================================
GPU Computing in Bayesian Inference of Realized Stochastic Volatility Model (Tetsuya Takaishi - 26 March, 2016)
We compare the computational time in performing the HMC algorithm on GPU (GTX 760) and CPU (Intel i7-4770 3.4GHz) and find that the GPU can be up to 17 times faster than the CPU
Link: https://arxiv.org/abs/1603.08114
====================================================
A portable platform for accelerated PIC codes and its application to GPUs using OpenACC (F. Hariri - 9 March, 2016)
Using the Cray XC30 system, Piz Daint, at the Swiss National Supercomputing Centre (CSCS), we show that PIC_ENGINE running on an NVIDIA Kepler K20X GPU can outperform the one on an Intel Sandybridge 8-core CPU by a factor of 3.4.
Link: https://arxiv.org/abs/1603.02886
====================================================
TTC: A high-performance Compiler for Tensor Transpositions (Paul Springer - 7 March, 2016)
Performance results show that the routines generated by TTC achieve close to peak memory bandwidth on both the Intel Haswell and the AMD Steamroller architectures, and yield significant performance gains over modern compilers. Experiments indicate that when only 100 potential solutions are considered, the resulting performance is about 99% of that achieved with exhaustive search.
Link: https://arxiv.org/abs/1603.02297
====================================================
If-Conversion Optimization using Neuro Evolution of Augmenting Topologies (Reem Elkhouly - 3 March, 2016)
We implemented our tech- nique in LLVM 3.6.1 compilation infrastructure and experimented on the kernels of SPEC-CPU2006 v1.1 benchmarks suite running on a multicore system of Intel(R) Xeon(R) 3.50GHz processors. Our findings show a performance gain up to 8.6% over the stan- dard optimized code (LLVM -O2 with if-conversion included), in- dicating the need for If-conversion compilation optimization that can adapt to the unique characteristics of every individual branch.
Link: https://arxiv.org/abs/1603.01112
====================================================
Wanted: Floating-Point Add Round-off Error instruction (Marat Dukhan - 1 March, 2016)
Performance estimates on Intel Haswell, Intel Skylake, and AMD Steamroller processors, as well as Intel Knights Corner co-processor, demonstrate that such an instruction would improve the latency of double-double addition by up to 55% and increase double-double addition throughput by up to 103%, with smaller, but non-negligible benefits for double-double multiplication. The new instruction delivers up to 2x speedups on three benchmarks that use high-precision floating-point arithmetic: double-double matrix-matrix multiplication, compensated dot product, and polynomial evaluation via the compensated Horner scheme.
Link: https://arxiv.org/abs/1603.00491
====================================================
Semi-External Memory Sparse Matrix Multiplication for Billion-Node Graphs (Da Zheng - 14 October, 2016)
It outperforms the in-memory implementations of Trilinos and Intel MKL and scales to billion-node graphs, far beyond the limitations of memory. SEM-SpMM achieves almost 100% performance of IM-SpMM on graphs when the dense matrix has more than four columns; it achieves at least 65% performance of IM-SpMM on all inputs
Link: https://arxiv.org/abs/1602.02864
====================================================
Bit-Planes: Dense Subpixel Alignment of Binary Descriptors (Hatem Alismail - 31 January, 2016)
The approach is demonstrated on a template tracking problem achieving state-of-the-art robustness and faster than real-time performance on consumer laptops (400+ fps on a single core Intel i7) and hand-held mobile devices (100+ fps on an iPad Air 2).
Link: https://arxiv.org/abs/1602.00307
====================================================
Task Parallel Incomplete Cholesky Factorization using 2D Partitioned-Block Layout (Kyungjoo Kim - 21 January, 2016)
Experimental results demonstrate that our task-parallel implementation delivers about 26.6x speedup (geometric mean) over single-threaded incomplete Cholesky-by-blocks and 19.2x speedup over serial Cholesky performance which does not carry tasking overhead using 56 threads on the Intel Xeon Phi processor for sparse matrices arising from various application problems.
Link: https://arxiv.org/abs/1601.05871
====================================================
Basker: A Threaded Sparse LU Factorization Utilizing Hierarchical Parallelism and Data Layouts (Joshua Dennis Booth - 21 January, 2016)
We present performance evaluations of Basker on the Intel SandyBridge and Xeon Phi platforms using circuit and power grid matrices taken from the University of Florida sparse matrix collection and from Xyce circuit simulations. Basker achieves a geometric mean speedup of 5.91x on CPU (16 cores) and 7.4x on Xeon Phi (32 cores) relative to KLU. Basker outperforms Intel MKL Pardiso (PMKL) by as much as 53x on CPU (16 cores) and 13.3x on Xeon Phi (32 cores) for low fill-in circuit matrices. Furthermore, Basker provides 5.4x speedup on a challenging matrix sequence taken from an actual Xyce simulation.
Link: https://arxiv.org/abs/1601.05725
====================================================
Multiple right-hand-side setup for the DD-Î±AMG (Daniel Richtmann - 13 January, 2016)
The synchronization overhead inflicted by on-chip parallelization (threading), which is becoming crucial on many-core architectures such as the Intel Xeon Phi, is effectively reduced. In the parts implemented so far, we observe a speedup of roughly 3x compared to the optimized version of the single right-hand-side setup on realistic lattices.
Link: https://arxiv.org/abs/1601.03184
====================================================
Aging in the three-dimensional Random Field Ising Model (Sebastian von Ohr - 25 January, 2016)
To reach these necessary long simulation times we employed an implementation running on Intel Xeon Phi coprocessors, reaching single spin flip times as short as 6 ps
Link: https://arxiv.org/abs/1601.02455
====================================================
A Semi-Markovian Modeling of Limit Order Markets (Anatoliy Swishchuk - 7 January, 2016)
We justify and illustrate our approach by calibrating our model to the five stocks Amazon, Apple, Google, Intel and Microsoft on June 21^{st} 2012
Link: https://arxiv.org/abs/1601.01710
====================================================
Comparison of cinepak, intel, microsoft video and indeo codec for video compression (Suleiman Mustafa - 7 January, 2016)
This work compares Cinepak, Intel, Microsoft Video and Indeo Codec for video compression. Peak Signal to Noise Ration is measured on a logarithmic scale and depends on the mean squared error (MSE) between an original and an impaired image or video, relative to (2n-1)2.
Link: https://arxiv.org/abs/1601.01408
====================================================
Efficient Construction of Simultaneous Deterministic Finite Automata on Multicores Using Rabin Fingerprints (Minyoung Jung - 25 September, 2017)
Evaluations have been conducted on a 4 CPU (64 cores) AMD Opteron 6378 system and a 2 CPU (28 cores, 2 hyperthreads per core) Intel Xeon E5-2697 v3 system. The observed speedups over the sequential baseline algorithm are up to 118541x on the AMD system and 2113968x on the Intel system.
Link: https://arxiv.org/abs/1512.09228
====================================================
An efficient solver for large structured eigenvalue problems in relativistic quantum chemistry (Toru Shiozaki - 16 February, 2016)
Taking advantage of the symmetry, the program is faster by up to a factor of two than state-of-the-art implementations of complex Hermitian diagonalization; diagonalizing a 12800 x 12800 matrix took 42.8 (9.5) and 85.6 (12.6) minutes with 1 CPU core (16 CPU cores) using our symmetry-adapted solver and Intel MKL's ZHEEV that is not structure-preserving, respectively
Link: https://arxiv.org/abs/1512.08934
====================================================
Impact of exponential long range and Gaussian short range lateral connectivity on the distributed simulation of neural networks including up to 30 billion synapses (Elena Pastorelli - 16 December, 2015)
The hardware platform was a cluster of IBM NX360 M5 16-core compute nodes, each one containing two Intel Xeon Haswell 8-core E5-2630 v3 processors, with a clock of 2.40GHz, interconnected through an InfiniBand network. This study is conducted in the framework of the CORTICONIC FET project, also in view of the next -to-start activities foreseen as part of the Human Brain Project (HBP), SubProject 3 Cognitive and Systems Neuroscience, WaveScalES work-package.
Link: https://arxiv.org/abs/1512.05264
====================================================
Adaptive algebraic multigrid on SIMD architectures (Simon Heybrock - 14 December, 2015)
We present details of our implementation of the Wuppertal adaptive algebraic multigrid code DD-$Î±$AMG on SIMD architectures, with particular emphasis on the Intel Xeon Phi processor (KNC) used in QPACE 2
Link: https://arxiv.org/abs/1512.04506
====================================================
Ãber die Klassifizierung von Knoten in dynamischen Netzwerken mit Inhalt (Martin Thoma - 23 November, 2015)
Aggarwal and Li measured in an experimental analysis that DYCOS adds the missing labels to a Graph with 19396 nodes of which 14814 are labeled and another Graph with 806635 nodes of which 18999 are labeld on one core of an Intel Xeon 2.5 GHz CPU with 32 G RAM within less than a minute
Link: https://arxiv.org/abs/1512.04469
====================================================
Scaling to 1024 software processes and hardware cores of the distributed simulation of a spiking neural network including up to 20G synapses (Elena Pastorelli - 30 November, 2015)
The neural network was distributed over a set of MPI processes and the simulations were run on a server platform composed of up to 64 dual-socket nodes, each socket equipped with Intel Haswell E5-2630 v3 processors (8 cores @ 2.4 GHz clock). The DPSNN simulator has been developed by INFN in the framework of EURETILE and CORTICONIC European FET Project and will be used by the WaveScalEW tem in the framework of the Human Brain Project (HBP), SubProject 2 - Cognitive and Systems Neuroscience
Link: https://arxiv.org/abs/1511.09325
====================================================
Model-Driven Automatic Tiling with Cache Associativity Lattices (David Adjiashvili - 17 November, 2015)
We also describe an implementation of our lattice tiling approach, show that it can be used to give speedups of over 10x versus unoptimized code, and despite currently only tiling for one level of cache, can already be competitive with the aggressive compiler optimizations used in general purposes compares such as GCC and Intel's ICC
Link: https://arxiv.org/abs/1511.05585
====================================================
ARMageddon: Cache Attacks on Mobile Devices (Moritz Lipp - 19 June, 2016)
In the last 10 years, cache attacks on Intel x86 CPUs have gained increasing attention among the scientific community and powerful techniques to exploit cache side channels have been developed. However, modern smartphones use one or more multi-core ARM CPUs that have a different cache organization and instruction set than Intel x86 CPUs
Link: https://arxiv.org/abs/1511.04897
====================================================
A polyphase filter for many-core architectures (Karel AdÃ¡mek - 21 April, 2016)
We describe in detail our implementation of the polyphase filter algorithm and its behaviour on three generations of NVIDIA GPU cards, on dual Intel Xeon CPUs and the Intel Xeon Phi (Knights Corner) platforms. We show that our Xeon Phi implementation has a performance that is 1.47x to 1.95x greater than our CPU implementation, however is not insufficient to compete with the performance of GPUs
Link: https://arxiv.org/abs/1511.03599
====================================================
Exact diagonalization of quantum lattice models on coprocessors (Topi Siro - 24 May, 2016)
We implement the Lanczos algorithm on an Intel Xeon Phi coprocessor and compare its performance to a multi-core Intel Xeon CPU and an NVIDIA graphics processor. We study two quantum lattice models with different particle numbers, and conclude that for small systems, the multi-core CPU is the fastest platform, while for large systems, the graphics processor is the clear winner, reaching speedups of up to 7.6 compared to the CPU. The Xeon Phi outperforms the CPU with sufficiently large particle number, reaching a speedup of 2.5.
Link: https://arxiv.org/abs/1511.00863
====================================================
Accelerating Twisted Mass LQCD with QPhiX (Mario SchrÃ¶ck - 29 October, 2015)
We analyze the performance on the Intel Xeon Phi (Knights Corner) coprocessor as well as on Intel Xeon Haswell CPUs. In particular, we demonstrate that on the Xeon Phi 7120P the Dslash kernel is able to reach 80\% of the theoretical peak bandwidth, while on a Xeon Haswell E5-2630 CPU our generated code for the Dslash operator with AVX2 instructions outperforms the corresponding implementation in the tmLQCD library by a factor of $\sim 5\times$ in single precision. We strong scale the code up to 6.8 (14.1) Tflops in single (half) precision on 64 Xeon Haswell CPUs.
Link: https://arxiv.org/abs/1510.08879
====================================================
Modern Gyrokinetic Particle-In-Cell Simulation of Fusion Plasmas on Top Supercomputers (Bei Wang - 19 October, 2015)
This particularly includes implementations on heterogeneous systems using NVIDIA GPU accelerators and Intel Xeon Phi (MIC) co-processors and performance comparisons with state-of-the-art homogeneous HPC systems such as Blue Gene/Q
Link: https://arxiv.org/abs/1510.05546
====================================================
New fast divide-and-conquer algorithms for the symmetric tridiagonal eigenvalue problem (Shengguo Li - 15 October, 2015)
Comparing the ADCs with highly optimized multithreaded libraries such as Intel MKL, we find that ADCs could be more than 6x times faster for some large matrices with few deflations.
Link: https://arxiv.org/abs/1510.04591
====================================================
Hydrostatic Simulation of Earth's Atmospheric Gas Using Multi-particle Collision Dynamics (Asis Pattisahusiwa - 25 September, 2015)
Simulation program is executed in Arch Linux and running in notebook with processor Intel i5 @2700 MHz with 10 GB DDR3 RAM
Link: https://arxiv.org/abs/1509.07603
====================================================
Failure Mitigation in Linear, Sesquilinear and Bijective Operations On Integer Data Streams Via Numerical Entanglement (Mohammad Ashraful Anam - 13 September, 2015)
We have validated our proposal in an Intel processor (Haswell architecture with AVX2 support) via convolution operations. This overhead is 9 to 14 times smaller than that of the equivalent checksum-based method
Link: https://arxiv.org/abs/1509.03838
====================================================
HAPPY: Hybrid Address-based Page Policy in DRAMs (Mohsen Ghasempour - 12 September, 2015)
As a case study, we integrate our technique, HAPPY, with a state-of-the-art monitor, the Intel-adaptive open-page policy predictor employed by the Intel Xeon X5650, and a traditional Hybrid page policy. We evaluate them across 70 memory intensive workload mixes consisting of single-thread and multi-thread applications. The experimental results show that using the HAPPY encoding applied to the Intel-adaptive page closure policy can reduce the hardware overhead by 5X for the evaluated 64 GB memory (up to 40X for a 512 GB memory) while maintaining the prediction accuracy.
Link: https://arxiv.org/abs/1509.03740
====================================================
Massively Parallel Algorithms for the Lattice Boltzmann Method on Non-uniform Grids (Florian Schornbaum - 21 January, 2016)
On an Intel-based system, the strong scaling of a simulation with refined grids and a total of more than 8.5 million cells is demonstrated to reach a performance of less than one millisecond per time step
Link: https://arxiv.org/abs/1508.07982
====================================================
Compact Convolutional Neural Network Cascade for Face Detection (Ilya Kalinovskii - 23 November, 2015)
Because of high computational efficiency, our detector can processing 4K Ultra HD video stream in real time (up to 27 fps) on mobile platforms (Intel Ivy Bridge CPUs and Nvidia Kepler GPUs) in searching objects with the dimension 60x60 pixels or higher
Link: https://arxiv.org/abs/1508.01292
====================================================
batman: BAsic Transit Model cAlculatioN in Python (Laura Kreidberg - 18 August, 2015)
For a typical light curve with 100 data points in transit, batman can calculate one million quadratic limb-darkened models in 30 seconds with a single 1.7 GHz Intel Core i5 processor. The same calculation takes seven minutes using the four-parameter nonlinear limb darkening model (computed to 1 ppm accuracy). Maximum truncation error for integrated models is an input parameter that can be set as low as 0.001 ppm, ensuring that the community is prepared for the precise transit light curves we anticipate measuring with upcoming facilities
Link: https://arxiv.org/abs/1507.08285
====================================================
Scaling Monte Carlo Tree Search on Intel Xeon Phi (S. Ali Mirsoleimani - 15 July, 2015)
The Intel Xeon Phi allows shared memory scaling studies up to 61 cores and 244 hardware threads. We achieve, to the best of our knowledge, the fastest implementation of a parallel MCTS on the 61 core Intel Xeon Phi using a real application (47 relative to a sequential run).
Link: https://arxiv.org/abs/1507.04383
====================================================
Model-based optimization of MPDATA on Intel Xeon Phi through load imbalancing (Alexey Lastovetsky - 5 July, 2015)
We show how to apply this algorithm to optimization of MPDATA on Intel Xeon Phi. Experimental results demonstrate that the performance of this carefully optimized load-balanced application can be further improved by 15\% using the proposed load-imbalancing optimization.
Link: https://arxiv.org/abs/1507.01265
====================================================
The Potential of the Intel Xeon Phi for Supervised Deep Learning (Andre Viebke - 30 June, 2015)
Our approach is evaluated on the Intel Xeon Phi 7120P using the MNIST dataset of handwritten digits for various thread counts and CNN architectures. Results show a 103.5x speed up when training our large network for 15 epochs using 244 threads, compared to one thread on the coprocessor
Link: https://arxiv.org/abs/1506.09067
====================================================
Accelerating DNA Sequence Analysis using Intel Xeon Phi (Suejb Memeti - 29 June, 2015)
The experimental results on Intel Xeon Phi show speed-ups of up to 10x compared to a sequential implementation running on an Intel Xeon processor E5.
Link: https://arxiv.org/abs/1506.08612
====================================================
Characterization and Architectural Implications of Big Data Workloads (Lei Wang - 25 June, 2015)
On a typical state-of-practice platform---Intel Xeon E5645, we compare the representative big data workloads with SPECINT, SPECCFP, PARSEC, CloudSuite and HPCC. First, the big data workloads are data movement dominated computing with more branch operations, taking up to 92% percentage in terms of instruction mix, which places them in a different class from Desktop (SPEC CPU2006), CMP (PARSEC), HPC (HPCC) workloads
Link: https://arxiv.org/abs/1506.07943
====================================================
Preventing Your Faults From Telling Your Secrets: Defenses Against Pigeonhole Attacks (Shweta Shinde - 12 January, 2016)
New hardware primitives such as Intel SGX secure a user-level process in presence of an untrusted or compromised OS. In this paper, we show that the page fault side-channel has sufficient channel capacity to extract bits of encryption keys from commodity implementations of cryptographic routines in OpenSSL and Libgcrypt --- leaking 27% on average and up to 100% of the secret bits in many case-studies. This defense when implemented generically can have significant overhead of up to 4000X, but with help of developer-assisted compiler optimizations, the overhead reduces to at most 29.22% in our case studies. Finally, we discuss scope for hardware-assisted defenses, and show one solution that can reduce overheads to 6.77% with support from hardware changes.
Link: https://arxiv.org/abs/1506.04832
====================================================
Machine Learning Based Auto-tuning for Enhanced OpenCL Performance Portability (Thomas L. Falch - 2 June, 2015)
We evaluate our method with different benchmarks, on several devices, including an Intel i7 3770 CPU, an Nvidia K40 GPU and an AMD Radeon HD 7970 GPU. Our model achieves a mean relative error as low as 6.1%, and is able to find configurations as little as 1.3% worse than the global minimum.
Link: https://arxiv.org/abs/1506.00842
====================================================
Particle-in-Cell Laser-Plasma Simulation on Xeon Phi Coprocessors (I. A. Surmin - 27 May, 2015)
This paper concerns development of a high-performance implementation of the Particle-in-Cell method for plasma simulation on Intel Xeon Phi coprocessors. Direct porting with no code modification gives performance on Xeon Phi close to 8-core CPU on a benchmark problem with 50 particles per cell. We demonstrate step-by-step application of optimization techniques such as improving data locality, enhancing parallelization efficiency and vectorization that leads to 3.75 x speedup on CPU and 7.5 x on Xeon Phi. The optimized version achieves 18.8 ns per particle update on Intel Xeon E5-2660 CPU and 9.3 ns per particle update on Intel Xeon Phi 5110P. On a real problem of laser ion acceleration in targets with surface grating that requires a large number of macroparticles per cell the speedup of Xeon Phi compared to CPU is 1.6 x.
Link: https://arxiv.org/abs/1505.07271
====================================================
Thread Parallelism for Highly Irregular Computation in Anisotropic Mesh Adaptation (Georgios Rokos - 18 May, 2015)
This work is motivated by mesh adaptation algorithms, for which we show a parallel efficiency of 60% and 50% on Intel(R) Xeon(R) Sandy Bridge and AMD Opteron(tm) Magny-Cours systems, respectively, using these techniques.
Link: https://arxiv.org/abs/1505.04694
====================================================
Prediction of sustained harmonic walking in the free-living environment using raw accelerometry data (Jacek K. Urbanek - 16 November, 2017)
150 million measurements) in relatively short time (~half an hour) on a common laptop computer (2.8 GHz Intel Core i7, 16 GB DDR3 RAM).
Link: https://arxiv.org/abs/1505.04066
====================================================
A Vision Based System for Monitoring the Loss of Attention in Automotive Drivers (Anirban Dasgupta - 13 May, 2015)
The algorithm has been cross validated using brain signals and finally been implemented on a Single Board Computer (SBC) having Intel Atom processor, 1 GB RAM, 1.66 GHz clock, x86 architecture, Windows Embedded XP operating system
Link: https://arxiv.org/abs/1505.03352
====================================================
Power, Energy and Speed of Embedded and Server Multi-Cores applied to Distributed Simulation of Spiking Neural Networks: ARM in NVIDIA Tegra vs Intel Xeon quad-cores (Pier Stanislao Paolucci - 12 May, 2015)
This short note regards a comparison of instantaneous power, total energy consumption, execution time and energetic cost per synaptic event of a spiking neural network simulator (DPSNN-STDP) distributed on MPI processes when executed either on an embedded platform (based on a dual socket quad-core ARM platform) or a server platform (INTEL-based quad-core dual socket platform). In summary, we observed that: 1- we spent 2.2 micro-Joule per simulated event on the "embedded platform", approx. 4.4 times lower than what was spent by the "server platform"; 2- the instantaneous power consumption of the "embedded platform" was 14.4 times better than the "server" one; 3- the server platform is a factor 3.3 faster
Link: https://arxiv.org/abs/1505.03015
====================================================
Performance evaluation of the Mojette erasure code for fault-tolerant distributed hot data storage (Dimitri Pertin - 27 April, 2015)
A gain factor up to $2$ is measured in comparison with the ISA-L Intel 
Link: https://arxiv.org/abs/1504.07038
====================================================
Speculative Segmented Sum for Sparse Matrix-Vector Multiplication on Heterogeneous Processors (Weifeng Liu - 14 September, 2015)
On three heterogeneous processors from Intel, AMD and nVidia, using 20 sparse matrices as a benchmark suite, the experimental results show that our method obtains significant performance improvement over the best existing CSR-based SpMV algorithms
Link: https://arxiv.org/abs/1504.06474
====================================================
Faster linearizability checking via $P$-compositionality (Alex Horn - 1 April, 2015)
Our experiments with over nine implementations of concurrent sets, including Intel's TBB library, show that our linearizability checker is one order of magnitude faster and/or more space efficient than the state-of-the-art algorithm.
Link: https://arxiv.org/abs/1504.00204
====================================================
CSR5: An Efficient Storage Format for Cross-Platform Sparse Matrix-Vector Multiplication (Weifeng Liu - 9 April, 2015)
For the 10 irregular matrices, the CSR5 obtains average performance improvement of 17.6\%, 28.5\%, 173.0\% and 293.3\% (up to 213.3\%, 153.6\%, 405.1\% and 943.3\%) over the best existing work on dual-socket Intel CPUs, an nVidia GPU, an AMD GPU and an Intel Xeon Phi, respectively
Link: https://arxiv.org/abs/1503.05032
====================================================
Evaluating kernels on Xeon Phi to accelerate Gysela application (G. Latu - 3 August, 2015)
We evaluate the performance of somegeneric micro-benchmark on Phi versus Intel Sandy Bridge. Some memory-bound and compute-bound kernels are accelerated by a factor 2 on the Phi device compared to Sandy architecture
Link: https://arxiv.org/abs/1503.04645
====================================================
Faster 64-bit universal hashing using carry-less multiplications (Daniel Lemire - 4 November, 2015)
Intel and AMD support the Carry-less Multiplication (CLMUL) instruction set in their x64 processors. We compare this new family with what might be the fastest almost universal family on x64 processors (VHASH). We find that CLHASH is at least 60% faster. We find that CLHASH is 40% faster than CityHash on inputs larger than 64 bytes and just as fast otherwise.
Link: https://arxiv.org/abs/1503.03465
====================================================
DCAFE: Dynamic load-balanced loop Chunking & Aggressive Finish Elimination for Recursive Task Parallel Programs (Suyash Gupta - 21 February, 2015)
With respect to the base X10 compiler extended with loop-chunking of Nandivada et al [Nandivada et al.(2013)Nandivada, Shirako, Zhao, and Sarkar](LC), DCAFE achieved a geometric mean speed up of 5.75x and 4.16x on the Intel and AMD system, respectively. We also present an evaluation with respect to the energy consumption on the Intel system and show that on average, compared to the LC versions, the DCAFE versions consume 71.2% less energy.
Link: https://arxiv.org/abs/1502.06086
====================================================
QPACE 2 and Domain Decomposition on the Intel Xeon Phi (Paul Arts - 13 February, 2015)
We give an overview of QPACE 2, which is a custom-designed supercomputer based on Intel Xeon Phi processors, developed in a collaboration of Regensburg University and Eurotech
Link: https://arxiv.org/abs/1502.04025
====================================================
Lattice QCD with Domain Decomposition on Intel Xeon Phi Co-Processors (Simon Heybrock - 8 December, 2014)
We investigate this in the context of Lattice Quantum Chromodynamics and implement such an alternative solver algorithm, based on domain decomposition, on Intel Xeon Phi co-processor (KNC) clusters. We demonstrate close-to-linear on-chip scaling to all 60 cores of the KNC. Compared to an optimized KNC implementation of a standard solver [1], our full multi-node domain-decomposition solver strong-scales to more nodes and reduces the time-to-solution by a factor of 5.
Link: https://arxiv.org/abs/1412.2629
====================================================
Parallelize Bubble and Merge Sort Algorithms Using Message Passing Interface (MPI) (Zaid Abdi Alkareem Alyasseri - 19 November, 2014)
We implemented MPI using Intel core i7-3610QM ,(8 CPUs),using two approaches (vectors of string and array 3D) 
Link: https://arxiv.org/abs/1411.5283
====================================================
Conjugate gradient solvers on Intel Xeon Phi and NVIDIA GPUs (O. Kaczmarek - 17 November, 2014)
Here we compare the performance of the Intel Xeon Phi to current Kepler-based NVIDIA Tesla GPUs running a conjugate gradient solver. By exposing more parallelism to the accelerator through inverting multiple vectors at the same time, we obtain a performance greater than 300 GFlop/s on both architectures
Link: https://arxiv.org/abs/1411.4439
====================================================
Glider: A GPU Library Driver for Improved System Security (Ardalan Amiri Sani - 13 November, 2014)
Glider reduces the TCB size and attack surface by about 35% and 84% respectively for a Radeon HD 6450 GPU and by about 38% and 90% respectively for an Intel Ivy Bridge GPU
Link: https://arxiv.org/abs/1411.3777
====================================================
On the Hardness of Bribery Variants in Voting with CP-Nets (Britta Dorn - 18 May, 2016)
Intell. 1--26 (2013)) in which they study the computational complexity of bribery schemes when voters have conditional preferences that are modeled by CP-nets
Link: https://arxiv.org/abs/1410.5186
====================================================
Techniques and tools for measuring energy efficiency of scientific software applications (David Abdurachmanov - 10 October, 2014)
There has been a growing interest in utilizing alternate architectures, such as low power ARM processors, to replace traditional Intel x86 architectures
Link: https://arxiv.org/abs/1410.3440
====================================================
Intel Cilk Plus for Complex Parallel Algorithms: "Enormous Fast Fourier Transform" (EFFT) Library (Ryo Asai - 19 September, 2014)
The result of our work is a library called EFFT that performs 1D DFTs of size 2^N for N>=21 faster than the corresponding Intel MKL parallel DFT implementation by up to 1.5x, and faster than FFTW by up to 2.5x
Link: https://arxiv.org/abs/1409.5757
====================================================
Performance analysis of a 240 thread tournament level MCTS Go program on the Intel Xeon Phi (S. Ali Mirsoleimani - 6 November, 2014)
In 2013 Intel introduced the Xeon Phi, a new parallel co-processor board. We report the first speedup figures for up to 240 parallel threads on a real machine, allowing a direct comparison to previous simulation studies. After a substantial amount of work, we observed that performance scales well up to 32 threads, largely confirming previous simulation results of this Go program, although the performance surprisingly deteriorates between 32 and 240 threads
Link: https://arxiv.org/abs/1409.4297
====================================================
HISQ inverter on Intel Xeon Phi and NVIDIA GPUs (O. Kaczmarek - 4 September, 2014)
In this contribution we compare the performance of the Intel Xeon Phi to current Kepler-based NVIDIA Tesla GPUs running a conjugate gradient solver. By exposing more parallelism to the accelerator through inverting multiple vectors at the same time we obtain a performance 250 GFlop/s on both architectures
Link: https://arxiv.org/abs/1409.1510
====================================================
Heterogeneous Computing on Mixed Unstructured Grids with PyFR (F. D. Witherden - 1 September, 2014)
Specifically, after benchmarking single-node performance for various platforms, PyFR v0.2.2 is used to undertake simulations of unsteady flow over a circular cylinder at Reynolds number 3 900 using a mixed unstructured grid of prismatic and tetrahedral elements on a desktop workstation containing an Intel Xeon E5-2697 v2 CPU, an NVIDIA Tesla K40c GPU, and an AMD FirePro W9100 GPU
Link: https://arxiv.org/abs/1409.0405
====================================================
An Automatic Mixed Software Hardware Pipeline Builder for CPU-FPGA Platforms (Takaaki Miyajima - 21 August, 2014)
The Pipeline Generator builds a pipeline control program by using Intel Threading Building Block to run both hardware modules and software functions in parallel. A series of functions were off-loaded, and speed up 15.36 times was achieved by using the built pipeline.
Link: https://arxiv.org/abs/1408.4969
====================================================
Parallelize Bubble Sort Algorithm Using OpenMP (Zaid Abdi Alkareem Alyasseri - 24 July, 2014)
We implemented OpenMP using Intel core i7-3610QM ,(8 CPUs),using two approaches (vectors of string and array 3D) 
Link: https://arxiv.org/abs/1407.6603
====================================================
A Way For Accelerating The DNA Sequence Reconstruction Problem By CUDA (Yukun Zhong - 13 April, 2014)
The experimental result show the construction of suffix array using GPU is an more efficient approach on Intel(R) Core(TM) i3-3110K quad-core and NVIDIA GeForce 610M GPU, and study show the performance of our method is more than 20 times than that of CPU serial implementation
Link: https://arxiv.org/abs/1404.3456
====================================================
Solving The Longest Overlap Region Problem for Noncoding DNA Sequences with GPU (YuKun Zhong - 27 October, 2014)
Our paper introduces a way to solve the longest overlap region of non-coding DNA sequences on using the Compute Unified Device Architecture (CUDA) platform Intel(R) Core(TM) i3- 3110m quad-core. Studies show the fact that efficiency of GPU performance is more than 20 times speedup than that of CPU serial implementation
Link: https://arxiv.org/abs/1404.3448
====================================================
MICA: A fast short-read aligner that takes full advantage of Intel Many Integrated Core Architecture (MIC) (Sze-Hang Chan - 19 February, 2014)
An uprising alternative to GPU is Intel MIC; supercomputers like Tianhe-2, currently top of TOP500, is built with 48,000 MIC boards to offer ~55 PFLOPS. Experiments on aligning 150bp paired-end reads show that MICA using one MIC board is 4.9 times faster than the BWA-MEM (using 6-core of a top-end CPU), and slightly faster than SOAP3-dp (using a GPU). Furthermore, MICAs simplicity allows very efficient scale-up when multiple MIC boards are used in a node (3 cards give a 14.1-fold speedup over BWA-MEM). We have tested MICA on Tianhe-2 with 90 WGS samples (17.47 Tera-bases), which can be aligned in an hour less than 400 nodes. MICA has impressive performance even though the current MIC is at its initial stage of development (the next generation of MIC has been announced to release in late 2014).
Link: https://arxiv.org/abs/1402.4876
====================================================
Comparing the Performance of Different x86 SIMD Instruction Sets for a Medical Imaging Application on Modern Multi- and Manycore Chips (Johannes Hofmann - 29 January, 2014)
We analyze the performance of SSE (128 bit), AVX (256 bit), AVX2 (256 bit), and IMCI (512 bit) implementations on recent Intel x86 systems
Link: https://arxiv.org/abs/1401.7494
====================================================
BigDataBench: a Big Data Benchmark Suite from Internet Services (Lei Wang - 22 February, 2014)
On a typical state-of-practice processor, Intel Xeon E5645, we have the following observations: First, in comparison with the traditional benchmarks: including PARSEC, HPCC, and SPECCPU, big data applications have very low operation intensity; Second, the volume of data input has non-negligible impact on micro-architecture characteristics, which may impose challenges for simulation-based big data architecture research; Last but not least, corroborating the observations in CloudSuite and DCBench (which use smaller data inputs), we find that the numbers of L1 instruction cache misses per 1000 instructions of the big data applications are higher than in the traditional benchmarks; also, we find that L3 caches are effective for the big data applications, corroborating the observation in DCBench.
Link: https://arxiv.org/abs/1401.1406
====================================================
Optimized simulated annealing for Ising spin glasses (S. V. Isakov - 24 September, 2015)
The latter codes achieve up to 50 spin flips per nanosecond on modern Intel CPUs
Link: https://arxiv.org/abs/1401.1084
====================================================
Digitize Your Body and Action in 3-D at Over 10 FPS: Real Time Dense Voxel Reconstruction and Marker-less Motion Tracking via GPU Acceleration (Jian Song - 26 November, 2013)
For the CPU only acceleration, we leverage Intel TBB to speed up the hot spot of the computational overhead and reached an accelerating ratio of 3.5 on a 4-core CPU. Taking account all data transfer and computing time, the GPU version is about 400 times faster than the original CPU implementation, leading the approach to run at a real-time speed.
Link: https://arxiv.org/abs/1311.6811
====================================================
Calculation of Stochastic Heating and Emissivity of Cosmic Dust Grains with Optimization for the Intel Many Integrated Core Architecture (Troy A. Porter - 19 November, 2013)
The HEATCODE library performance on a single Intel Xeon Phi coprocessor (Intel MIC architecture) is approximately 2 times a general-purpose two-socket multicore processor system with approximately the same nominal power consumption
Link: https://arxiv.org/abs/1311.4627
====================================================
Use of checkpoint-restart for complex HEP software on traditional architectures and Intel MIC (Kapil Arya - 22 January, 2014)
We analyze both single- and multi-threaded applications and test on both standard Intel x86 architectures and on Intel MIC
Link: https://arxiv.org/abs/1311.0272
====================================================
The Plasma Simulation Code: A modern particle-in-cell code with load-balancing and GPU support (Kai Germaschewski - 12 November, 2015)
Recent increases in supercomputing power, driven by the multi-core revolution and accelerators such as the IBM Cell processor, graphics processing units (GPUs) and Intel's Many Integrated Core (MIC) technology have enabled kinetic simulations of plasmas at unprecedented resolutions, but changing HPC architectures also come with challenges for writing efficient numerical codes. We focus on two distinguishing feature of the code: patch-based load balancing using space-filling curves, and support for Nvidia GPUs, which achieves substantial speed-up of up to more than 6x on the Cray XK7 architecture compared to a CPU-only implementation.
Link: https://arxiv.org/abs/1310.7866
====================================================
First Evaluation of the CPU, GPGPU and MIC Architectures for Real Time Particle Tracking based on Hough Transform at the LHC (V. Halyo - 3 February, 2014)
In this article, a new tracking algorithm based on the Hough transform will be evaluated for the first time on a multi-core Intel Xeon E5-2697v2 CPU, an NVIDIA Tesla K20c GPU, and an Intel \xphi\ 7120 coprocessor
Link: https://arxiv.org/abs/1310.7556
====================================================
The Quest-V Separation Kernel for Mixed Criticality Systems (Ye Li - 23 October, 2013)
Many of these processors now feature hardware virtualization capabilities, such as the ARM Cortex A15, and x86 processors with Intel VT-x or AMD-V support
Link: https://arxiv.org/abs/1310.6298
====================================================
An Empirical Study of Intel Xeon Phi (Jianbin Fang - 20 December, 2013)
With at least 50 cores, Intel Xeon Phi is a true many-core architecture. Featuring fairly powerful cores, two cache levels, and very fast interconnections, the Xeon Phi can get a theoretical peak of 1000 GFLOPs and over 240 GB/s
Link: https://arxiv.org/abs/1310.5842
====================================================
SIMD Parallel MCMC Sampling with Applications for Big-Data Bayesian Analytics (Alireza S. Mahani - 19 November, 2014)
For big-data Bayesian GLM graphs, the end-result is a routine for evaluating the conditional posterior and its gradient vector that is 5 times faster than a naive implementation using (built-in) multi-threaded Intel MKL BLAS, and reaches within the striking distance of the memory-bandwidth-induced hardware limit. The proposed optimization strategies improve the scaling of performance with number of cores and width of vector units (applicable to many-core SIMD processors such as Intel Xeon Phi and GPUs), resulting in cost-effectiveness, energy efficiency, and higher speed on multi-core x86 processors.
Link: https://arxiv.org/abs/1310.1537
====================================================
A graphics processor-based intranuclear cascade and evaporation simulation (H. Wan Chan Tseung - 18 February, 2014)
A speed-up factor of $\sim$20 relative to one Intel i7-3820 core processor thread was achieved.
Link: https://arxiv.org/abs/1309.7963
====================================================
First experiences with the Intel MIC architecture at LRZ (Volker Weinberg - 14 August, 2013)
In the beginning of 2013, the first production-level cards named Intel Xeon Phi came on the market. LRZ has been considered by Intel as a leading research centre for evaluating coprocessors based on the MIC architecture since 2010 under strict NDA
Link: https://arxiv.org/abs/1308.3123
====================================================
A GPGPU based program to solve the TDSE in intense laser fields through the finite difference approach (Cathal Ã Broin - 8 August, 2013)
This is followed by some examples and a short benchmark between an 8 hardware thread (i.e logical core) Intel Xeon CPU and an AMD 6970 GPU, where the parallel algorithm runs 10 times faster on the GPU than the CPU.
Link: https://arxiv.org/abs/1308.1856
====================================================
Chip-level and multi-node analysis of energy-optimized lattice-Boltzmann CFD simulations (Markus Wittmann - 22 May, 2015)
We choose the lattice-Boltzmann method (LBM) on an Intel Sandy Bridge cluster as a prototype scenario to investigate if and how single-chip performance and power characteristics can be generalized to the highly parallel case. In our setup we could achieve energy savings of 35% in this case, compared to a naive approach
Link: https://arxiv.org/abs/1304.7664
====================================================
Ultra-fast Multiple Genome Sequence Matching Using GPU (Gang Liao - 3 May, 2015)
In this paper, a contrastive evaluation of massively parallel implementations of suffix tree and suffix array to accelerate genome sequence matching are proposed based on Intel Core i7 3770K quad-core and NVIDIA GeForce GTX680 GPU. Besides suffix array only held approximately 20%~30% of the space relative to suffix tree, the coalesced binary search and tile optimization make suffix array clearly outperform suffix tree using GPU. Consequently, the experimental results show that multiple genome sequence matching based on suffix array is more than 99 times speedup than that of CPU serial implementation
Link: https://arxiv.org/abs/1303.3692
====================================================
Efficient long division via Montgomery multiply (Ernst W. Mayer - 20 August, 2016)
For the paradigmatic performance test of multiword dividend and single 64-bit-word divisor, exploitation of the inherent data-parallelism of the algorithm effectively mitigates the long latency of hardware integer MUL operations, as a result of which we are able to achieve respective costs for remainder-only and full-DIV (remainder and quotient) of 6 and 12.5 cycles per dividend word on the Intel Core 2 implementation of the x86_64 architecture, in single-threaded execution mode. We also show how the Montgomery-multiply-based powering can be efficiently used in Mersenne and Fermat-number trial factorization via direct computation of a modular inverse power of 2, without any need for explicit radix-mod scalings.
Link: https://arxiv.org/abs/1303.0328
====================================================
Performance Evaluation of Sparse Matrix Multiplication Kernels on Intel Xeon Phi (Erik Saule - 5 February, 2013)
Intel Xeon Phi is a recently released high-performance coprocessor which features 61 cores each supporting 4 hardware threads with 512-bit wide SIMD registers achieving a peak theoretical performance of 1Tflop/s in double precision
Link: https://arxiv.org/abs/1302.1078
====================================================
A GPU-accelerated Direct-sum Boundary Integral Poisson-Boltzmann Solver (Weihua Geng - 24 January, 2013)
The GPU implementation using one GPU card (Nvidia Tesla M2070) achieves 120-150X speed-up to the implementation using one CPU (Intel L5640 2.27GHz). With our approach, solving PB equations on well-discretized molecular surfaces with up to 300,000 boundary elements will take less than about 10 minutes, hence our approach is particularly suitable for fast electrostatics computations on small to medium biomolecules.
Link: https://arxiv.org/abs/1301.5885
====================================================
Partial Orders for Efficient BMC of Concurrent Software (Jade Alglave - 8 January, 2013)
It scales to programs of sufficient size to achieve first-time formal verification of non-trivial concurrent systems code over a wide range of models, including SC, Intel x86 and IBM Power.
Link: https://arxiv.org/abs/1301.1629
====================================================
Comparison of OpenMP & OpenCL Parallel Processing Technologies (Krishnahari Thouti - 8 November, 2012)
In our simulation, we used Fedora operating system; a system with Intel Xeon Dual core processor having thread count 24 coupled with NVIDIA Quadro FX 3800 as graphical processing unit.
Link: https://arxiv.org/abs/1211.2038
====================================================
Massively parallel Monte Carlo for many-particle simulations on GPUs (Joshua A. Anderson - 23 August, 2013)
On a Tesla K20, our GPU implementation executes over one billion trial moves per second, which is 148 times faster than on a single Intel Xeon E5540 CPU core, enables 27 times better performance per dollar, and cuts energy usage by a factor of 13
Link: https://arxiv.org/abs/1211.1646
====================================================
A Speculative Parallel DFA Membership Test for Multicore, SIMD and Cloud Computing Environments (Yousun Ko - 22 July, 2013)
Evaluation was conducted on a 4 CPU (40 cores) shared-memory node of the Intel Manycore Testing Lab (Intel MTL), on the Intel AVX2 SDE simulator for 8-way fully vectorized SIMD execution, and on a 20-node (288 cores) cluster on the Amazon EC2 computing cloud.
Link: https://arxiv.org/abs/1210.5093
====================================================
SMAT: An Input Adaptive Sparse Matrix-Vector Multiplication Auto-Tuner (Jiajia Li - 9 October, 2012)
The experiments show that SMAT achieves the maximum performance of 75 GFLOP/s in single-precision and 33 GFLOP/s in double-precision on Intel, and 41 GFLOP/s in single-precision and 34 GFLOP/s in double-precision on AMD. Compared with the sparse functions in MKL library, SMAT runs faster by more than 3 times.
Link: https://arxiv.org/abs/1210.2536
====================================================
Clown: a Microprocessor Simulator for Operating System Studies (Dmitry Zinoviev - 21 July, 2012)
The simulator architecturally resembles mainstream microprocessors from the Intel 80386 family, but is much easier to learn and program
Link: https://arxiv.org/abs/1207.5176
====================================================
Complete PISO and SIMPLE solvers on Graphics Processing Units (Tadeusz Tomczak - 6 July, 2012)
The results show that a GPU (Tesla C2070) can outperform a server-class 6-core, 12-thread CPU (Intel Xeon X5670) by a factor of 4.2.
Link: https://arxiv.org/abs/1207.1571
====================================================
The Necessity for Hardware QoS Support for Server Consolidation and Cloud Computing (Javier Merino - 27 June, 2012)
We will show in three actual computing systems, based on Sun UltraSparc T1, Sun UltraSparc T2 and Intel Xeon processors, how state-of-the-art virtualization techniques are unable to guarantee performance isolation in a representative workload such as SPECweb2005. In an especially conceived near worst-case scenario, it is possible to reduce the performance achieved by a Solaris Zones consolidated server for this suite of benchmarks in a Sun Fire T1000 and a Sun Enterprise T5120 by up to 80%. The performance drop observed by a Xen consolidated server running in a HP Proliant DL160 G5 is almost 45%
Link: https://arxiv.org/abs/1206.6213
====================================================
Pipelining the Fast Multipole Method over a Runtime System (Emmanuel Agullo - 1 June, 2012)
We compute potentials and forces of 200 million particles in 48.7 seconds on a homogeneous 160 cores SGI Altix UV 100 and of 38 million particles in 13.34 seconds on a heterogeneous 12 cores Intel Nehalem processor enhanced with 3 Nvidia M2090 Fermi GPUs.
Link: https://arxiv.org/abs/1206.0115
====================================================
Graph Coloring Algorithms for Muti-core and Massively Multithreaded Architectures (Umit Catalyurek - 16 May, 2012)
We study the performance of the algorithms on the Cray XMT and two multi-core systems, Sun Niagara 2 and Intel Nehalem
Link: https://arxiv.org/abs/1205.3809
====================================================
Phantom-GRAPE: numerical software library to accelerate collisionless $N$-body simulation with SIMD instruction set on x86 architecture (Ataru Tanikawa - 9 October, 2012)
Using an Intel Core i7--2600 processor, we measure the performance of our library for both the forces. In the case of Newton's forces, we achieve 2 x 10^9 interactions per second with 1 processor core, which is 20 times higher than the performance of an implementation without any explicit use of SIMD instructions, and 2 times than that with the SSE instructions. With 4 processor cores, we obtain the performance of 8 x 10^9 interactions per second. In the case of the arbitrarily shaped forces, we can calculate 1 x 10^9 and 4 x 10^9 interactions per second with 1 and 4 processor cores, respectively. The performance with 1 processor core is 6 times and 2 times higher than those of the implementations without any use of SIMD instructions and with the SSE instructions
Link: https://arxiv.org/abs/1203.4037
====================================================
An Optimized Sparse Approximate Matrix Multiply for Matrices with Decay (Nicolas Bock - 4 September, 2012)
Relative to naive implementations of \SpAMM{} using Intel's Math Kernel Library ({\tt MKL}) or AMD's Core Math Library ({\tt ACML}), our optimized version is found to be significantly faster. Finally, we discuss the potential of improved hardware prefetch to yield 2--3x speedups.
Link: https://arxiv.org/abs/1203.1692
====================================================
Performance engineering for the Lattice Boltzmann method on GPGPUs: Architectural requirements and performance results (Johannes Habich - 5 December, 2011)
Intel Xeon Westmere X5650. Our 3D LBM GPU implementation reaches up to 650 MLUPS in single precision and 290 MLUPS in double precision on an NVIDIA Tesla C2070.
Link: https://arxiv.org/abs/1112.0850
====================================================
An efficient mixed-precision, hybrid CPU-GPU implementation of a fully implicit particle-in-cell algorithm (Guangye Chen - 22 November, 2011)
This corresponds to 25% absolute GPU efficiency against the peak theoretical performance, and is about 300 times faster than an equivalent serial CPU (Intel Xeon X5460) execution. For the test case chosen, the mixed-precision hybrid CPU-GPU solver is shown to over-perform the DP CPU-only serial version by a factor of \sim 100, without apparent loss of robustness or accuracy in a challenging long-timescale ion acoustic wave simulation.
Link: https://arxiv.org/abs/1111.5295
====================================================
Hybrid static/dynamic scheduling for already optimized dense matrix factorization (Simplice Donfack - 12 October, 2011)
On a 16-core Intel Xeon machine, our hybrid static/dynamic scheduling approach is up to 8% faster than the version of CALU that uses a fully static scheduling or fully dynamic scheduling. On the 48 core AMD NUMA machine, our best implementation is up to 110% faster than MKL, while on the 16 core Intel Xeon machine, it is up to 82% faster than MKL
Link: https://arxiv.org/abs/1110.2677
====================================================
Performance analysis and optimization of the JOREK code for many-core CPUs (T. B. FehÃ©r - 10 October, 2018)
This report investigates the performance of the JOREK code on the Intel Knights Landing and Skylake processor architectures
Link: https://arxiv.org/abs/1810.04413
====================================================
Towards Lattice Quantum Chromodynamics on FPGA devices (Grzegorz Korcyl - 8 October, 2018)
We find out that the FPGA implementation offers a comparable performance with that obtained using current CPU or Intel's many core Xeon Phi accelerators
Link: https://arxiv.org/abs/1810.04201
====================================================
PCI-MDR: Missing Data Recovery in Wireless Sensor Networks using Partial Canonical Identity Matrix (Neha Jain - 8 October, 2018)
To validate the proposed method, the results have been obtained on the real data set of temperature sensors from the Intel Lab
Link: https://arxiv.org/abs/1810.03401
====================================================
Privado: Practical and Secure DNN Inference (Shruti Tople - 1 October, 2018)
Recently, cloud providers have extended support for trusted hardware primitives such as Intel SGX
Link: https://arxiv.org/abs/1810.00602
====================================================
GPU acceleration of an iterative scheme for gas-kinetic model equations with memory reduction techniques (Lianhua Zhu - 30 September, 2018)
A $190\times$ speedup can be achieved on the Tesla K40 GPUs against a single core of Intel Xeon-E5-2680v3 CPU for the 3D lid-driven cavity flow.
Link: https://arxiv.org/abs/1810.00348
====================================================
HSTREAM: A directive-based language extension for heterogeneous stream computing (Suejb Memeti - 25 September, 2018)
Big data streaming applications require utilization of heterogeneous parallel computing systems, which may comprise multiple multi-core CPUs and many-core accelerating devices such as NVIDIA GPUs and Intel Xeon Phis
Link: https://arxiv.org/abs/1809.09387
====================================================
Software for Sparse Tensor Decomposition on Emerging Computing Architectures (Eric Phipps - 24 September, 2018)
Our goal is to develop software that is portable to a variety of multicore and manycore computing architectures, such as multicore CPUs, the Intel Xeon Phi, and NVIDIA GPUs. We show that we are competitive with state-of-the-art approaches available in the literature while having the advantage of being able to run on a wider of variety of architectures with a single code.
Link: https://arxiv.org/abs/1809.09175
====================================================
ReplicaTEE: Enabling Seamless Replication of SGX Enclaves in the Cloud (Claudio Soriente - 13 September, 2018)
With the proliferation of Trusted Execution Environments (TEEs) such as Intel SGX, a number of cloud providers will soon introduce TEE capabilities within their offering (e.g., Microsoft Azure)
Link: https://arxiv.org/abs/1809.05027
====================================================
Comparing Computing Platforms for Deep Learning on a Humanoid Robot (Alexander Biddulph - 10 September, 2018)
One of the platforms is the CPU-centered Intel NUC7i7BNH and the other is a NVIDIA Jetson TX2 system that puts more emphasis on GPU processing
Link: https://arxiv.org/abs/1809.03668
====================================================
Pushing the Limits of Encrypted Databases with Secure Hardware (Panagiotis Antonopoulos - 7 September, 2018)
Recently, trusted computing platforms (e.g., Intel SGX) have emerged as an alternative to implement encrypted databases
Link: https://arxiv.org/abs/1809.02631
====================================================
Automated Instruction Stream Throughput Prediction for Intel and AMD Microarchitectures (Jan Laukemann - 10 October, 2018)
We show the process of building a machine model from available documentation and semi-automatic benchmarking, and carry it out for the latest Intel Skylake and AMD Zen micro-architectures
Link: https://arxiv.org/abs/1809.00912
====================================================
The Shift from Processor Power Consumption to Performance Variations: Fundamental Implications at Scale (Joseph Schuchart - 24 August, 2018)
The Intel Haswell-EP processor generation introduces several major advancements of power control and energy-efficiency features. Through measurements on an Intel Sandy Bridge-EP cluster, we show that previous generations have sustained homogeneous performance across multiple CPUs and compensated for hardware manufacturing variability through varying power consumption
Link: https://arxiv.org/abs/1808.08106
====================================================
Student Cluster Competition 2017, Team University ofTexas at Austin/Texas State University: Reproducing Vectorization of the Tersoff Multi-Body Potential on the Intel Skylake and NVIDIA V100 Architectures (James Sullivan - 21 August, 2018)
We investigated accuracy, optimization performance, and scaling with our Intel CPU and NVIDIA GPU based cluster.
Link: https://arxiv.org/abs/1808.07027
====================================================
Mitigating Branch-Shadowing Attacks on Intel SGX using Control Flow Randomization (Shohreh Hosseinzadeh - 20 August, 2018)
Intel Software Guard Extensions (SGX) is a promising hardware-based technology for protecting sensitive computations from potentially compromised system software
Link: https://arxiv.org/abs/1808.06478
====================================================
GEEC: Scalable, Efficient, and Consistent Consensus for Blockchains (Xusheng Chen - 7 August, 2018)
We present GEEC, a new blockchain protocol and its runtime system by leveraging the strong confidentiality and integrity of the Intel Software Guard eXtentions (SGX) hardware. GEEC achieves strong privacy and security for permissioned blockchains with Intel SGX and provides an open membership scheme to make the blockchain scale as easily as a public blockchain
Link: https://arxiv.org/abs/1808.02252
====================================================
Sound Transpilation from Binary to Machine-Independent Code (Roberto Metere - 27 July, 2018)
Intel)
Link: https://arxiv.org/abs/1807.10664
====================================================
Spectre Returns! Speculation Attacks using the Return Stack Buffer (Esmaeil Mohammadian Koruyeh - 20 July, 2018)
Importantly, none of the known defenses including Retpoline and Intel's microcode patches stop all SpectreRSB attacks. In particular, on Core-i7 Skylake and newer processors (but not on Intel's Xeon processor line), a patch called RSB refilling is used to address a vulnerability when the RSB underfills; this defense interferes with SpectreRSB's ability to launch attacks that switch into the kernel
Link: https://arxiv.org/abs/1807.07940
====================================================
SPOC: Secure Payments for Outsourced Computations (MichaÅ KrÃ³l - 17 July, 2018)
We implement our system using Ethereum Smart Contracts and Intel SGX and present first evaluation proving its security and low usage cost.
Link: https://arxiv.org/abs/1807.06462
====================================================
A NUMA-Aware Provably-Efficient Task-Parallel Platform Based on the Work-First Principle (Justin Deters - 5 September, 2018)
Furthermore, we implemented a prototype platform by modifying Intel's Cilk Plus runtime system and empirically demonstrate that the resulting system is work efficient and scalable.
Link: https://arxiv.org/abs/1806.11128
====================================================
Context-aware Failure-oblivious Computing as a Means of Preventing Buffer Overflows (Manuel Rigger - 26 June, 2018)
We demonstrate that introspection can be implemented in popular bug-finding and bug-mitigation tools such as LLVM's AddressSanitizer, SoftBound, and Intel-MPX-based bounds checking
Link: https://arxiv.org/abs/1806.09026
====================================================
Trading algorithms with learning in latent alpha models (Philippe Casgrain - 12 June, 2018)
We also provide calibration results for a particular model using Intel Corporation stock as an example.
Link: https://arxiv.org/abs/1806.04472
====================================================
Achieving Data Dissemination with Security using FIWARE and Intel Software Guard Extensions (SGX) (Dalton CÃ©zane Gomes Valadares - 5 June, 2018)
We present a solution that considers the security components of FIWARE and the Intel SGX capabilities. FIWARE is a platform created to support the development of Smart Applications, including IoT systems, and SGX is the Intel solution for Trusted Execution Environment (TEE)
Link: https://arxiv.org/abs/1806.01906
====================================================
Highly Efficient 8-bit Low Precision Inference of Convolutional Neural Networks with IntelCaffe (Jiong Gong - 4 May, 2018)
We show that the inference throughput and latency with ResNet-50, Inception-v3 and SSD are improved by 1.38X-2.9X and 1.35X-3X respectively with neglectable accuracy loss from IntelCaffe FP32 baseline and by 56X-75X and 26X-37X from BVLC Caffe. All these techniques have been open-sourced on IntelCaffe GitHub1, and the artifact is provided to reproduce the result on Amazon AWS Cloud.
Link: https://arxiv.org/abs/1805.08691
====================================================
Blockchain and Trusted Computing: Problems, Pitfalls, and a Solution for Hyperledger Fabric (Marcus Brandenburger - 22 May, 2018)
To remedy this problem, it has been suggested to combine blockchains with trusted execution environments (TEEs), such as Intel SGX, for executing applications that demand privacy
Link: https://arxiv.org/abs/1805.08541
====================================================
SGX-Aware Container Orchestration for Heterogeneous Clusters (SÃ©bastien Vaucher - 27 July, 2018)
The recent introduction by Intel of Software Guard Extensions (SGX) into the mass market offers an alternative to developers, who can now execute their code in a hardware-secured environment without trusting the cloud provider.
Link: https://arxiv.org/abs/1805.05847
====================================================
Nethammer: Inducing Rowhammer Faults through Network Requests (Moritz Lipp - 13 May, 2018)
Other systems can still be attacked if they are protected with quality-of-service techniques like Intel CAT
Link: https://arxiv.org/abs/1805.04956
====================================================
Program Generation for Small-Scale Linear Algebra Applications (Daniele G. Spampinato - 12 May, 2018)
The results show significant speed-ups compared to straightforward C with Intel icc and clang with a polyhedral optimizer, as well as library-based and template-based implementations.
Link: https://arxiv.org/abs/1805.04775
====================================================
Dwarfs on Accelerators: Enhancing OpenCL Benchmarking for Heterogeneous Computing Architectures (Beau Johnston - 10 May, 2018)
Preliminary results and analysis are reported for eight benchmark codes on a diverse set of architectures -- three Intel CPUs, five Nvidia GPUs, six AMD GPUs and a Xeon Phi.
Link: https://arxiv.org/abs/1805.03841
====================================================
SecureCloud: Secure Big Data Processing in Untrusted Clouds (Florian Kelbert - 4 May, 2018)
To provide security guarantees, SecureCloud leverages novel security mechanisms present in recent commodity CPUs, in particular, Intel's Software Guard Extensions (SGX)
Link: https://arxiv.org/abs/1805.01783
====================================================
SecureStreams: A Reactive Middleware Framework for Secure Data Stream Processing (AurÃ©lien Havet - 4 May, 2018)
Its design combines the high-level reactive dataflow programming paradigm with Intel's low-level software guard extensions (SGX) in order to guarantee privacy and integrity of the processed data
Link: https://arxiv.org/abs/1805.01752
====================================================
X-Search: Revisiting Private Web Search using Intel SGX (Sonia Ben Mokhtar - 4 May, 2018)
This paper introduces X-Search , a novel private Web search mechanism building on the disruptive Software Guard Extensions (SGX) proposed by Intel. Our evaluation shows that: (1) X-Search offers stronger privacy guarantees than its competitors as it operates under a stronger adversarial model; (2) it better resists state-of-the-art re-identification attacks; and (3) from the performance perspective, X-Search outperforms its competitors both in terms of latency and throughput by orders of magnitude.
Link: https://arxiv.org/abs/1805.01742
====================================================
CYCLOSA: Decentralizing Private Web Search Through SGX-Based Browser Extensions (Rafael Pires - 27 July, 2018)
CYCLOSA improves security by relying on trusted execution environments (TEEs) as provided by Intel SGX
Link: https://arxiv.org/abs/1805.01548
====================================================
Identity Aging: Efficient Blockchain Consensus (Mansoor Ahmed - 19 April, 2018)
Our first system, SCIFER, leverages Intel's SGX attestation for identity bootstrapping in a partially-decentralized setting, where blockchain is permissionless, but we trust Intel for attestation
Link: https://arxiv.org/abs/1804.07391
====================================================
The Brain on Low Power Architectures - Efficient Simulation of Cortical Slow Waves and Asynchronous States (Roberto Ammendola - 10 April, 2018)
Furthermore, a comparison is given of instantaneous power, total energy consumption, execution time and energetic cost per synaptic event of SWA/AW DPSNN simulations when executed on either ARM- or Intel-based server platforms.
Link: https://arxiv.org/abs/1804.03441
====================================================
Increasing Parallelism in the ROOT I/O Subsystem (Guilherme Amadio - 9 April, 2018)
Performance measurements are discussed through real life examples coming from CMS production workflows on traditional server platforms and highly parallel architectures such as Intel Xeon Phi.
Link: https://arxiv.org/abs/1804.03326
====================================================
High-performance sparse matrix-matrix products on Intel KNL and multicore architectures (Yusuke Nagasaka - 26 June, 2018)
We firstly identify and mitigate multiple bottlenecks with memory management and thread scheduling on Intel Xeon Phi (Knights Landing or KNL)
Link: https://arxiv.org/abs/1804.01698
====================================================
Sparse Matrix-Matrix Multiplication on Multilevel Memory Architectures : Algorithms and Experiments (Mehmet Deveci - 2 April, 2018)
This paper investigates the performance of sparse matrix multiplication kernels on two leading high-performance computing architectures -- Intel's Knights Landing processor and NVIDIA's Pascal GPU
Link: https://arxiv.org/abs/1804.00695
====================================================
Migrating SGX Enclaves with Persistent State (Fritz Alder - 29 March, 2018)
Hardware-supported security mechanisms like Intel Software Guard Extensions (SGX) provide strong security guarantees, which are particularly relevant in cloud settings
Link: https://arxiv.org/abs/1803.11021
====================================================
Chebyshev Filter Diagonalization on Modern Manycore Processors and GPGPUs (Moritz Kreutzer - 6 March, 2018)
We focus on the transparent access to the full address space supported by both architectures under consideration: Intel Xeon Phi "Knights Landing" and Nvidia "Pascal."
Link: https://arxiv.org/abs/1803.02156
====================================================
Secure and Privacy-Aware Data Dissemination for Cloud-Based Applications (Lilia Sampaio - 2 March, 2018)
The proposed system aims at enabling an application ecosystem that uses off-the-shelf trusted platforms (in this case, Intel SGX), so that users may allow or disallow third parties to access the live data stream with a specific sensitivity-level
Link: https://arxiv.org/abs/1803.00989
====================================================
Technical Report about Tiramisu: a Three-Layered Abstraction for Hiding Hardware Complexity from DSL Compilers (Riyadh Baghdadi - 28 May, 2018)
Finally, we demonstrate that Tiramisu can generate very efficient code that matches the highly optimized Intel MKL gemm (generalized matrix multiplication) implementation, we also show speedups reaching 4X in Halide and 16X in Julia due to optimizations enabled by Tiramisu.
Link: https://arxiv.org/abs/1803.00419
====================================================
SgxPectre Attacks: Stealing Intel Secrets from SGX Enclaves via Speculative Execution (Guoxing Chen - 2 June, 2018)
Most importantly, we have applied SgxPectre Attacks to steal seal keys and attestation keys from Intel signed quoting enclaves. This paper also systematically evaluates Intel's existing countermeasures against SgxPectre Attacks and discusses the security implications.
Link: https://arxiv.org/abs/1802.09085
====================================================
Aurora: Providing Trusted System Services for Enclaves On an Untrusted System (Hongliang Liang - 10 February, 2018)
Intel SGX provisions shielded executions for security-sensitive computation, but lacks support for trusted system services (TSS), such as clock, network and filesystem
Link: https://arxiv.org/abs/1802.03530
====================================================
A Systematic Analysis for State-of-the-Art 3D Lung Nodule Proposals Generation (Hui Wu - 8 January, 2018)
We implement the 3D CNN model on CPU platform and propose an Intel Extended-Caffe framework which supports many highly-efficient 3D computations, which is opened source at https://github.com/extendedcaffe/extended-caffe.
Link: https://arxiv.org/abs/1802.02179
====================================================
D2.3 Power models, energy models and libraries for energy-efficient concurrent data structures and algorithms (Phuong Hoai Ha - 8 February, 2018)
The work has been conducted on two main EXCESS platforms: Intel platforms with recent Intel multicore CPUs and Movidius Myriad platforms.
Link: https://arxiv.org/abs/1801.10556
====================================================
Task-based Parallel Computation of the Density Matrix in Quantum-based Molecular Dynamics using Graph Partitioning (Purnima Ghale - 25 January, 2018)
We develop task-based implementations of the data-parallel G-SP2 algorithm using both Intel's Concurrent Collections (CnC) as well as the Charm++ programming model and evaluate these implementations for future use
Link: https://arxiv.org/abs/1801.10016
====================================================
D2.1 Models for energy consumption of data structures and algorithms (Phuong Hoai Ha - 8 February, 2018)
The work has been conducted on the two main EXCESS platforms: (1) Intel platform with recent Intel multi-core CPUs and (2) Movidius embedded platform.
Link: https://arxiv.org/abs/1801.09992
====================================================
D2.2 White-box methodologies, programming abstractions and libraries (Phuong Hoai Ha - 8 February, 2018)
For Intel platforms, we have generalized the model for concurrent queues on CPU platforms to offer more flexibility according to the workers calling the data structure (parallel section sizes of enqueuers and dequeuers are decoupled). Regarding programming abstractions and libraries, we have continued investigat- ing the trade-offs between energy consumption and performance of data structures such as concurrent queues and concurrent search trees based on the early results of Task 2.1.The preliminary results show that our concurrent trees are faster and more energy efficient than the state-of-the-art on commodity HPC and embedded platforms.
Link: https://arxiv.org/abs/1801.08761
====================================================
Intel nGraph: An Intermediate Representation, Compiler, and Executor for Deep Learning (Scott Cyphers - 29 January, 2018)
Initially-supported frameworks include TensorFlow, MXNet, and Intel neon framework. Initial backends are Intel Architecture CPUs (CPU), the Intel(R) Nervana Neural Network Processor(R) (NNP), and NVIDIA GPUs
Link: https://arxiv.org/abs/1801.08058
====================================================
On Scale-out Deep Learning Training for Cloud and HPC (Srinivas Sridharan - 24 January, 2018)
In this paper, we describe the philosophy, design, and implementation of Intel Machine Learning Scalability Library (MLSL) and present proof-points demonstrating scaling DL training on 100s to 1000s of nodes across Cloud and HPC systems.
Link: https://arxiv.org/abs/1801.08030
====================================================
Integrating Remote Attestation with Transport Layer Security (Thomas Knauth - 17 January, 2018)
Intel(R) Software Guard Extensions (Intel(R) SGX) is a promising technology to securely process information in otherwise untrusted environments. An important aspect of Intel SGX is the ability to perform remote attestation to assess the endpoint's trustworthiness
Link: https://arxiv.org/abs/1801.05863
====================================================
Computing the sparse matrix vector product using block-based kernels without zero padding on processors with AVX-512 instructions (Berenger Bramas - 11 May, 2018)
We compare the performance of our approach to that of the Intel MKL CSR kernel and the CSR5 open-source package on a set of standard benchmark matrices
Link: https://arxiv.org/abs/1801.01134
====================================================
FogGrid: Leveraging Fog Computing for Enhanced Smart Grid Network (Rabindra K. Barik - 27 December, 2017)
To alleviate the advantages of Fog computing, a Fog computing framework based on Intel Edison is proposed
Link: https://arxiv.org/abs/1712.09645
====================================================
Smart Fog: Fog Computing Framework for Unsupervised Clustering Analytics in Wearable Internet of Things (Debanjan Borthakur - 24 December, 2017)
We employed Intel Edison and Raspberry Pi as Fog computer in proposed architecture
Link: https://arxiv.org/abs/1712.09347
====================================================
The Heisenberg Defense: Proactively Defending SGX Enclaves against Page-Table-Based Side-Channel Attacks (Raoul Strackx - 22 December, 2017)
Unfortunately, Intel SGX -- the only publicly available high-end PMA -- has been shown to only provide limited isolation
Link: https://arxiv.org/abs/1712.08519
====================================================
The Pyramid Scheme: Oblivious RAM for Trusted Processors (Manuel Costa - 21 December, 2017)
Modern processors, e.g., Intel SGX, allow applications to isolate secret code and data in encrypted memory regions called enclaves
Link: https://arxiv.org/abs/1712.07882
====================================================
Intel SGX Enabled Key Manager Service with OpenStack Barbican (Somnath Chakrabarti - 20 December, 2017)
We extend OpenStack Barbican API to support attestation of an Intel SGX crypto plugin, to allow clients higher confidence in the software they are using for storing keys. In addition, the API provides support for mutual attestation for Intel SGX enabled clients, multi-user key distribution, and extensions for protecting the confidentiality and integrity of the backend database.
Link: https://arxiv.org/abs/1712.07694
====================================================
Persistent Memory Programming Abstractions in Context of Concurrent Applications (Ajay Singh - 13 December, 2017)
To this end, several programming abstractions have been proposed like NVthreads, Mnemosyne and intel's NVML
Link: https://arxiv.org/abs/1712.04989
====================================================
Practical Implementation of Lattice QCD Simulation on Intel Xeon Phi Knights Landing (Issaku Kanamori - 5 December, 2017)
We investigate implementation of lattice Quantum Chromodynamics (QCD) code on the Intel Xeon Phi Knights Landing (KNL)
Link: https://arxiv.org/abs/1712.01505
====================================================
MILC Code Performance on High End CPU and GPU Supercomputer Clusters (Ruizi Li - 30 November, 2017)
It has been necessary to adapt the MILC code to these new processors starting with NVIDIA GPUs, and more recently, the Intel Xeon Phi processors. We report on our efforts to port and optimize our code for the Intel Knights Landing architecture
Link: https://arxiv.org/abs/1712.00143
====================================================
2D Image Convolution using Three Parallel Programming Models on the Xeon Phi (Ashkan Tousimojarad - 27 November, 2017)
We then compare the parallel performance of the optimised code using OpenMP, OpenCL and GPRM implementations on the Intel Xeon Phi
Link: https://arxiv.org/abs/1711.09791
====================================================
MemJam: A False Dependency Attack against Constant-Time Crypto Implementations (Ahmad Moghimi - 21 November, 2017)
As a proof of concept, we demonstrate the first key recovery attacks on a constant-time implementation of AES, and a SM4 implementation with cache protection in the current Intel Integrated Performance Primitives (Intel IPP) cryptographic library. Compared to CacheBleed, which is limited to older processor generations, MemJam is the first intra cache level attack applicable to all major Intel processors including the latest generations that support the SGX extension.
Link: https://arxiv.org/abs/1711.08002
====================================================
Parallelized Kalman-Filter-Based Reconstruction of Particle Tracks on Many-Core Architectures (Giuseppe Cerati - 27 March, 2018)
Previously we reported the significant parallel speedups that resulted from our efforts to adapt Kalman-filter-based tracking to many-core architectures such as Intel Xeon Phi
Link: https://arxiv.org/abs/1711.06571
====================================================
Performance Analysis and Optimization of Sparse Matrix-Vector Multiplication on Modern Multi- and Many-Core Processors (Athena Elafrou - 15 November, 2017)
We evaluate our optimizer on three x86-based computing platforms and demonstrate that it is able to distinguish and appropriately optimize SpMV for the majority of matrices in a representative test suite, leading to significant speedups over the CSR and Inspector-Executor CSR SpMV kernels available in the latest release of the Intel MKL library.
Link: https://arxiv.org/abs/1711.05487
====================================================
Accelerating HPC codes on Intel(R) Omni-Path Architecture networks: From particle physics to Machine Learning (Peter Boyle - 13 November, 2017)
We discuss practical methods to ensure near wirespeed performance from clusters with either one or two Intel(R) Omni-Path host fabric interfaces (HFI) per node, and Intel(R) Xeon Phi(TM) 72xx (Knight's Landing) processors, and using the Linux operating system.
Link: https://arxiv.org/abs/1711.04883
====================================================
Strongly Secure and Efficient Data Shuffle On Hardware Enclaves (Ju Chen - 12 November, 2017)
Mitigating memory-access attacks on the Intel SGX architecture is an important and open research problem. The proposed approach is to software-engineer the oblivious algorithm of Melbourne shuffle on the Intel SGX/TSX architecture, where the Transaction Synchronization eXtension (TSX) is (ab)used to detect the occurrence of cache misses
Link: https://arxiv.org/abs/1711.04243
====================================================
Hamming distance completeness and sparse matrix multiplication (Daniel Graf - 3 May, 2018)
Furthermore, our reductions apply to the pattern matching setting, showing equivalence (up to polylog factors) between pattern matching under Hamming Distance, $\ell_{2p+1}$ Distance, Dominance Product and Threshold Product, with current best upperbounds due to results of Abrahamson (SICOMP'87), Amir and Farach (Ann.~Math.~Artif.~Intell.'91), Atallah and Duket (IPL'11), Clifford, Clifford and Iliopoulous (CPM'05) and Amir, Lipsky, Porat and Umanski (CPM'05)
Link: https://arxiv.org/abs/1711.03887
====================================================
Baryonic and mesonic 3-point functions with open spin indices (Gunnar S. Bali - 7 November, 2017)
We explain this factorization as well as its efficient implementation in a new library which has been written to provide the necessary functionality on modern parallel architectures and on CPUs, including Intel's Xeon Phi series.
Link: https://arxiv.org/abs/1711.02384
====================================================
Multi-Glimpse LSTM with Color-Depth Feature Fusion for Human Detection (Hengduo Li - 3 November, 2017)
With the development of depth cameras such as Kinect and Intel Realsense, RGB-D based human detection receives continuous research attention due to its usage in a variety of applications
Link: https://arxiv.org/abs/1711.01062
====================================================
DynSGX: A Privacy Preserving Toolset for Dynamically Loading Functions into Intel(R) SGX Enclaves (Rodolfo Silva - 31 October, 2017)
Intel(R) Software Guard eXtensions (SGX) is a hardware-based technology for ensuring security of sensitive data from disclosure or modification that enables user-level applications to allocate protected areas of memory called enclaves
Link: https://arxiv.org/abs/1710.11423
====================================================
DART: Distribution Aware Retinal Transform for Event-based Cameras (Bharath Ramesh - 30 October, 2017)
Using the in-house N-SOD, we demonstrate real-time classification performance on an Intel Compute Stick directly interfaced to an event camera flying on-board a quadcopter
Link: https://arxiv.org/abs/1710.10800
====================================================
Power Modelling for Heterogeneous Cloud-Edge Data Centers (Kai Chen - 27 October, 2017)
Our research first develops a hardware counter selection method that appropriately selects counters most correlated to power on ARM and Intel processors. The key results are: (i) the automated hardware performance counter selection method achieves comparable selection to the manual selection methods reported in literature, and (ii) the two stage power model can predict dynamic power more accurately on both ARM and Intel processors when compared to classic power models.
Link: https://arxiv.org/abs/1710.10325
====================================================
Performance optimizations for scalable CFD applications on hybrid CPU+MIC heterogeneous computing system with millions of cores (Yong-Xian Wang - 27 October, 2017)
How to achieve the best performance in the modern supercomputer system, especially with heterogeneous computing resources such as hybrid CPU+GPU, or a CPU + Intel Xeon Phi (MIC) co-processors, is still a great challenge.
Link: https://arxiv.org/abs/1710.09995
====================================================
End-to-End Optimized Speech Coding with Deep Neural Networks (Srihari Kankanahalli - 24 October, 2017)
It also runs in realtime on a 3.8GhZ Intel CPU.
Link: https://arxiv.org/abs/1710.09064
====================================================
Leaking Uninitialized Secure Enclave Memory via Structure Padding (Extended Abstract) (Sangho Lee - 24 October, 2017)
Intel software guard extensions (SGX) aims to provide an isolated execution environment, known as an enclave, for a user-level process to maximize its confidentiality and integrity. We found that, during ECALL and OCALL, proxy functions that are automatically generated by the Intel SGX Software Development Kit (SDK) fully copy structure variables from an enclave to the normal memory to return the result of an ECALL function and to pass input parameters to an OCALL function
Link: https://arxiv.org/abs/1710.09061
====================================================
FPGA-based ORB Feature Extraction for Real-Time Visual SLAM (Weikang Fang - 18 October, 2017)
Hence, in this paper, we design, implement, and evaluate a hardware ORB feature extractor and prove that our design is a great balance between performance and energy consumption compared with ARM Krait and Intel Core i5.
Link: https://arxiv.org/abs/1710.07312
====================================================
Wilson and Domainwall Kernels on Oakforest-PACS (Issaku Kanamori - 18 October, 2017)
We report the performance of Wilson and Domainwall Kernels on a new Intel Xeon Phi Knights Landing based machine named Oakforest-PACS, which is co-hosted by University of Tokyo and Tsukuba University and is currently fastest in Japan. This machine uses Intel Omni-Path for the internode network
Link: https://arxiv.org/abs/1710.07226
====================================================
DD-$Î±$AMG on QPACE 3 (Peter Georg - 19 October, 2017)
We first review how the code was ported from the first generation Intel Xeon Phi processor (Knights Corner) to its successor (Knights Landing)
Link: https://arxiv.org/abs/1710.07041
====================================================
The Tersoff many-body potential: Sustainable performance through vectorization (Markus HÃ¶hnerbach - 2 October, 2017)
To reduce the burden of explicit vectorization, we abstract from the specific vector instruction set and desired precision: From one algorithm, we get optimized implementations for many platforms, from SSE4.2 to AVX512, and the Intel Xeon Phi. Our optimizations benefit any architecture, but have a disproportionate effect on the Intel Xeon Phi, which beats the CPU (2xE5-2650) after optimization.
Link: https://arxiv.org/abs/1710.00882
====================================================
Another Flip in the Wall of Rowhammer Defenses (Daniel Gruss - 31 January, 2018)
Finally, we abuse Intel SGX to hide the attack entirely from the user and the operating system, making any inspection or detection of the attack infeasible
Link: https://arxiv.org/abs/1710.00551
====================================================
DR.SGX: Hardening SGX Enclaves against Cache Attacks with Data Location Randomization (Ferdinand Brasser - 28 September, 2017)
Recent research has demonstrated that Intel's SGX is vulnerable to various software-based side-channel attacks
Link: https://arxiv.org/abs/1709.09917
====================================================
Energy efficiency of finite difference algorithms on multicore CPUs, GPUs, and Intel Xeon Phi processors (Satya P. Jammy - 27 September, 2017)
In the present work, finite difference algorithms of varying computational and memory intensity are evaluated with respect to both energy efficiency and runtime on an Intel Ivy Bridge CPU node, an Intel Xeon Phi Knights Landing processor, and an NVIDIA Tesla K40c GPU
Link: https://arxiv.org/abs/1709.09713
====================================================
Power Regulation in High Performance Multicore Processors (X. Chen - 14 September, 2017)
We present an implementation of the controller on Intel's fourth-generation microarchitecture, Haswell, and test it on a number of industry benchmark programs which are used in scientific computing and datacenter applications
Link: https://arxiv.org/abs/1709.04859
====================================================
Monte Carlo methods for massively parallel computers (Martin Weigel - 13 September, 2017)
Embracing the opportunities of parallel computing and especially the possibilities provided by a new generation of massively parallel accelerator devices such as GPUs, Intel's Xeon Phi or even FPGAs enables applications and studies that are inaccessible to serial programs
Link: https://arxiv.org/abs/1709.04394
====================================================
A Novel Scheduling Framework Leveraging Hardware Cache Partitioning for Cache-Side-Channel Elimination in Clouds (Read Sprabery - 30 August, 2017)
Combining the Intel CAT architecture that enables cache partitioning on the fly with novel scheduling techniques and state cleansing mechanisms, we enable cache-side-channel free computing for Linux-based containers and virtual machines, in particular, those managed by KVM
Link: https://arxiv.org/abs/1708.09538
====================================================
The Parallel Algorithm for the 2-D Discrete Wavelet Transform (David Barina - 26 September, 2017)
The evaluation was performed on 61-core Intel Xeon Phi and 8-core Intel Xeon processors.
Link: https://arxiv.org/abs/1708.07853
====================================================
Thinking, Fast and Slow: Combining Vector Spaces and Knowledge Graphs (Sudip Mittal - 20 August, 2017)
We also demonstrate and evaluate the VKG structure and the query processing engine by developing a system called Cyber-All-Intel for knowledge extraction, representation and querying in an end-to-end pipeline grounded in the cybersecurity informatics domain.
Link: https://arxiv.org/abs/1708.03310
====================================================
Scaling Deep Learning on GPU and Knights Landing clusters (Yang You - 9 August, 2017)
We use both self-hosted Intel Knights Landing (KNL) clusters and multi-GPU clusters as our target platforms
Link: https://arxiv.org/abs/1708.02983
====================================================
AutOMP: An Automatic OpenMP Parallelization Generator for Variable-Oriented High-Performance Scientific Codes (Gal Oren - 22 July, 2017)
The relative ease of implementing OpenMP, along with the development of multi-core shared memory processors (such as Intel Xeon Phi) makes OpenMP a favorable method for parallelization in the process of modernizing a legacy codes
Link: https://arxiv.org/abs/1707.07137
====================================================
Stacco: Differentially Analyzing Side-Channel Traces for Detecting SSL/TLS Vulnerabilities in Secure Enclaves (Yuan Xiao - 26 September, 2017)
Intel Software Guard Extension (SGX) offers software applications enclave to protect their confidentiality and integrity from malicious operating systems
Link: https://arxiv.org/abs/1707.03473
====================================================
Finding Substitutable Binary Code By Synthesizing Adapters (Vaibhav Sharma - 29 November, 2017)
We implement our technique using (1) concrete adapter enumeration based on Intel's Pin framework (2) binary symbolic execution, and explore the relation between size of adapter search space and total search time
Link: https://arxiv.org/abs/1707.01536
====================================================
Geometry-Oblivious FMM for Compressing Dense SPD Matrices (Chenhan D. Yu - 1 July, 2017)
We present results on the Intel Knights Landing and Haswell architectures, and on the NVIDIA Pascal architecture for a variety of matrices.
Link: https://arxiv.org/abs/1707.00164
====================================================
Fog Computing in Medical Internet-of-Things: Architecture, Implementation, and Applications (Harishchandra Dubey - 24 June, 2017)
The centerpiece of Fog computing is a low-power, intelligent, wireless, embedded computing node that carries out signal conditioning and data analytics on raw data collected from wearables or other medical sensors and offers efficient means to serve telehealth interventions. We implemented and tested an fog computing system using the Intel Edison and Raspberry Pi that allows acquisition, computing, storage and communication of the various medical data such as pathological speech data of individuals with speech disorders, Phonocardiogram (PCG) signal for heart rate estimation, and Electrocardiogram (ECG)-based Q, R, S detection.
Link: https://arxiv.org/abs/1706.08012
====================================================
Using GPI-2 for Distributed Memory Paralleliziation of the Caffe Toolbox to Speed up Deep Neural Network Training (Martin Kuehn - 18 August, 2017)
First benchmarks demonstrate better scaling behavior com- pared with other extensions, e.g., the Intel TM Caffe
Link: https://arxiv.org/abs/1706.00095
====================================================
Parallel Accelerated Vector Similarity Calculations for Genomics Applications (Wayne Joubert - 20 April, 2018)
In this paper we describe a new approach to performing vector similarity metrics calculations, suitable for parallel systems equipped with graphics processing units (GPUs) or Intel Xeon Phi processors
Link: https://arxiv.org/abs/1705.08210
====================================================
Elastic and Secure Energy Forecasting in Cloud Environments (AndrÃ© Martin - 18 May, 2017)
Our approach is based on StreamMine3G, an elastic event stream processing system and Intel's SGX technology that provides secure processing using enclaves. We highlight the key aspects of our approach and research challenges when using Intel's SGX technology.
Link: https://arxiv.org/abs/1705.06453
====================================================
Engineering Record And Replay For Deployability: Extended Technical Report (Robert O&#39;Callahan - 16 May, 2017)
Fortunately modern Intel CPUs, Linux kernels and user-space frameworks do meet these constraints, although this has only become true recently
Link: https://arxiv.org/abs/1705.05937
====================================================
A lightweight MapReduce framework for secure processing with SGX (Rafael Pires - 16 May, 2017)
Intel, the largest manufacturer of commodity CPUs, recently introduced SGX (software guard extensions), a set of hardware instructions that support execution of code in an isolated secure environment. In this paper, we explore the use of Intel SGX for providing privacy guarantees for MapReduce operations, and based on our evaluation we conclude that it represents a viable alternative to a cryptographic mechanism
Link: https://arxiv.org/abs/1705.05684
====================================================
Intel RealSense Stereoscopic Depth Cameras (Leonid Keselman - 29 October, 2017)
We present a comprehensive overview of the stereoscopic Intel RealSense RGBD imaging systems. Our discussion covers the Intel RealSense R200 and the Intel RealSense D400 (formally RS400).
Link: https://arxiv.org/abs/1705.05548
====================================================
Leveraging Intel SGX to Create a Nondisclosure Cryptographic library (Mohammad Hasanzadeh Mofrad - 2 April, 2018)
The Intel SGX puts sensitive code and data into CPU-hardened protected regions called enclaves. In this project we leverage the Intel SGX to produce a secure cryptographic library which keeps the generated keys inside an enclave restricting use and dissemination of confidential cryptographic keys
Link: https://arxiv.org/abs/1705.04706
====================================================
Parallelized Kalman-Filter-Based Reconstruction of Particle Tracks on Many-Core Processors and GPUs (Giuseppe Cerati - 19 June, 2017)
Instead, chipmakers have been pushed into producing lower-power, multi-core processors such as GPGPU, ARM and Intel MIC. Previously we reported on the significant parallel speedups that resulted from our investigations to adapt Kalman filters to track fitting and track building on Intel Xeon and Xeon Phi
Link: https://arxiv.org/abs/1705.02876
====================================================
A Fast Causal Profiler for Task Parallel Programs (Adarsh Yoga - 2 July, 2017)
We have used TASKPROF to isolate parallelism bottlenecks in twenty three applications that use the Intel Threading Building Blocks library
Link: https://arxiv.org/abs/1705.01522
====================================================
Ensemble Sales Forecasting Study in Semiconductor Industry (Qiuping Xu - 16 May, 2017)
In this paper CPU sales forecasting of Intel Corporation, a multinational semiconductor industry, was considered
Link: https://arxiv.org/abs/1705.00003
====================================================
Benchmarking OpenCL, OpenACC, OpenMP, and CUDA: programming productivity, performance, and energy consumption (Suejb Memeti - 18 April, 2017)
Such nodes may comprise general purpose CPUs and accelerators (such as, GPU, or Intel Xeon Phi) that provide high performance with suitable energy-consumption characteristics
Link: https://arxiv.org/abs/1704.05316
====================================================
Parallelized Kendall's Tau Coefficient Computation via SIMD Vectorized Sorting On Many-Integrated-Core Processors (Yongchao Liu - 12 April, 2017)
In this paper, we investigated a parallel algorithm accelerating all-pairs Kendall's tau coefficient computation via single instruction multiple data (SIMD) vectorized sorting on Intel Xeon Phis by taking advantage of many processing cores and 512-bit SIMD vector instructions
Link: https://arxiv.org/abs/1704.03767
====================================================
Faster Base64 Encoding and Decoding Using AVX2 Instructions (Wojciech MuÅa - 14 June, 2018)
We achieve these good results by using the single-instruction-multiple-data (SIMD) instructions available on recent Intel processors (AVX2)
Link: https://arxiv.org/abs/1704.00605
====================================================
CacheZoom: How SGX Amplifies The Power of Cache Attacks (Ahmad Moghimi - 20 August, 2017)
Intel proposed SGX to create a trusted execution environment within the processor
Link: https://arxiv.org/abs/1703.06986
====================================================
Parallel Sort-Based Matching for Data Distribution Management on Shared-Memory Multiprocessors (Moreno Marzolla - 7 August, 2018)
We describe the algorithm and compute its asymptotic running time; we complete the analysis by assessing its performance and scalability through extensive experiments on two commodity multicore systems based on a dual socket Intel Xeon processor, and a single socket Intel Core i7 processor.
Link: https://arxiv.org/abs/1703.06680
====================================================
CLTune: A Generic Auto-Tuner for OpenCL Kernels (Cedric Nugteren - 19 March, 2017)
For matrix-multiplication, we use CLTune to explore a parameter space of more than two-hundred thousand configurations, we show the need for device-specific tuning, and outperform the clBLAS library on NVIDIA, AMD and Intel GPUs.
Link: https://arxiv.org/abs/1703.06503
====================================================
Proof of Luck: an Efficient Blockchain Consensus Protocol (Mitar Milutinovic - 15 March, 2017)
In the paper, we present designs for multiple blockchain consensus primitives and a novel blockchain system, all based on the use of trusted execution environments (TEEs), such as Intel SGX-enabled CPUs
Link: https://arxiv.org/abs/1703.05435
====================================================
Optimization of Lattice Boltzmann Simulations on Heterogeneous Computers (E. Calore - 14 March, 2017)
We test the performance of our codes and their scaling properties using as testbeds HPC clusters incorporating different accelerators: Intel Xeon-Phi many-core processors, NVIDIA GPUs and AMD GPUs.
Link: https://arxiv.org/abs/1703.04594
====================================================
HardIDX: Practical and Secure Index with SGX (Benny Fuhry - 14 March, 2017)
In this paper we present HardIDX: a hardware-based approach, leveraging Intel's SGX, for search over encrypted data
Link: https://arxiv.org/abs/1703.04583
====================================================
Evaluation of DVFS techniques on modern HPC processors and accelerators for energy-aware applications (Enrico Calore - 8 March, 2017)
We run selected kernels and a full HPC application on two high-end processors widely used in the HPC context, namely an NVIDIA K80 GPU and an Intel Haswell CPU
Link: https://arxiv.org/abs/1703.02788
====================================================
Malware Guard Extension: Using SGX to Conceal Cache Attacks (Michael Schwarz - 1 March, 2017)
Intel SGX provides a mechanism that addresses this scenario
Link: https://arxiv.org/abs/1702.08719
====================================================
An analysis of core- and chip-level architectural features in four generations of Intel server processors (Johannes Hofmann - 24 February, 2017)
This paper presents a survey of architectural features among four generations of Intel server processors (Sandy Bridge, Ivy Bridge, Haswell, and Broad- well) with a focus on performance with floating point workloads
Link: https://arxiv.org/abs/1702.07554
====================================================
Glimmers: Resolving the Privacy/Trust Quagmire (David Lie - 23 February, 2017)
We describe how trustworthy hardware such as Intel's SGX can be used client-side -- in contrast to much recent work exploring SGX in cloud services -- to realize the Glimmer architecture, and demonstrate how this realization is able to resolve the tension between privacy and trust in a variety of cases.
Link: https://arxiv.org/abs/1702.07436
====================================================
Kalman filter tracking on parallel architectures (Giuseppe Cerati - 21 November, 2017)
We demonstrate very good performance on Intel Xeon and Xeon Phi architectures, as well as promising first results on Nvidia GPUs.
Link: https://arxiv.org/abs/1702.06359
====================================================
An Analysis of Parallelized Motion Masking Using Dual-Mode Single Gaussian Models (Peter Henderson - 16 February, 2017)
We implement the technique in Intel's Thread Building Blocks (TBB) and NVIDIA's CUDA libraries
Link: https://arxiv.org/abs/1702.05156
====================================================
TruSDN: Bootstrapping Trust in Cloud Network Infrastructure (Nicolae Paladi - 14 February, 2017)
We describe and implement TruSDN, a framework for bootstrapping trust in SDN infrastructure using Intel Software Guard Extensions (SGX), allowing to securely deploy SDN components and protect communication between network endpoints
Link: https://arxiv.org/abs/1702.04143
====================================================
Connecting the Dots: Privacy Leakage via Write-Access Patterns to the Main Memory (Tara Merin John - 17 June, 2017)
The attack has been shown on an Intel Core(TM) i7-4790 3.60GHz processor based system
Link: https://arxiv.org/abs/1702.03965
====================================================
Big Data Technology Accelerate Genomics Precision Medicine (Hao Li - 29 January, 2017)
Intel defines high performance GenomicsDB for variant call data query and Lustre filesystem with Hierarchal Storage Management for genomics data store. Based on these great technology, Intel defines genomics knowledge share and exchange architecture, which is landed and validated in BGI China and Shanghai Children Hospital with very positive feedback
Link: https://arxiv.org/abs/1701.09045
====================================================
Fog-Assisted wIoT: A Smart Fog Gateway for End-to-End Analytics in Wearable Internet of Things (Nicholas Constant - 24 January, 2017)
We developed a prototype of smart fog gateway (a middle layer) using Intel Edison and Raspberry Pi. We discussed the role of the smart fog gateway in orchestrating the process of data conditioning, intelligent filtering, smart analytics, and selective transfer to the cloud for long-term storage and temporal variability monitoring
Link: https://arxiv.org/abs/1701.08680
====================================================
Secure Content-Based Routing Using Intel Software Guard Extensions (Rafael Pires - 17 January, 2017)
We exploit Intel's new software guard extensions (SGX) to implement a CBR engine in a secure enclave
Link: https://arxiv.org/abs/1701.04612
====================================================
FogGIS: Fog Computing for Geospatial Big Data Analytics (Rabindra K. Barik - 10 December, 2016)
We built a prototype using Intel Edison, an embedded microprocessor
Link: https://arxiv.org/abs/1701.02601
====================================================
SGXIO: Generic Trusted I/O Path for Intel SGX (Samuel Weiser - 4 January, 2017)
To overcome this dependency, Intel introduced SGX, which allows to protect application code against a subverted or malicious OS by running it in a hardware-protected enclave
Link: https://arxiv.org/abs/1701.01061
====================================================
Rollback and Forking Detection for Trusted Execution Environments using Lightweight Collective Memory (Marcus Brandenburger - 19 June, 2017)
Novel hardware-aided trusted execution environments, as provided by Intel's Software Guard Extensions (SGX), enable to execute applications in a secure context that enforces confidentiality and integrity of the application state even when the host system is misbehaving
Link: https://arxiv.org/abs/1701.00981
====================================================
Fault Attacks on Encrypted General Purpose Compute Platforms (Robert Buhren - 12 December, 2016)
Intel's SGX and AMD's SME will provide means to encrypt parts of the RAM to protect security-relevant assets that reside there
Link: https://arxiv.org/abs/1612.03744
====================================================
Faster Population Counts Using AVX2 Instructions (Wojciech MuÅa - 5 September, 2018)
Maybe surprisingly, we show that a vectorized approach using SIMD instructions can be twice as fast as using the dedicated instructions on recent Intel processors
Link: https://arxiv.org/abs/1611.07612
====================================================
Parallelizing Word2Vec in Multi-Core and Many-Core Architectures (Shihao Ji - 23 December, 2016)
The new algorithm is particularly suitable for modern multi-core/many-core architectures, especially Intel's latest Knights Landing processors, and allows us to scale up the computation near linearly across cores and nodes, and process hundreds of millions of words per second, which is the fastest word2vec implementation to the best of our knowledge.
Link: https://arxiv.org/abs/1611.06172
====================================================
MILC staggered conjugate gradient performance on Intel KNL (Carleton DeTar - 3 November, 2016)
We review our work done to optimize the staggered conjugate gradient (CG) algorithm in the MILC code for use with the Intel Knights Landing (KNL) architecture. KNL is the second gener- ation Intel Xeon Phi processor
Link: https://arxiv.org/abs/1611.00728
====================================================
Accelerating BLAS on Custom Architecture through Algorithm-Architecture Co-design (Farhad Merchant - 27 November, 2016)
Finally, we show performance improvement of 3-140x in PE over commercially available Intel micro-architectures, ClearSpeed CSX700, FPGA, and Nvidia GPGPUs.
Link: https://arxiv.org/abs/1610.06385
====================================================
Portage: Bringing Hackers' Wisdom to Science (Guilherme Amadio - 9 October, 2016)
Here we demonstrate how a Gentoo Prefix installation can be used to cross compile software packages for the Intel Xeon Phi known as Knights Corner, as well as to manage large software stacks in HPC environments.
Link: https://arxiv.org/abs/1610.02742
====================================================
Lightweight User-Space Record And Replay (Robert O&#39;Callahan - 7 October, 2016)
Fortunately modern Intel CPUs, Linux kernels and user-space frameworks meet these constraints, although this has only become true recently
Link: https://arxiv.org/abs/1610.02144
====================================================
The BigDAWG Polystore System and Architecture (Vijay Gadepally - 23 September, 2016)
As a part of the Intel Science and Technology Center on Big Data, we are developing a polystore system designed for such problems
Link: https://arxiv.org/abs/1609.07548
====================================================
An ECM-based energy-efficiency optimization approach for bandwidth-limited streaming kernels on recent Intel Xeon processors (Johannes Hofmann - 12 September, 2016)
Using a 2D Jacobi solver as example that can serve as a blueprint for other memory-bound applications, we evaluate our approach on the four most recent Intel Xeon E5 processors (Sandy Bridge-EP, Ivy Bridge-EP, Haswell-EP, and Broadwell-EP)
Link: https://arxiv.org/abs/1609.03347
====================================================
A Lightweight Approach to Performance Portability with targetDP (Alan Gray - 9 November, 2016)
Leading HPC systems achieve their status through use of highly parallel devices such as NVIDIA GPUs or Intel Xeon Phi many-core CPUs
Link: https://arxiv.org/abs/1609.01479
====================================================
General Semi-Markov Model for Limit Order Books: Theory, Implementation and Numerics (Anatoliy Swishchuk - 17 August, 2016)
For both cases the justifications, diffusion limits, implementations and numerical results are presented for different Limit Order Book data: Apple, Amazon, Google, Microsoft, Intel on 2012/06/21 and Cisco, Facebook, Intel, Liberty Global, Liberty Interactive, Microsoft, Vodafone from 2014/11/03 to 2014/11/07.
Link: https://arxiv.org/abs/1608.05060
====================================================
A survey of sparse matrix-vector multiplication performance on large matrices (Max Grossman - 1 August, 2016)
We contribute a third-party survey of sparse matrix-vector (SpMV) product performance on industrial-strength, large matrices using: (1) The SpMV implementations in Intel MKL, the Trilinos project (Tpetra subpackage), the CUSPARSE library, and the CUSP library, each running on modern architectures. (2) NVIDIA GPUs and Intel multi-core CPUs (supported by each software package)
Link: https://arxiv.org/abs/1608.00636
====================================================
PANDA: Extreme Scale Parallel K-Nearest Neighbor on Distributed Architectures (Md. Mostofa Ali Patwary - 27 July, 2016)
In addition, we showcase performance and scalability on the recently released Intel Xeon Phi processor showing that our algorithm scales well even on massively parallel architectures.
Link: https://arxiv.org/abs/1607.08220
====================================================
Parallel Galton Watson Process (Olivier Bodini - 21 June, 2016)
Then we present how it can be implemented in a task-based parallel paradigm for shared memory (here, Intel Cilk)
Link: https://arxiv.org/abs/1606.06629
====================================================
cltorch: a Hardware-Agnostic Backend for the Torch Deep Neural Network Library, Based on OpenCL (Hugh Perkins - 15 June, 2016)
cltorch enables training of deep neural networks on GPUs from diverse hardware vendors, including AMD, NVIDIA, and Intel
Link: https://arxiv.org/abs/1606.04884
====================================================
Parallel Space Saving on Multi and Many-Core Processors (Massimo Cafaro - 11 January, 2017)
In this paper we deal with parallel shared-memory algorithms for frequent items; we present a shared-memory version of the Space Saving algorithm and we study its behavior with regard to accuracy and performance on many and multi-core processors, including the Intel Phi accelerator. Results also prove that for this algorithm the Intel Phi accelerator does not introduce any improvement with respect to the Xeon octa-core processor.
Link: https://arxiv.org/abs/1606.04669
====================================================
Splotch: porting and optimizing for the Xeon Phi (Timothy Dykes - 14 June, 2016)
We focus on the porting and optimization of Splotch, a scalable visualization algorithm, to utilize the Xeon Phi, Intel's coprocessor based upon the new Many Integrated Core architecture
Link: https://arxiv.org/abs/1606.04427
====================================================
BDDT-SCC: A Task-parallel Runtime for Non Cache-Coherent Multicores (Alexandros Labrineas - 14 June, 2016)
This paper presents BDDT-SCC, a task-parallel runtime system for non cache-coherent multicore processors, implemented for the Intel Single-Chip Cloud Computer
Link: https://arxiv.org/abs/1606.04288
====================================================
The Circle Game: Scalable Private Membership Test Using Trusted Hardware (Sandeep Tamrakar - 17 February, 2017)
We show how the carousel approach, using different data structures to represent the dictionary, can be realized on two different commercial hardware security architectures (ARM TrustZone and Intel SGX)
Link: https://arxiv.org/abs/1606.01655
====================================================
Multi-threaded Geant4 on the Xeon-Phi with Complex High-Energy Physics Geometry (Steven Farrell - 26 May, 2016)
A highly-complex detector geometry is used for benchmarking on an Intel Xeon Phi coprocessor. In addition, an implementation of parallel I/O based on Intel SCIF and ROOT technologies is incorporated and studied.
Link: https://arxiv.org/abs/1605.08371
====================================================
Kalman Filter Tracking on Parallel Architectures (Giuseppe Cerati - 18 May, 2016)
To address this we have seen the introduction of lower-power, multi-core processors such as GPGPU, ARM and Intel MIC. Our previous investigations showed that, using optimized data structures, track fitting with a Kalman Filter can achieve large speedups both with Intel Xeon and Xeon Phi
Link: https://arxiv.org/abs/1605.05508
====================================================
Extending Geant4 Parallelism with External Libraries (MPI, TBB) and Its Use on HPC Resources (Andrea Dotti - 5 May, 2016)
We have chosen to develop examples using the popular Intel Threading Building Block (for short TBB) as an alternative parallelization approach to the native Geant4 POSIX
Link: https://arxiv.org/abs/1605.01792
====================================================
Inspector: A Data Provenance Library for Multithreaded Programs (JÃ¶rg Thalheim - 2 May, 2016)
We implemented our algorithm to operate at the compiled binary code level by leveraging a combination of OS-specific mechanisms, and recently released Intel PT ISA extensions as part of the Broadwell micro-architecture
Link: https://arxiv.org/abs/1605.00498
====================================================
h-Index Manipulation by Undoing Merges (RenÃ© van Bevern - 9 July, 2016)
Intel., to appear] showed that, despite computational worst-case hardness results, substantial manipulation of the h-Index of Google Scholar author profiles is possible by merging articles
Link: https://arxiv.org/abs/1604.04827
====================================================
Unsupervised single-particle deep clustering via statistical manifold learning (Jiayi Wu - 31 December, 2016)
Through code optimization over the Intel high-performance computing (HPC) processors, our software implementation can generate thousands of reference-free class averages within several hours from hundreds of thousands of single-particle cryo-EM images, which allows significant improvement in ab initio 3D reconstruction resolution and quality
Link: https://arxiv.org/abs/1604.04539
====================================================
IPA in the Loop: Control Design for Throughput Regulation in Computer Processors (Xinwei Chen - 10 April, 2016)
The purpose of this paper is to report on its implementation on a machine, namely an Intel Haswell microprocessor, and compare its performance to that obtained from cycle-level, full system simulation environment
Link: https://arxiv.org/abs/1604.02727
====================================================
Performance analysis of the Kahan-enhanced scalar product on current multi- and manycore processors (Johannes Hofmann - 7 April, 2016)
The ECM model is extended appropriately to accommodate not only modern Intel multicore chips but also the Intel Xeon Phi "Knights Corner" coprocessor and an IBM POWER8 CPU
Link: https://arxiv.org/abs/1604.01890
====================================================
A block Recycled GMRES method with investigations into aspects of solver performance (Michael L. Parks - 6 April, 2016)
Numerical experiments are split into those demonstrating convergence properties and those demonstrating the data movement and cache efficiencies of the dominant operations of the method, measured using processor monitoring code from Intel.
Link: https://arxiv.org/abs/1604.01713
====================================================
Elzar: Triple Modular Redundancy using Intel Advanced Vector Extensions (technical report) (Dmitrii Kuvaiskii - 24 August, 2016)
To verify this hypothesis, we propose Elzar, a compiler framework that transforms unmodified multithreaded applications to support triple modular redundancy using Intel AVX extensions for vectorization. We study the sources of overheads and discuss possible improvements to Intel AVX that would lead to better performance.
Link: https://arxiv.org/abs/1604.00500
====================================================
Towards Automated Android App Collusion Detection (Irina Mariuca Asavoae - 7 March, 2016)
In this paper we provide a concise definition of collusion and report on a number of automated detection approaches, developed in co-operation with Intel Security.
Link: https://arxiv.org/abs/1603.02308
====================================================
Kalman-Filter-Based Particle Tracking on Parallel Architectures at Hadron Colliders (Giuseppe Cerati - 29 January, 2016)
To address this we have seen the introduction of lower-power, multi-core processors such as GPGPU, ARM and Intel MIC. Our previous investigations showed that, using optimized data structures, track fitting with Kalman Filter can achieve large speedups both with Intel Xeon and Xeon Phi
Link: https://arxiv.org/abs/1601.08245
====================================================
Auto-Tuning Dedispersion for Many-Core Accelerators (Alessio Sclocco - 18 January, 2016)
In this paper, we study the parallelization of the dedispersion algorithm on many-core accelerators, including GPUs from AMD and NVIDIA, and the Intel Xeon Phi
Link: https://arxiv.org/abs/1601.05052
====================================================
Evaluation of the Partitioned Global Address Space (PGAS) model for an inviscid Euler solver (Martina Prugger - 12 November, 2016)
In order to evaluate the incremental approach to parallelization (which is possible with UPC) and its performance characteristics, we implement different levels of optimization of the UPC code and compare it with an MPI parallelization on four different clusters of the Austrian HPC infrastructure (LEO3, LEO3E, VSC2, VSC3) and on an Intel Xeon Phi. The obtained results show worse performance (on VSC2), competitive performance (on LEO3, LEO3E and VSC3), and superior performance (on the Intel Xeon Phi).
Link: https://arxiv.org/abs/1601.03623
====================================================
Real-Time Dedispersion for Fast Radio Transient Surveys, using Auto Tuning on Many-Core Accelerators (Alessio Sclocco - 6 January, 2016)
We here present a study of the parallelization of this algorithm on many-core accelerators, including GPUs from AMD and NVIDIA, and the Intel Xeon Phi
Link: https://arxiv.org/abs/1601.01165
====================================================
On-the fly AES Decryption/Encryption for Cloud SQL Databases (Sushil Jajodia - 20 December, 2015)
AES processing overhead appears negligible for a modern CPU, e.g., a popular Intel I5
Link: https://arxiv.org/abs/1512.06423
====================================================
Optimizing the domain wall fermion Dirac operator using the R-Stream source-to-source compiler (Meifeng Lin - 4 December, 2015)
Our initial target platform is the Intel PC clusters
Link: https://arxiv.org/abs/1512.01542
====================================================
GPU-based fast Monte Carlo simulation for radiotherapy dose calculation (Xun Jia - 18 July, 2011)
Speed up factors of 69.1 ~ 87.2 have been observed using an NVIDIA Tesla C2050 GPU card against a 2.27GHz Intel Xeon CPU processor. For realistic IMRT and VMAT plans, MC dose calculation can be completed with less than 1% standard deviation in 36.1~39.6 sec using gDPM.
Link: https://arxiv.org/abs/1107.3355
====================================================
N-body simulation for self-gravitating collisional systems with a new SIMD instruction set extension to the x86 architecture, Advanced Vector eXtensions (Ataru Tanikawa - 5 September, 2011)
With one processor core of Intel Core i7-2600 processor (8 MB cache and 3.40 GHz) based on Sandy Bridge micro-architecture, we implemented a fourth-order Hermite scheme with individual timestep scheme (Makino and Aarseth, 1992), and achieved the performance of 20 giga floating point number operations per second (GFLOPS) for double-precision accuracy, which is two times and five times higher than that of the previously developed code implemented with the SSE instructions (Nitadori et al., 2006b), and that of a code implemented without any explicit use of SIMD instructions with the same processor core, respectively. We have parallelized the code by using so-called NINJA scheme (Nitadori et al., 2006a), and achieved 90 GFLOPS for a system containing more than N = 8192 particles with 8 MPI processes on four cores. We expect to achieve about 10 tera FLOPS (TFLOPS) for a self-gravitating collisional system with N 105 on massively parallel systems with at most 800 cores with Sandy Bridge micro-architecture. This performance will be comparable to that of Graphic Processing Unit (GPU) cluster systems, such as the one with about 200 Tesla C1070 GPUs (Spurzem et al., 2010)
Link: https://arxiv.org/abs/1104.2700
====================================================
GPUMCD: a new GPU-oriented Monte Carlo dose calculation platform (Sami Hissoiny - 6 January, 2011)
GPUMCD was run on a NVIDIA GTX480 while single threaded implementations of EGSnrc and DPM were run on an Intel Core i7 860. In all but one test case, 98% or more of all significant voxels passed a gamma criteria of 2%-2mm. In terms of execution speed and efficiency, GPUMCD is more than 900 times faster than EGSnrc and more than 200 times faster than DPM, a Monte Carlo package aiming fast executions. Absolute execution times of less than 0.3 s are found for the simulation of 1M electrons and 4M photons in water for monoenergetic beams of 15 MeV, including GPU-CPU memory transfers
Link: https://arxiv.org/abs/1101.1245
====================================================
Work-stealing for mixed-mode parallelism by deterministic team-building (Martin Wimmer - 22 December, 2010)
For instance, sorting 2^27-1 randomly generated integers we could improve the speed-up from 5.1 to 8.7 on a 32-core Intel Nehalem EX system, being consistently better than the tuned, task-parallel Cilk++ system.
Link: https://arxiv.org/abs/1012.5030
====================================================
Efficient Implementations of Molecular Dynamics Simulations for Lennard-Jones Systems (H. Watanabe - 23 June, 2011)
By utilizing the developed code, benchmark simulations are performed on a HITACHI SR16000/J2 system consisting of IBM POWER6 processors which are 4.7 GHz at the National Institute for Fusion Science (NIFS) and an SGI Altix ICE 8400EX system consisting of Intel Xeon processors which are 2.93 GHz at the Institute for Solid State Physics (ISSP), the University of Tokyo. The parallelization efficiency of the largest run, consisting of 4.1 billion particles with 8192 MPI processes, is about 73% relative to that of the smallest run with 128 MPI processes at NIFS, and it is about 66% relative to that of the smallest run with 4 MPI processes at ISSP
Link: https://arxiv.org/abs/1012.2677
====================================================
The Development of Epitaxial Graphene For 21st Century Electronics (Walt A. de Heer - 7 December, 2010)
The Georgia Institute of Technology (GIT) graphene electronics research project was first funded, by Intel in 2003, and later by the NSF in 2004 and the Keck foundation in 2008. The GIT group selected epitaxial graphene as the most viable route for graphene based electronics and their seminal paper on transport and structural measurements of epitaxial graphene was published in 2004
Link: https://arxiv.org/abs/1012.1644
====================================================
Large-Scale DNS of Gas-Solid Flow on Mole-8.5 (Qingang Xiong - 11 November, 2010)
Almost 20-fold speedup is achieved on one Nvidia C2050 GPU over one core of Intel E5520 CPU in double precision, and nearly ideal scalability is maintained when using up to 672 GPUs
Link: https://arxiv.org/abs/1011.2613
====================================================
Faster Radix Sort via Virtual Memory and Write-Combining (Jan Wassenberg - 6 September, 2010)
Our implementation outperforms Intel's recently published radix sort by a factor of 1.5
Link: https://arxiv.org/abs/1008.2849
====================================================
CRBLASTER: A Parallel-Processing Computational Framework for Embarrassingly-Parallel Image-Analysis Algorithms (Kenneth John Mighell - 12 August, 2010)
Removing cosmic rays from a single 800x800 pixel Hubble Space Telescope WFPC2 image takes 44 seconds with the IRAF script lacos_im.cl running on a single core of an Apple Mac Pro computer with two 2.8-GHz quad-core Intel Xeon processors. CRBLASTER is 7.4 times faster processing the same image on a single core on the same machine. Processing the same image with CRBLASTER simultaneously on all 8 cores of the same machine takes 0.875 seconds -- which is a speedup factor of 50.3 times faster than the IRAF script. A detailed analysis is presented of the performance of CRBLASTER using between 1 and 57 processors on a low-power Tilera 700-MHz 64-core TILE64 processor.
Link: https://arxiv.org/abs/1008.2192
====================================================
Toward large-scale Hybrid Monte Carlo simulations of the Hubbard model on graphics processing units (Kyle A. Wendt - 20 July, 2010)
We study these operations as implemented for the fermion matrix of the Hubbard model in d+1 space-time dimensions, and report a performance comparison between a 2.66 GHz Intel Xeon E5430 CPU and an NVIDIA Tesla C1060 GPU using double-precision arithmetic. We find speedup factors ranging between 30-350 for d = 1, and in excess of 40 for d = 3
Link: https://arxiv.org/abs/1007.3432
====================================================
Ultra-fast treatment plan optimization for volumetric modulated arc therapy (VMAT) (Chunhua Men - 24 May, 2010)
It takes only 5~8 minutes on CPU (MATLAB code on an Intel Xeon 2.27 GHz CPU) and 18~31 seconds on GPU (CUDA code on an NVIDIA Tesla C1060 GPU card) to generate such a plan
Link: https://arxiv.org/abs/1005.4396
====================================================
Multi-camera Realtime 3D Tracking of Multiple Flying Animals (Andrew D. Straw - 24 January, 2010)
In one implementation, an eleven camera system is capable of tracking three flies simultaneously at 60 frames per second using a gigabit network of nine standard Intel Pentium 4 and Core 2 Duo computers
Link: https://arxiv.org/abs/1001.4297
====================================================
RapidMind: Portability across Architectures and its Limitations (Iris Christadler - 19 February, 2010)
Performance of these kernels has been measured on various RapidMind backends (cuda, cell and x86) and compared to other hardware-specific implementations (using CUDA, Cell SDK and Intel MKL)
Link: https://arxiv.org/abs/1001.1902
====================================================
OMI4papps: Optimisation, Modelling and Implementation for Highly Parallel Applications (Volker Weinberg - 1 February, 2010)
An approach for modelling LRZ's application mix is given whichh makes use of performance counter measurements of real applications running on "HLRB II", an SGI Altix system based on 9728 Intel Montecito dual-cores.
Link: https://arxiv.org/abs/1001.1860
====================================================
Development of a GPU-based Monte Carlo dose calculation code for coupled electron-photon transport (Xun Jia - 22 March, 2010)
Speed up factors of about 5.0 ~ 6.6 times have been observed, using an NVIDIA Tesla C1060 GPU card against a 2.27GHz Intel Xeon CPU processor.
Link: https://arxiv.org/abs/0910.0329
====================================================
Cell processor implementation of a MILC lattice QCD application (Guochun Shi - 1 October, 2009)
In spite of this limitation, speedups of 8.7x (for 8x8x16x16 lattice) and 9.6x (for 16x16x16x16 lattice) were achieved when comparing a 3.2 GHz Cell processor to a single core of a 2.33 GHz Intel Xeon processor. When comparing the code scaled up to execute on a dual-Cell blade and a quad-core dual-chip Intel Xeon blade, the speedups are 1.5x (8x8x16x16 lattice) and 4.1x (16x16x16x16 lattice).
Link: https://arxiv.org/abs/0910.0262
====================================================
FastFlow: Efficient Parallel Streaming Applications on Multi-core (Marco Aldinucci - 7 September, 2009)
We compare FastFlow with state-of-the-art programming frameworks such as Cilk, OpenMP, and Intel TBB. We experimentally demonstrate that FastFlow is always more efficient than all of them in a set of micro-benchmarks and on a real world application; the speedup edge of FastFlow over other solutions might be bold for fine grain tasks, as an example +35% on OpenMP, +226% on Cilk, +96% on TBB for the alignment of protein P01111 against UniProt DB using Smith-Waterman algorithm.
Link: https://arxiv.org/abs/0909.1187
====================================================
GPU-based ultra fast IMRT plan optimization (Chunhua Men - 30 August, 2009)
On an NVIDIA Tesla C1060 GPU card, we have achieved speedup factors of 20-40 without losing accuracy, compared to the results from an Intel Xeon 2.27 GHz CPU. For a specific 9-field prostate IMRT case with 5x5 mm^2 beamlet size and 2.5x2.5x2.5 mm^3 voxel size, our GPU implementation takes only 2.8 seconds to generate an optimal IMRT plan
Link: https://arxiv.org/abs/0908.4421
====================================================
GPU-based ultra fast dose calculation using a finite pencil beam model (Xuejun Gu - 30 August, 2009)
All testing scenarios achieved speedup ranging from 200~400 times when using a NVIDIA Tesla C1060 card in comparison with a 2.27GHz Intel Xeon CPU. The computational time for calculating dose deposition coefficients for a 9-field prostate IMRT plan with this new framework is less than 1 second
Link: https://arxiv.org/abs/0908.4417
====================================================
Efficient Multiplication of Dense Matrices over GF(2) (Martin Albrecht - 11 November, 2008)
Good performance is demonstrated on on AMD's Opteron and particulary good performance on Intel's Core 2 Duo
Link: https://arxiv.org/abs/0811.1714
====================================================
A Public Key Block Cipher Based on Multivariate Quadratic Quasigroups (Danilo Gligoroski - 2 August, 2008)
Namely the reference C code for the 160-bit variant of the algorithm performs decryption in less than 11,000 cycles (on Intel Core 2 Duo -- using only one processor core), and around 6,000 cycles using two CPU cores and OpenMP 2.0 library. However, implemented in Xilinx Virtex-5 FPGA that is running on 249.4 MHz it achieves decryption throughput of 399 Mbps, and implemented on four Xilinx Virtex-5 chips that are running on 276.7 MHz it achieves encryption throughput of 44.27 Gbps
Link: https://arxiv.org/abs/0808.0247
====================================================
XORSAT: An Efficient Algorithm for the DIMACS 32-bit Parity Problem (Jing-Chao Chen - 1 March, 2007)
For a par32-5 instance, XORSAT took 2.9 seconds, while EqSatz took 2844 seconds on Intel Pentium IV 2.66GHz CPU
Link: https://arxiv.org/abs/cs/0703006
====================================================
FLY: MPI-2 High Resolution code for LSS Cosmological Simulations (U. Becciani - 20 March, 2007)
This new version was developed using the Linux Cluster of CINECA, an IBM Cluster with 1024 Intel Xeon Pentium IV 3.0 Ghz. The results show that it is possible to run a 64 Million particle simulation in less than 15 minutes for each timestep, and the code scalability with the number of processors is achieved. This lead us to propose FLY as a code to run very large N-Body simulations with more than $10^{9}$ particles with the higher resolution of a pure tree code
Link: https://arxiv.org/abs/astro-ph/0703526
====================================================
Detection of Markov Random Fields on Two-Dimensional Intersymbol Interference Channels (Ying Zhu - 27 September, 2006)
Intell., Nov. 1984. On the 2 x 2 averaging-mask ISI channel, at a bit error rate (BER) of 10^{-5}, the concatenated algorithm achieves SNR savings of between 0.5 and 2.0 dB over the IRCSDF detector alone; the savings increase as the MRFs become more correlated, or as the SNR decreases
Link: https://arxiv.org/abs/cs/0609155
====================================================
Kurucz's codes under GNU-Linux (L. Sbordone - 13 September, 2005)
The latest version (8.1 at the time of the workshop) of the Intel Fortran Compiler allowed for a significantly better backward compatibility with the VMS version of the code, thus allowing us to remove almost all the modifications we initially introduced in order to compile the code under IFC. We now provide ported versions both of ATLAS 9 (the ODF version of ATLAS) and ATLAS 12 (the opacity sampling version)
Link: https://arxiv.org/abs/astro-ph/0509337
====================================================
A Flexible Thread Scheduler for Hierarchical Multiprocessor Machines (Samuel Thibault - 27 June, 2005)
We experimented our proposal on a scientific application running on a ccNUMA Bull NovaScale with 16 Intel Itanium II processors; results show a 30% gain compared to a classical scheduler, and are similar to what a handmade scheduler achieves in a non-portable way.
Link: https://arxiv.org/abs/cs/0506097
====================================================
Utilizing Reconfigurable Hardware Processors via Grid Services (Darran Nathan - 15 November, 2004)
Computational grids typically consist of nodes utilizing ordinary processors such as the Intel Pentium. This paper explores how FPGAs can be transparently exposed for remote use via grid services, by integrating the Proteus Software Platform with the Globus Toolkit 3.0.
Link: https://arxiv.org/abs/cs/0411050
====================================================
A machine-independent port of the SR language run-time system to the NetBSD operating system (Ignatios Souvatzis - 10 November, 2004)
The integrated POSIX threads support of NetBSD-2.0 should allow us to use library primitives provided for NetBSD's phtread system to implement the primitives needed by the SR run-time system, thus implementing 13 target CPUs at once and automatically making use of SMP on VAX, Alpha, PowerPC, Sparc, 32-bit Intel and 64 bit AMD CPUs.
Link: https://arxiv.org/abs/cs/0411028
====================================================
Cluster computing performances using virtual processors and mathematical software (Gianluca Argentini - 9 January, 2004)
The tested technology is the INTEL Hyper Threading on real processors, and the programs are MATLAB 6.5 Release 13 scripts for floating points computation
Link: https://arxiv.org/abs/cs/0401006
====================================================
Lattice QCD Calculations on Commodity Clusters at DESY (A. Gellrich - 16 June, 2003)
16 dual-CPU PCs, equipped with Intel Pentium 4 Xeon processors. Using the SIMD Streaming Extensions (SSE/SSE2) on Intel's Pentium 4 Xeon CPUs give promising results for both the single CPU and the parallel version
Link: https://arxiv.org/abs/physics/0306090
====================================================
Specifying nonspecific evidence (Johan Schubert - 16 May, 2003)
Intell. 8(6), 711-725 (1993)] we established within Dempster-Shafer theory a criterion function called the metaconflict function
Link: https://arxiv.org/abs/cs/0305020
====================================================
Finding a Posterior Domain Probability Distribution by Specifying Nonspecific Evidence (Johan Schubert - 16 May, 2003)
Intell. 8 (1993) 711-725] we established within Dempster-Shafer theory a criterion function called the metaconflict function. Thesis, TRITA-NA-9410, Royal Institute of Technology, Stockholm, 1994, ISBN 91-7170-801-4] we not only found the most plausible subset for each piece of evidence, we also found the plausibility for every subset that this piece of evidence belongs to the subset
Link: https://arxiv.org/abs/cs/0305015
====================================================
A scalable PC-based parallel computer for lattice QCD (Z. Fodor - 12 September, 2002)
cluster consists of 137 Intel P4-1.7GHz nodes. The sustained performance for dynamical staggered(wilson) quarks on large lattices is around 70(110) GFlops
Link: https://arxiv.org/abs/hep-lat/0209115
====================================================
Weaves: A Novel Direct Code Execution Interface for Parallel High Performance Scientific Codes (Srinidhi Varadarajan - 3 May, 2002)
We identify design constraints, their impact on implementation alternatives, configuration scenarios, and present results from a prototype implementation on Intel x86 architectures.
Link: https://arxiv.org/abs/cs/0205004
====================================================
Better than $1/Mflops sustained: a scalable PC-based parallel computer for lattice QCD (Z. Fodor - 21 May, 2003)
cluster consists of 137 Intel P4-1.7GHz nodes with 512 MB RDRAM. The 32-bit, single precision sustained performance for dynamical QCD without communication is 1510 Mflops/node with Wilson and 970 Mflops/node with staggered fermions. This gives a total performance of 208 Gflops for Wilson and 133 Gflops for staggered QCD, respectively (for 64-bit applications the performance is approximately halved). This type of communication is cost effective (only 30% of the hardware costs is spent on the communication). According to our benchmark measurements this type of communication results in around 40% communication time fraction for lattices upto 48^3\cdot96 in full QCD simulations
Link: https://arxiv.org/abs/hep-lat/0202030
====================================================
FEL injector control system on the base of EPICS (T. V. Salikova - 8 November, 2001)
It uses low-cost hardware: personal computers with the processor Intel x86 and CAMAC equipment produced by our institute
Link: https://arxiv.org/abs/physics/0111038
====================================================
The PCI Interface for GRAPE Systems: PCI-HIB (A. Kawai - 16 July, 1997)
PCI is an I/O bus standard developed by Intel. In test runs with a Barnes-Hut treecode, we found that the performance of new system with PCI interface is 40% better than that of the original system.
Link: https://arxiv.org/abs/astro-ph/9707079
====================================================
Calculation of electronic properties of amorphous alloys (J. C. Swihart - 3 November, 1995)
The LSMS algorithm is optimized for the Intel XP/S-150, a multiple-instruction-multiple-data parallel computer with 1024 nodes and 2 compute processors per node. In these calculations we determine the potentials in the atomic sphere approximation self consistently at each site, unlike previous calculations[2] where we determined the potentials self consistently at an average site. We present calculated total electronic densities of states for amorphous Ni$_{80}$P$_{20}$ and Ni$_{40}$Pd$_{40}$P$_{20}$ with 300 atoms in a supercell.
Link: https://arxiv.org/abs/cond-mat/9511021
====================================================
A Hybrid Decomposition Parallel Implementation of the Car-Parrinello Method (James K. Wiggs - 14 November, 1994)
Performance statistics for 32, 64, 128 and 512 Si atom runs on the Touchstone Delta and Intel Paragon parallel supercomputers and comparison with the performance of an optimized code running the smaller systems on the Cray Y-MP and C90 are presented.
Link: https://arxiv.org/abs/chem-ph/9411009
====================================================
Performance analysis and optimization of the JOREK code for many-core CPUs (T. B. FehÃ©r - 10 October, 2018)
This report investigates the performance of the JOREK code on the Intel Knights Landing and Skylake processor architectures
Link: https://arxiv.org/abs/1810.04413
====================================================
Towards Lattice Quantum Chromodynamics on FPGA devices (Grzegorz Korcyl - 8 October, 2018)
We find out that the FPGA implementation offers a comparable performance with that obtained using current CPU or Intel's many core Xeon Phi accelerators
Link: https://arxiv.org/abs/1810.04201
====================================================
PCI-MDR: Missing Data Recovery in Wireless Sensor Networks using Partial Canonical Identity Matrix (Neha Jain - 8 October, 2018)
To validate the proposed method, the results have been obtained on the real data set of temperature sensors from the Intel Lab
Link: https://arxiv.org/abs/1810.03401
====================================================
Privado: Practical and Secure DNN Inference (Shruti Tople - 1 October, 2018)
Recently, cloud providers have extended support for trusted hardware primitives such as Intel SGX
Link: https://arxiv.org/abs/1810.00602
====================================================
GPU acceleration of an iterative scheme for gas-kinetic model equations with memory reduction techniques (Lianhua Zhu - 30 September, 2018)
A $190\times$ speedup can be achieved on the Tesla K40 GPUs against a single core of Intel Xeon-E5-2680v3 CPU for the 3D lid-driven cavity flow.
Link: https://arxiv.org/abs/1810.00348
====================================================
HSTREAM: A directive-based language extension for heterogeneous stream computing (Suejb Memeti - 25 September, 2018)
Big data streaming applications require utilization of heterogeneous parallel computing systems, which may comprise multiple multi-core CPUs and many-core accelerating devices such as NVIDIA GPUs and Intel Xeon Phis
Link: https://arxiv.org/abs/1809.09387
====================================================
Software for Sparse Tensor Decomposition on Emerging Computing Architectures (Eric Phipps - 24 September, 2018)
Our goal is to develop software that is portable to a variety of multicore and manycore computing architectures, such as multicore CPUs, the Intel Xeon Phi, and NVIDIA GPUs. We show that we are competitive with state-of-the-art approaches available in the literature while having the advantage of being able to run on a wider of variety of architectures with a single code.
Link: https://arxiv.org/abs/1809.09175
====================================================
ReplicaTEE: Enabling Seamless Replication of SGX Enclaves in the Cloud (Claudio Soriente - 13 September, 2018)
With the proliferation of Trusted Execution Environments (TEEs) such as Intel SGX, a number of cloud providers will soon introduce TEE capabilities within their offering (e.g., Microsoft Azure)
Link: https://arxiv.org/abs/1809.05027
====================================================
Comparing Computing Platforms for Deep Learning on a Humanoid Robot (Alexander Biddulph - 10 September, 2018)
One of the platforms is the CPU-centered Intel NUC7i7BNH and the other is a NVIDIA Jetson TX2 system that puts more emphasis on GPU processing
Link: https://arxiv.org/abs/1809.03668
====================================================
Pushing the Limits of Encrypted Databases with Secure Hardware (Panagiotis Antonopoulos - 7 September, 2018)
Recently, trusted computing platforms (e.g., Intel SGX) have emerged as an alternative to implement encrypted databases
Link: https://arxiv.org/abs/1809.02631
====================================================
Automated Instruction Stream Throughput Prediction for Intel and AMD Microarchitectures (Jan Laukemann - 10 October, 2018)
We show the process of building a machine model from available documentation and semi-automatic benchmarking, and carry it out for the latest Intel Skylake and AMD Zen micro-architectures
Link: https://arxiv.org/abs/1809.00912
====================================================
The Shift from Processor Power Consumption to Performance Variations: Fundamental Implications at Scale (Joseph Schuchart - 24 August, 2018)
The Intel Haswell-EP processor generation introduces several major advancements of power control and energy-efficiency features. Through measurements on an Intel Sandy Bridge-EP cluster, we show that previous generations have sustained homogeneous performance across multiple CPUs and compensated for hardware manufacturing variability through varying power consumption
Link: https://arxiv.org/abs/1808.08106
====================================================
Student Cluster Competition 2017, Team University ofTexas at Austin/Texas State University: Reproducing Vectorization of the Tersoff Multi-Body Potential on the Intel Skylake and NVIDIA V100 Architectures (James Sullivan - 21 August, 2018)
We investigated accuracy, optimization performance, and scaling with our Intel CPU and NVIDIA GPU based cluster.
Link: https://arxiv.org/abs/1808.07027
====================================================
Mitigating Branch-Shadowing Attacks on Intel SGX using Control Flow Randomization (Shohreh Hosseinzadeh - 20 August, 2018)
Intel Software Guard Extensions (SGX) is a promising hardware-based technology for protecting sensitive computations from potentially compromised system software
Link: https://arxiv.org/abs/1808.06478
====================================================
GEEC: Scalable, Efficient, and Consistent Consensus for Blockchains (Xusheng Chen - 7 August, 2018)
We present GEEC, a new blockchain protocol and its runtime system by leveraging the strong confidentiality and integrity of the Intel Software Guard eXtentions (SGX) hardware. GEEC achieves strong privacy and security for permissioned blockchains with Intel SGX and provides an open membership scheme to make the blockchain scale as easily as a public blockchain
Link: https://arxiv.org/abs/1808.02252
====================================================
Sound Transpilation from Binary to Machine-Independent Code (Roberto Metere - 27 July, 2018)
Intel)
Link: https://arxiv.org/abs/1807.10664
====================================================
Spectre Returns! Speculation Attacks using the Return Stack Buffer (Esmaeil Mohammadian Koruyeh - 20 July, 2018)
Importantly, none of the known defenses including Retpoline and Intel's microcode patches stop all SpectreRSB attacks. In particular, on Core-i7 Skylake and newer processors (but not on Intel's Xeon processor line), a patch called RSB refilling is used to address a vulnerability when the RSB underfills; this defense interferes with SpectreRSB's ability to launch attacks that switch into the kernel
Link: https://arxiv.org/abs/1807.07940
====================================================
SPOC: Secure Payments for Outsourced Computations (MichaÅ KrÃ³l - 17 July, 2018)
We implement our system using Ethereum Smart Contracts and Intel SGX and present first evaluation proving its security and low usage cost.
Link: https://arxiv.org/abs/1807.06462
====================================================
A NUMA-Aware Provably-Efficient Task-Parallel Platform Based on the Work-First Principle (Justin Deters - 5 September, 2018)
Furthermore, we implemented a prototype platform by modifying Intel's Cilk Plus runtime system and empirically demonstrate that the resulting system is work efficient and scalable.
Link: https://arxiv.org/abs/1806.11128
====================================================
Context-aware Failure-oblivious Computing as a Means of Preventing Buffer Overflows (Manuel Rigger - 26 June, 2018)
We demonstrate that introspection can be implemented in popular bug-finding and bug-mitigation tools such as LLVM's AddressSanitizer, SoftBound, and Intel-MPX-based bounds checking
Link: https://arxiv.org/abs/1806.09026
====================================================
Trading algorithms with learning in latent alpha models (Philippe Casgrain - 12 June, 2018)
We also provide calibration results for a particular model using Intel Corporation stock as an example.
Link: https://arxiv.org/abs/1806.04472
====================================================
Achieving Data Dissemination with Security using FIWARE and Intel Software Guard Extensions (SGX) (Dalton CÃ©zane Gomes Valadares - 5 June, 2018)
We present a solution that considers the security components of FIWARE and the Intel SGX capabilities. FIWARE is a platform created to support the development of Smart Applications, including IoT systems, and SGX is the Intel solution for Trusted Execution Environment (TEE)
Link: https://arxiv.org/abs/1806.01906
====================================================
Highly Efficient 8-bit Low Precision Inference of Convolutional Neural Networks with IntelCaffe (Jiong Gong - 4 May, 2018)
We show that the inference throughput and latency with ResNet-50, Inception-v3 and SSD are improved by 1.38X-2.9X and 1.35X-3X respectively with neglectable accuracy loss from IntelCaffe FP32 baseline and by 56X-75X and 26X-37X from BVLC Caffe. All these techniques have been open-sourced on IntelCaffe GitHub1, and the artifact is provided to reproduce the result on Amazon AWS Cloud.
Link: https://arxiv.org/abs/1805.08691
====================================================
Blockchain and Trusted Computing: Problems, Pitfalls, and a Solution for Hyperledger Fabric (Marcus Brandenburger - 22 May, 2018)
To remedy this problem, it has been suggested to combine blockchains with trusted execution environments (TEEs), such as Intel SGX, for executing applications that demand privacy
Link: https://arxiv.org/abs/1805.08541
====================================================
SGX-Aware Container Orchestration for Heterogeneous Clusters (SÃ©bastien Vaucher - 27 July, 2018)
The recent introduction by Intel of Software Guard Extensions (SGX) into the mass market offers an alternative to developers, who can now execute their code in a hardware-secured environment without trusting the cloud provider.
Link: https://arxiv.org/abs/1805.05847
====================================================
Nethammer: Inducing Rowhammer Faults through Network Requests (Moritz Lipp - 13 May, 2018)
Other systems can still be attacked if they are protected with quality-of-service techniques like Intel CAT
Link: https://arxiv.org/abs/1805.04956
====================================================
Program Generation for Small-Scale Linear Algebra Applications (Daniele G. Spampinato - 12 May, 2018)
The results show significant speed-ups compared to straightforward C with Intel icc and clang with a polyhedral optimizer, as well as library-based and template-based implementations.
Link: https://arxiv.org/abs/1805.04775
====================================================
Dwarfs on Accelerators: Enhancing OpenCL Benchmarking for Heterogeneous Computing Architectures (Beau Johnston - 10 May, 2018)
Preliminary results and analysis are reported for eight benchmark codes on a diverse set of architectures -- three Intel CPUs, five Nvidia GPUs, six AMD GPUs and a Xeon Phi.
Link: https://arxiv.org/abs/1805.03841
====================================================
SecureCloud: Secure Big Data Processing in Untrusted Clouds (Florian Kelbert - 4 May, 2018)
To provide security guarantees, SecureCloud leverages novel security mechanisms present in recent commodity CPUs, in particular, Intel's Software Guard Extensions (SGX)
Link: https://arxiv.org/abs/1805.01783
====================================================
SecureStreams: A Reactive Middleware Framework for Secure Data Stream Processing (AurÃ©lien Havet - 4 May, 2018)
Its design combines the high-level reactive dataflow programming paradigm with Intel's low-level software guard extensions (SGX) in order to guarantee privacy and integrity of the processed data
Link: https://arxiv.org/abs/1805.01752
====================================================
X-Search: Revisiting Private Web Search using Intel SGX (Sonia Ben Mokhtar - 4 May, 2018)
This paper introduces X-Search , a novel private Web search mechanism building on the disruptive Software Guard Extensions (SGX) proposed by Intel. Our evaluation shows that: (1) X-Search offers stronger privacy guarantees than its competitors as it operates under a stronger adversarial model; (2) it better resists state-of-the-art re-identification attacks; and (3) from the performance perspective, X-Search outperforms its competitors both in terms of latency and throughput by orders of magnitude.
Link: https://arxiv.org/abs/1805.01742
====================================================
CYCLOSA: Decentralizing Private Web Search Through SGX-Based Browser Extensions (Rafael Pires - 27 July, 2018)
CYCLOSA improves security by relying on trusted execution environments (TEEs) as provided by Intel SGX
Link: https://arxiv.org/abs/1805.01548
====================================================
Identity Aging: Efficient Blockchain Consensus (Mansoor Ahmed - 19 April, 2018)
Our first system, SCIFER, leverages Intel's SGX attestation for identity bootstrapping in a partially-decentralized setting, where blockchain is permissionless, but we trust Intel for attestation
Link: https://arxiv.org/abs/1804.07391
====================================================
The Brain on Low Power Architectures - Efficient Simulation of Cortical Slow Waves and Asynchronous States (Roberto Ammendola - 10 April, 2018)
Furthermore, a comparison is given of instantaneous power, total energy consumption, execution time and energetic cost per synaptic event of SWA/AW DPSNN simulations when executed on either ARM- or Intel-based server platforms.
Link: https://arxiv.org/abs/1804.03441
====================================================
Increasing Parallelism in the ROOT I/O Subsystem (Guilherme Amadio - 9 April, 2018)
Performance measurements are discussed through real life examples coming from CMS production workflows on traditional server platforms and highly parallel architectures such as Intel Xeon Phi.
Link: https://arxiv.org/abs/1804.03326
====================================================
